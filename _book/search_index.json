[
["index.html", "An Introduction to Probability and Simulation Preface", " An Introduction to Probability and Simulation Kevin Ross 2020-07-25 Preface Why study probability and simulation? Why study probability? Probability is the study of uncertainty, and life is uncertain Probability is used in a wide variety of fields, including: statistics, physics, engineering, biology, medicine, finance, actuarial science, political science, law, sports , … Many topics and problems in probability are frequently misunderstood and sometimes counter intuitive, so it’s worthwhile to take a careful study “Probabilistic thinking” is an important component of statistical literacy (e.g. how to assess risk when making decisions) Probability provides the foundation for many important statistical concepts and methods such as p-values and confidence intervals Why use simulation to study probability? Many concepts encountered in probability can seem esoteric; simulation helps make them more concrete. Simulation provides an effective tool for analyzing probability models and for exploring effects of changing assumptions Simulation can be used to check analytical solutions Simulation is often the best or only method for investigating many problems which are too complex to solve analytically Simulation-based reasoning is an important component of statistical literacy (e.g. understanding a p-value via simulation) Many statistical procedures employ simulation-based methods (e.g. bootstrapping) 0.0.1 Learning Objectives/Goals/Style??? (Better title) Don’t skimp on rigorous definitions (RV is function defined on probspace) but deemphasize mathematical computation (counting and calculus) Emphasize simulation Visualize in lots of plots Start multivariate relationships early Rely on statistical literacy Active learning, workbook style Symbulate This book uses the Python package Symbulate (https://github.com/dlsun/symbulate) which provides a user friendly framework for conducting simulations involving probability models. The syntax of Symbulate reflects the “language of probability” and makes it intuitive to specify, run, analyze, and visualize the results of a simulation. In Symbulate, probability spaces, events, random variables, and random processes are symbolic objects which can be manipulated, independently of their simulated realizations. Symbulate’s consistency with the mathematics of probability reinforces understanding of probabilistic concepts. The article Ross and Sun (2019) discusses Symbulate and its features in more detail. To install Symbulate, it is recommended that you first install the Anaconda distribution, which is a Python environment with many scientific packages installed (including all of the packages that Symbulate is built on). After installing Anaconda, the recommended way to installing Symbulate is run the command !pip install symbulate from inside a notebook. (The Symbulate package can also be downloaded and installed manually from the Symbulate Github repository following these instructions.) The following command imports Symbulate during a Python session. from symbulate import * The Symbulate command plot() produces graphics. These graphics can be customized (by changing axis limits, adding titles, legends, etc) using Matplotlib, and in particular the pyplot method, which can be imported with import matplotlib import matplotlib.pyplot as plt Jupyter or Google Colab notebooks provide a natural interface for Symbulate. The code in this book matches as closely as possible the commands that would be entered into cells in a notebook. However, certain commands that appear throughout the book are needed only to properly produce the output in this book, and not if working directly in notebooks. In particular, plt.figure() and plt.show() are not needed to produce graphics in Jupyter (with the use of the %matplotlib inline “magic”). In addition, Jupyter automatically displays the result of the last line in a cell; print() is generally not needed to display output (unless you wish to format it, or it is not the last line in the cell). For example, a code snippet that appears in this book as x = RV(Binomial(4, 0.5)).sim(10000) plt.figure() x.plot() plt.show() print(x) x = RV(Binomial(4, 0.5)).sim(10000) # plt.figure() x.plot() plt.show() print(x) ## &lt;symbulate.results.RVResults object at 0x00000000208C7EC8&gt; x = RV(Binomial(4, 0.5)).sim(10000) plt.figure() x.plot() plt.show() print(x) ## &lt;symbulate.results.RVResults object at 0x000000002B9FAAC8&gt; would be entered in a Jupyter notebook as x = RV(Binomial(4, 0.5)).sim(10000) x.plot() x Don’t do what Donny Don’t does Some of the examples and exercises in this book are labeled “Don’t do what Donny Don’t does”. This is a Simpson’s reference. In this text, Donny represents a student who makes many of the mistakes commonly made by students studying probability. The idea of these problems is for you to learn from the common mistakes that Donny makes, by identifying why he is wrong and by helping him understand and correct his mistakes. (But be careful: sometimes Donny is right!) About this book This book was written using the bookdown package (Xie 2020), which was built on top of R Markdown and knitr (Xie 2015). Python code was run in RStudio using the reticulate package. References "],
["prob-literacy.html", "Chapter 1 What is Probability?", " Chapter 1 What is Probability? This chapter provides a non-technical introduction to randomness and probability. Many of the topics introduced in this chapter will be covered in more detail in later chapters. NO MATH BEYOND TWO WAY TABLES AND BASIC EXPECTED VALUES Expand chapter 1 with more example of probability/simulation computations with as little math and terminology as possible. (e.g. Don’t define RV or event or sample space.) Add a few motivating examples with links - 538 election, hurricane, etc "],
["randomness.html", "1.1 Instances of randomness", " 1.1 Instances of randomness instances of randomness - examples; include in other sections? (random sampling, random assignment, future/past, etc, physical (coin, die), quantum) Exercise 1.1 Each of the following situations involves a probability. How are the various situations similar, and how are they different? What is one feature that all of the situations have in common? If you were to estimate the probability in question, how might you do it? What are some things to consider? The goal here is not to do any calculations but rather to think about, via these examples, similarities and differences of situations in which probabilities are of interest. The probability that a single flip of a fair coin lands on heads. The probability that in two flips of a fair coin exactly one flip lands on heads. The probability that in 10000 flips of a fair coin exactly 5000 flips land on heads. The probability that in 10000 flips of a fair coin “around” 5000 flips land on heads. The probability you win the next Powerball lottery if you purchase a single ticket, 6-7-16-23-26, plus the Powerball number, 4. (FYI: There are roughly1 300 million possible winning number combinations.) The probability you win the next Powerball lottery if you purchase a single ticket, 1-2-3-4-5, plus the Powerball number, 6. The probability that someone wins the next Powerball lottery. (FYI: especially when the jackpot is large, there are hundreds of millions of tickets sold.) The probability that a “randomly selected” Cal Poly student is from CA. The probability that Hurricane Humberto makes landfall in the U.S. The probability that the Los Angeles Chargers win the next Superbowl. The probability that Donald Trump wins the 2020 U.S. Presidential Election. The probability that extraterrestrial life currently exists somewhere in the universe. The probability that you ate an apple on April 17, 2009. The subject of probability concerns random phenomena. A phenomenon is random if there are multiple potential outcomes, and there is uncertainty about which outcome will occur. Uncertainty is the feature that all the scenarios have in common. Uncertainty does not necessarily mean uncertainty about an occurrence in the future. For example, you either ate or apple or not on April 17, 2009, but you’re not certain about it. But if you tended to eat a lot of apples ten years ago, then you might give a high probability to the event that you ate one on April 17, 2009. Many phenomena involve physical randomness2, like flipping a coin or drawing powerballs at random from a bin. Statistical applications often involve the planned use of physical randomness Random selection involves selecting a sample of individuals at random from a population (e.g. via random digit dialing). Random assignment involves assigning individuals at random to groups (e.g. in a randomized experiment). However, in many other situations randomness just vaguely reflects uncertainty. In any case, random does not mean haphazard. In a random phenomenon, while individual outcomes are uncertain, there is a regular distribution of outcomes over a large number of (hypothetical) repetitions. In two flips of a fair coin we wouldn’t necessarily see one head and one tail. But in 10000 flips of a fair coin, we would expect to see close to 5000 heads and 5000 tails. We don’t know who will win the next Superbowl, but we can and should certainly consider some teams as more likely to win than others. We could imagine a large number of hypothetical 2019 seasons; how often would we expect the Eagles to win? The Raiders? (Hopefully a lot for the Eagles; probably not much for the Raiders). Also, random does not necessarily mean equally likely. In a random phenomenon, certain outcomes or events might be more or less likely than others. It’s much more likely that a randomly selected Cal Poly student is from CA than not. Not all NFL teams are equally likely to win the next Superbowl. The exact count is 292,201,338. We will see how to compute this number later.↩︎ We will refer to as “random” any scenario that involves a reasonable degree of uncertainty. We’re avoiding philosophical questions about what is “true” randomness, like the following. Is a coin flip really random? If all factors that affect the trajectory of the coin were known precisely, then wouldn’t the outcome be determined? Does true randomness only exist in quantum mechanics?↩︎ "],
["interpretations.html", "1.2 Interpretations of probability", " 1.2 Interpretations of probability In the previous section we encountered a variety of scenarios which involved uncertainty, a.k.a. randomness. Just as there are a few “types” of randomness, there are a few ways of interpreting probability, namely, long run relative frequency and subjective probability. Exercise 1.2 Revisit the scenarios in Exercise 1.1. Now consider how “probability” is interpreted in the different scenarios. In each scenario, what does “probability” mean? How might you estimate the probability? Start to make guesses for the probabilities; are they “high” or “low”? How high or low? Again, the goal is not to do any calculations but rather to think about, via these examples, similarities and differences of situations in which probabilities are of interest. In particular, compare Scenarios 3 and 4 Scenarios 5 and 6 Scenarios 6 and 7 How are scenarios 1 through 8 (collectively) different from scenarios 9 through 13 (collectively)? The probability of an event is a number in the interval \\([0, 1]\\) measuring the event’s likelihood or degree of uncertainty. A probability can take any values in the continuous scale from 0% to 100%3. In particular, a probability requires much more interpretation than “is the probability greater than, less than, or equal to 50%?” When interpreting probabilities, be careful not to confuse “the particular” with “the general”. (“The particular.”) A very specific event, surprising or not, often has low probability. Even though in 10000 flips of a fair coin we would expect to see about 5000 heads, the probability that exactly 5000 out of 10000 flips are heads is fairly small (about4 0.008). The probability that the winning powerball number is 6-7-16-23-26-(4) is exactly the same as the probability that the winning powerball number is 1-2-3-4-5-(6). Each of these sequences is just one of the roughly 300 million possible sequences, and each sequences has about a 1 in 300 million chance of being the winning number. However, many people think 6-7-16-23-26-(4) is more likely because 1-2-3-4-5-(6) “doesn’t look random”. The probability that you get a text from your best friend at 7:43pm on Oct 12, 2019 inviting you to dinner after you’ve just ordered pizza from your favorite pizza place is probably pretty small. None of these items — getting a text, having a friend invite you to dinner, ordering pizza from your favorite pizza place — is unusual, but the chances of them all combining in this way at this particular time are fairly small. (“The general.”) However, if there are many like events, their combined probability can be high. The probability that around 5000 out of 10000 coin flips land on heads is fairly large. For example, if “around” is interpreted as between 4900 and 5100 (for a proportion of heads between 0.49 to 0.51) the probability is about 0.956. The probability that the winning powerball number is an ordered sequence, like 1-2-3-4-5-(6), is extremely small5. However, the probability that the winning number is not an ordered sequence, like 6-7-16-23-26-(4), is exremely high. When interpreting probabilities, be careful not to confuse an event like “the winning number is 6-7-16-23-26-(4)” (the particular, low probability) with an event like “the winning number is not an ordered sequence” (the general, high probability). The probability that some time in the next month or so a friend invites you for dinner after you’ve already had dinner on your own is probably fairly high. Even if an event has extremely small probability, given enough repetitions of the random phenomenon, the probability that the event occurs on at least one of the repetitions is high. The probability that a specific powerball ticket is the winning number is about 1 in 300 million. So if you buy a single ticket, it is extremely unlikely that you will win. However, if hundreds of millions of powerball tickets are sold, the probability that someone somewhere wins is pretty high. For example, if 500 million tickets are sold then there is a roughly 80% chance that at least one ticket has the winning number (under certain assumptions). 1.2.1 Relative frequency The probability that a single flip of a fair coin lands on heads is 0.5. How do we interpret this 0.5? The notation of “fairness” implies that the two outcomes, heads and tails, should be equally likely, so we have a “50/50 chance”. But how else can we interpret this 50%? One way is by considering what would happen if we flipped the coin main times. Now, if we would flipped the coin twice, we wouldn’t expect to necessarily see one head and one tail. And we already mentioned that if we flipped the coin 10000 times, the chances of seeing exactly 5000 heads is small. But in many flips, we might expect to see heads on something close to 50% of flips. Consider Figure 1.1 below. Each dot represents a set of 10,000 fair coin flips. There are 100 dots displayed, representing 100 different sets of 10,000 coin flips each. For each set of flips, the proportion of the 10,000 flips which landed on head is recorded. For example, if in one set 4973 out of 10,000 flips landed on heads, the proportion of heads is 0.4973. The plot displays 100 such proportions. We see that only 5 of these 100 proportions are less than 0.49 or greater than 0.51. So if between 0.49 and 0.51 is considered “close to 0.5”, then yes, in 10000 coin flips we would expect the proportion of heads to be close to 0.5. (In 10000 flips, the probability of heads on between 49% and 51% of flips is 0.956, so 95 out of 100 provides a rough estimate of this probability.) Figure 1.1: Proportion of flips which are heads in 100 sets of 10,000 fair coin flips. Each dot represents a set of 10,000 fair coin flips. But what if we want to be stricter about what qualifies as “close to 0.5”? You might suspect that with even more flips we would expect to observe heads on even closer to 50% of flips. Indeed, this is the case. Figure 1.2 displays the results of 100 sets of 1,000,000 fair coin flips. The pattern seems similar to Figure 1.1 but pay close attention to the horizontal axis which covers a much shorter range of values than in the previous figure. Now 96 of the 100 proportions are between 0.499 and 0.501. So in 1,000,000 flips we would expect the proportion of heads to be between 0.499 and 0.501, pretty close to 0.5. (In 1,000,000 flips, the probability of heads on between 49.9% and 50.1% of flips is 0.955, and 96 out of 100 sets provides a rough estimate of this probability.) Figure 1.2: Proportion of flips which are heads in 100 sets of 1,000,000 fair coin flips. Each dot represents a set of 1,000,000 fair coin flips. In Figure 1.3 each dot represents a set of 100 millions flips. The pattern seems similar to the previous figures, but again pay close attention the horizontal access which covers a smaller range of values. Now 96 of the 100 proportions are between 0.4999 and 0.5001. (In 100 million flips, The probability of heads on between 49.99% and 50.01% of flips is 0.977, so 96 out of 100 sets provides a rough estimate of this probability.) Figure 1.3: Proportion of flips which are heads in 100 sets of 100,000,000 fair coin flips. Each dot represents a set of 100,000,000 fair coin flips. The previous figures illustrate that the more flips there are, the more likely it is that we observe a proportion of flips landing on heads close to 0.5. We also see that with more flips we can refine our definition of “close to 0.5”: increasing the number of flips by a factor of 100 (10,000 to 1,000,000 to 100,000,000) seems to give us an additional decimal place of precision (\\(0.5\\pm0.01\\) to \\(0.5\\pm 0.001\\) to \\(0.5\\pm 0.0001\\).) These observations illustrate the relative frequency interpretation of probability. The probability of an event corresponding to the result of a random phenomenon can be interpreted as the proportion of times that the event would occur in a very large number of hypothetical repetitions of the random phenomenon. That is, a probability can be interpreted as a long run proportion or long run relative frequency. This means that the probability of an event can be approximated by simulating the random phenomenon a large number of times and determining the proportion of simulated repetitions on which the event occurred out of the total number of repetitions of the simulation (this proportion is also called the relative frequency of the event.) A simulation involves an artificial recreation of the random phenomenon, usually using a computer. For example, if a basketball player is successful on 90% of her free throw attempts, we can simulate the player shooting a single free throw attempt by taking 10 cards and labeling 9 as “success” and 1 as “miss” then shuffling well and dealing one card. The long run relative frequency interpretation of probability can be applied when a situation can be repeated numerous times, at least conceptually, and the outcome can be observed each time. The relative frequency of a particular event will settle down to a single constant value after many repetitions, and that long run value is the probability of that event. However, what constitutes the random phenomenon or how the simulation is conducted depends on certain assumptions. Changing those assumptions can affect probabilities of interest. For example, if you’re interested in the probability that a die lands on 1, you need to know if it’s a four-sided die or a six-sided die, and if the die is consider “fair”. As a more complicated example, simulating the outcome of the next Superbowl involves many assumptions 1.2.2 Subjective probability The relative frequency interpretation is natural in scenarios 1 through 8 of Exercise 1.1. We can consider as repeateable situations like flipping a coin, drawing powerballs from a bin, or selecting a student at random. On the other hand, it is difficult to conceptualize scenarios 8 through 13 of Exercise 1.1 as relative frequencies. Superbowl 2020 will only be played once, the 2020 U.S. Presidential Election will only be conducted once (we hope), and there was only one April 17, 2009 on which you either did or did not eat an apple. But while these situations are not naturally repeatable they still involve randomness (uncertainty) and it is still reasonable to assign probabilities. At this point in time, the Chargers are less likely than the Patriots (ugh) to win Superbowl 2020, Donald Trump is more likely than Dwayne Johnson to win the U.S. 2020 Presidential Election, and if you’ve always been an “apple-a-day” person, there’s a good chance you ate one on April 17, 2009. So it still makes sense to talk about probability in uncertain, but not necessarily repeated situations. However, the meaning of probability does seem different in scenarios 9 through 13 compared to 1 through 8. Consider Superbowl 2020. As of Sept 16, According to fivethirtyeight.com, the Patriots have a 19% chance of winning the Superbowl, the highest of any team, while the Chargers have a 4% chance. According to footballoutsider.com, the Patriots have a 26% chance of winning the Superbowl, the highest of any team, while the Chargers have a 6% chance. According to playoffstatus.com the Patriots have a 7% chance of winning the Superbowl, behind the Chiefs and Packers at 9% each, while the Chargers have a 3% chance. All three websites, as well as many others, ascribe different probabilities to the Patriots or Chargers winning. Which website, if any, is correct? In the coin flipping example, we could perform a simulation to see that the long run relative frequency is 0.5. However, simulating Superbowl 2020 involves first simulating the 2019 season to determine the playoff matchups, then simulating the playoffs to see which teams make the Superbowl, then simulating the Superbowl matchup itself. And simulating the 2019 involves simulating all the weekly matchups and potential injuries and their effects. Even just simulating a single game involves many assumptions; differences in opinions with regards to these assumptions can lead to different probabilities. For example, according to fivethirtyeight, the Chiefs have a 69% chance of beating the Ravens on Sept 22, but according to pickingpros.com it’s only 52%. Unlike in the coin flipping problem, there is no single set of rules for running the simulation, and there is no single relative frequency that determines the probability. Therefore, in a situation like forecasting the Superbowl we consider subjective probability. There are many situations where the outcome is uncertain, but it does mnot make sense to consider the situation as repeatable. In such situations, a subjective (a.k.a. personal) probability describes the degree of likelihood a given individual ascribes to a certain event. As the name suggests, different individuals might have different subjective (personal) probabilities for the same event. In contrast to the long run relative frequency situation, in which the probability is agreed to be defined as the long run relative frequency. The fivethirtyeight NFL predictions are the output of a probabilistic forecast. Probabilistic forecasts combine observed data and statistical models to make predictions. Rather than providing a single prediction (such as “the Patriots will win Superbowl 2020”), probabilistic forecasts provide a range of scenarios and their relative likelihoods. Be sure to make a distinction between assumption and observation. Probabilities are usually defined as decimals, but are often colloquially referred to as percentages. We’re not sticklers; we’ll refer to probabilities as decimals and as percentages.↩︎ We will see how to compute probabilities like this one in upcoming chapters.↩︎ If a “sequence” is defined with the powerball as the last number in the sequence, then the probability is about 21 out of 300 million. Since the powerball must be a number from 1 to 26, there are only 21 tickets out of 300 million possibilities for which the numbers are in an ordered sequence: 1-2-3-4-5-(6), 2-3-4-5-6-(7), … 21-22-23-24-25-(26).↩︎ "],
["proportional-reasoning-and-tables-of-counts.html", "1.3 Proportional reasoning and tables of counts", " 1.3 Proportional reasoning and tables of counts In general, knowing probabilities of individual events alone is not enough to determine probabilities of combinations of them. Two-way tables (a.k.a. contingency tables) of counts are a useful tool for probability problems dealing with two events. For the purposes of constructing the table and computing related probabilities, any value can be used for the hypothetical total count (as long as you don’t round numbers in between). Suppose we are interested in the relationship between income and college graduation rates at Cal Poly. Consider the sample space \\(S = \\{\\text{all current Cal Poly students}\\}\\). Suppose that the probability6 that a (randomly selected) Cal Poly student graduates within six years is 0.75, and that the probability that a (randomly selected) Cal Poly student has a Pell grant (for low income students) is 0.2. Do we have enough information to find the probability that a Cal Poly student both has a Pell Grant and graduates within six years? Without knowing any other information, what is the largest value the probability in (a) could possibly be? Under what conditions is this value attained? Set up a two-way table corresponding to this scenario. Without knowing any other information, what is the smallest value the probability in (a) could possibly be? Under what conditions is this value attained? Set up a two-way table corresponding to this scenario. Suppose that the probability that a Cal Poly student both has a Pell Grant and graduates within six years is 0.11. Construct the corresponding two-way table. Find the probability that a Cal Poly student does not have a Pell Grant and graduates within six years. Donny says “75% of CP students graduate within six years while 20% of CP students have a Pell Grant. So 95% of Cal Poly students graduate within six years or have a Pell Grant.” Do you agree? What would need to be true in order for the Donny’s statement in the previous part to be true? These number are estimates based on data from https://projects.propublica.org/colleges/schools/california-polytechnic-state-university-san-luis-obispo↩︎ "],
["consistency.html", "1.4 Working with probabilities", " 1.4 Working with probabilities In the previous section we saw two different interpretations of probability: relative frequency and subjective. Fortunately, the mathematics of probability work the same way regardless of the interpretation. Also, even with subjective probabilities it is helpful to consider what might happen in a simulation. 1.4.1 Consistency requirements With either the relative frequency or personal probability interpretation there are some basic logical consistency requirements7 which probabilities need to satisfy. Example 1.1 As of Sept 18, the website fivethirtyeight.com listed the following probabilities for who will win the 2019 World Series. Houston Astros 25% Los Angeles Dodgers 21% ew York Yankees 20% tlanta Braves 8% Is the relative frequency or subjective probability interpretation more appropriate here? According to the site, what must be the probability that the Houston Astros do not win? According to this site, what must be the probability that one of the above four teams is the World Series champion? According to this site, what must be the probability that a team other than the above four teams is the World Series champion? Solution. to Example 1.1 It is more appropriate to think of the probabilities themselves in application as subjective. Different websites or models could reasonably assign other probabilities to the teams. However, we can still imagine the probabilities as relative frequencies, if it helps our intuition. If we think of this as a simulation, each repetition results in a World Series champion and in the long run the Astros would be the champion in 25% of repetitions. Either the Astros win or they don’t; if there’s a 25% chance that the Astros win, there must be a 75% chance that they do not win. If we think of this as a simulation, each repetition results in either the Astros winning or not, so if they win in 25% of repetitions, they must not win in the other 75% to account for 100% of the repetitions. There is only one World Series champion, so if say the Astros win then no other team can win. Thinking again of a simulation, the repetitions in which the Astros win are distinct from those in which the Dodgers win. So if the Astros win in 25% of repetitions and the Dodgers wins in 21% repetitions, then on a total of 46% of repetitions either the Astros or Dodgers win. Adding the four probabilities, we see that the probability that one of the four teams above wins must be 74%. Either one of the four teams above wins, or some other team wins. If there is a 74% chance that the winner is one of the four teams above, then there must be a 26% chance that the winner is not one of these four teams. 1.4.2 Odds The words “probability”, “chance”, “likelihood”, and “odds” are colloquially treated as synonyms. However, in the mathematical language of probability, odds provide a different way of reporting a probability. Rather than reporting probability on a 0% to 100% scale, odds report probabilities in terms of ratios. Example 1.2 In Example 1.1 the odds that the Astros win the World Series are 3 to 1 against. What do you think that “3 to 1 against” means? What are the odds of the Astros not winning? What are the odds of the Yankees winning? What are the odds of the Braves winning? Solution. to Example 1.2 The probability that the Astros win is 0.25, so the probability that they do not win is 0.75. These numbers are in a 3 to 1 ratio: the probability of not winning (0.75) is 3 times greater than the probability of winning (0.25). So the odds against the Astros winning the World Series are 3 to 1; “against” because the Astros are less likely to win than to not win. The probabilities are still in the 3 to 1 ratio, but we can say that the odds are 3 to 1 in favor of the Astros not winning. The probability that the Yankees win is 0.2 and that they don’t win is 0.8, and \\(0.8/0.2 = 4\\)). So the odds are 4 to 1 against the Yankees winning (“against” because the Yankees are less likely to win than to not win). The probability that the Braves win is 0.08 and that they don’t win is 0.92, and \\(0.92/0.08 = 11.5\\)). So the odds are 11.5 to 1, or 23 to 2, against the Braves winning (“against” because the Braves are less likely to win than to not win). The odds of an event is a ratio involving the probability that the event occurs and the probability that the event does not occur \\[ \\begin{aligned} \\text{odds in favor} &amp; = \\frac{\\text{probability that the event occurs}}{\\text{probability that the event does not occur}} \\\\ &amp; \\\\ \\text{odds against} &amp; = \\frac{\\text{probability that the event does not occur}}{\\text{probability that the event occurs}}\\end{aligned} \\] In many situations (e.g., gambling) odds are implicitly reported as odds against. Odds are usually expressed as whole numbers, e.g., 11 to 1, 7 to 2. Ron and Leslie make the following bet. If Boston wins, Leslie will pay Ron $200; if not, Ron will pay Leslie $100. If both consider this to be a fair bet, what have they agreed that the probability that Boston wins is? The odds of a fair bet on whether or not an event will occur imply a probability for the event \\[\\text{probability that event occurs} = \\frac{\\text{odds in favor of the event}}{1+\\text{odds in favor of the event}}\\] 1.4.3 Dutch book Dutch book8 Odds give us one way to see why even subjective probabilities most follow basic logical consistency requirements. Example 1.3 Donny Dont is pretty sure that the Astros are going to win the World Series. He thinks their only real competition is the Braves. The following are Donny’s subjective probabilities. Houston Astros 60% Atlanta Braves 20% Other 10% In Section 2.4, we will formalize these requirements in the axioms of probability.↩︎ “Book” in the sense of a bookie taking bets↩︎ "],
["sim.html", "1.5 Approximating probabilities - a brief introduction to simulation", " 1.5 Approximating probabilities - a brief introduction to simulation Here’s a seemingly simple problem. Flip a fair coin four times and record the results in order. For the recorded sequence, compute the proportion of the flips which immediately follow a H that result in H. What value do you expect for this proportion? (If there are no flips which immediately follow a H, i.e. the outcome is either TTTT or TTTH, discard the sequence and try again with four more flips.) For example, the sequence HHTT means the the first and second flips are heads and the third and fourth flips are tails. For this sequence there are two flips which immediately followed heads, the second and the third, of which one (the second) was heads. So the proportion in question for this sequence is 1/2. So what value do you expect for this proportion? We think it’s safe to say that most people would answer 1/2. Afterall, it shouldn’t matter if a flip follows heads or not, right? We would expect half of the flips to land on heads regardless of whether the flip follows H, right? We’ll see there are some subtleties lurking behind these questions. To get an idea of what we would expect for this proportion, we could conduct a simulation: flip a coin 4 times and see what happens. Here are the results of a few repetitions; each repetition consists of an ordered sequence of 4 coin flips for which the proportion in question is measured. (Flips which immediately follow H are in bold.) Table 1.1: Simulated outcomes for 6 sets of four flips of a fair coin. Repetition | Outcome | Fl Flips that follow H | H that follow H | Pro Proportion of H following H | 1 | HHTT | 2 | 1 | 0.5 | 2 | HTTH | 1 | 0 | 0 | 3 | TTTH | 0 | NA | try again | 4 | THHH | 2 | 2 | 1 | 5 | HHTT | 2 | 1 | 0.5 | 6 | HHHT | 3 | 2 | 0.667 | We can keep repeating the above process to investigate what happens in the long run. Rather than actually flipping coins, we use a computer to run a simulation. The table and plot below summarize the results of 1,000,000 repetitions of the simulation9. While you can’t see the individual “dots” in the plot, each dot would represent a sequence of 4 coin flips (with at least one flip following a H) and the value plotted being plotted is the proportion of H following H for that sequence. The results could be summarized in a table like Table 1.1, albeit with 1,000,000 rows (after discarding rows with no flips immediately following H.) Figure 1.4: Proportion of flips immediately following Heads that result in Heads for 1,000,000 sets of 4 coin flips. (Each set has at least one flip immediately following H.) For example, the proportion in 429,123 of sets We asked the question: what would you expect for the proportion of the flips which immediately follow a H that result in H? That depends on how we define what’s “expected”. If we are interested in the value that is most likely to occur when we flip a coin four times, then the answer is 0: we see that in the long run a little over 40% of the sets resulted in a proportion of 0, while only about 30% of sets resulted in a value of 1/2. We see that the plot is not centered at 1/2; a higher percentage of repetitions resulted in a proportion below 1/2 than above 1/2. We think that most people would find this surprising. Another way to interpret “expected” is as “average”. Just as probability can be interpreted as long run relative frequency, there is a concept called expected value which can be interpreted as the long run average value. After 1,000,000 repetitions, each involving a set of four fair coin flips, we have 1,000,000 simulated values of the proportion of H following H, as recorded in the rightmost column of Table 1.1. We could then average these values: add up the values in the column and divide by 1,000,000. It turns out that average value is 0.405, which is not 1/2. Again, we think most people find this surprising. A quick note: the term “expected value” is somewhat of a misnomer. We are not saying that if we flip a coin four times we would expect the proportion of H following H for that set of flips to be 0.405. In fact, the simulation shows that on any single set of four fair coin flips, the only possible values for the proportion of H following H are 0, 1/2, 2/3, and 1. So in a set of four coin flips it’s not possible to see a proportion of 0.405. Rather, 0.405 is the average value of the proportion of H following H that we would expect to see in the long run over many sets of four fair coin flips. We will return to this idea later. We will return to this example several times throughout the book to investigate these results more closely. For now, just observe that The study of probability can involve some subtleties and our intuition isn’t always right. Simulation is an effective way of investigating probability problems, and can reveal interesting and suprising patterns. In MS coin - add statement about probability of H after H versus proportion of H after H Section XXX covers how to program the simulation and analyze the results.↩︎ "],
["sliding-scale-of-probability-or-probability-of-what.html", "1.6 Sliding scale of probability, or Probability of what?", " 1.6 Sliding scale of probability, or Probability of what? Here’s a funny series of cartoons What does 1/million mean? At least one, etc. xkcd/538 benchmarks, put in benchmarks (one in a million, a billion, etc) probability of coincidences "],
["common-misinterpretation-and-fallacies-e-g-outbreak-of-asian-disease-utts-book.html", "1.7 Common misinterpretation and fallacies (e.g. outbreak of Asian disease, Utts book)", " 1.7 Common misinterpretation and fallacies (e.g. outbreak of Asian disease, Utts book) Sally Clark? Allais paradox? A famous study10 by Kahneman and Tversky presented a group of people with the following scenario. \"Imagine that the U.S. is preparing for the outbreak of an unusual Asian disease, which is expected to kill 600 people. Two alternative programs to combat the disease have been proposed. Assume that the exact scientific estimate of the consequences of the programs are as follows: If Program A is adopted, 200 people will be saved. If Program B is adopted, there is 1/3 probability that 600 people will be saved, and 2/3 probability that no people will be saved. Which of the two programs would you favor?\" Which of these two options, A or B, would you choose? Of the 152 participants, a large majority (72%) favored one of the options; which one do you think it was? A second group was presented with the same set up, but the following options instead of A/B. If Program C is adopted 400 people will die. If Program D is adopted there is 1/3 probability that nobody will die, and 2/3 probability that 600 people will die. Which of these two options, C or D, would you choose? Of the 155 participants, a large majority (78%) favored one of the options; which one do you think it was? Compute the expected number of people who die and who are saved with Program D. Compute the expected number of people who die and who are saved with Program B. Compare options A and C. Are these the same? How about B and D? Do the risk preferences depend on the wording of how the information is presented? Many studies have shown that human intuition does not generally deal well with issues of uncertainty. So it’s worthwhile to take a careful study Example 1.4 (Monty Hall problem) MOnty Hall in CHpater 1??? Source: https://www.ncbi.nlm.nih.gov/pubmed/7455683↩︎ "],
["why-study-coins-dice-cards-and-spinners.html", "1.8 Why study coins, dice, cards, and spinners?", " 1.8 Why study coins, dice, cards, and spinners? Many probability problems involve “toy” situations like flipping coins, rolling dice, shuffling cards, or spinning spinners. These situations might seem unexciting, or at least not very practically meaningful. However, coins and spinners and the like provide familiar, concrete situations which facilitate understanding of probability concepts. Furthermore, simple situations often provide insight into real and complex problems. The following is just one illustration. Many basketball players and fans alike believe in the “hot hand” phenomenon: the idea that making several shots in a row increases a player’s chances of making the next shot. However, the consensus conclusion of thirty years of studies on the hot hand, beginning with the seminal study Gilovich, Vallone, and Tversky (1985), had been that there is no statistical evidence that the hot hand in basketball is real. As a result, many statisticians regularly caution against the “hot hand fallacy”: the belief that the hot hand exists when, in reality, the degree of streaky behavior typically observed in sequential data is consistent with what would be expected simply by chance in independent trials. The idea behind studies like Gilovich, Vallone, and Tversky (1985) is essentially the following. Consider a player who attempts 100 shots and makes 50%. If there is no hot hand, then we might expect the player to make 50% of shots both on attempts that follow hit streaks — usually considered three (or more) made attempts in a row — and on other attempts. Therefore, a success rate of 50% on both sets of attempts provides no evidence of the hot hand. However, recent research of Miller and Sanjurjo (2018a), Miller and Sanjurjo (2018c), Miller and Sanjurjo (2018b) concludes that previous studies on the hot hand in basketball, starting with Gilovich, Vallone, and Tversky (1985), have been subject to a bias. After correcting for the bias, the authors find strong evidence in favor of the hot hand effect in basketball shooting, suggesting the hot hand fallacy is not a fallacy after all. One interesting aspect of these studies is that Miller and Sanjurjo’s methods are simulation-based. Miller and Sanjurjo (2018a) introduced the coin flipping problem in Section 1.5 to illustrate the idea behind their research and the bias in previous studies. Consider again a player who attempts 100 shots and makes 50%. Even if there is no hot hand, Miller and Sanjurjo show that we would actually expect the player to have a shooting percentage of strictly less than 50% on the attempts which followed streaks, and strictly greater than 50% on the other attempts. The reason is the same as for the coin flipping problem in Section 1.5: in a fixed number of trials, the proportion of H on trials following H is expected to be less than the true probability of H, even though the trials are independent. Therefore, for the example player a success rate of 50% on both sets of attempts actually provides directional evidence in favor of the hot hand. Properly acccounting for this bias leads to substantially different statistical analyses (i.e., p-values) and conclusions. References "],
["list-of-recurring-examples.html", "1.9 List of recurring examples", " 1.9 List of recurring examples Add references/links to throughout text when book is finished. Example 1.5 Roll a four-sided die11 twice. What can we say about the sum of the two rolls? The larger of the two rolls? This is an admittedly uninteresting example, but we will use this simple example to introduce many of the ideas in a relatively straightforward setting. Example 1.6 Why four-sided? Simply to make the number of possibilities a little more manageable (e.g., for in-class simulation activities). Rolling a four-sided die twice yields 16 possible pairs, while rolling a six-sided die yields 36 possible pairs.↩︎ "],
["probmath.html", "Chapter 2 The Language of Probability", " Chapter 2 The Language of Probability A phenomenon is random if there are multiple potential outcomes, and there is uncertainty about which outcome will occur. This chapter introduces the fundamental terminology and objects of random phenomena, including Possible outcomes of the random phenomenon Related events that could occur Random variables which measure numeric quantities based on outcomes Probability measures which assign likelihoods to events in a logically coherent way Probability spaces which put it all together Full disclosure: many of the examples in this chapter involve rather dry tasks like discussing mathematical notation or listing elements of sets. Also, some of the things we do in these examples are rarely done in practice. So why bother? Many common mistakes in solving probability problems arise from misunderstanding of the foundational objects of probability. We hope that concrete — though sometimes uninteresting — examples foster understanding of fundamental concepts. This chapter introduces what the fundamental objects of probability are, but not yet how to solve probability problems. Don’t worry; we’ll solve many interesting problems in the remaining chapters. Think of this chapter as introducing the “language” or “grammar” of probability. When first learning to write, we learn the basic elements of sentences: subjects, predicates, clauses, modifiers, etc. Understanding these fundamental building blocks is essential to learning how to write well, even if we don’t explicitly identify the subject, the verb, etc., in every sentence we write. Likewise, understanding the language of probability is crucial to learning how to solve probability problems, even if the language is sometimes unspoken. "],
["samplespace.html", "2.1 Sample space of outcomes", " 2.1 Sample space of outcomes Probability models can be applied to any situation in which there are multiple potential outcomes and there is uncertainty about which outcome will occur. Due to the wide variety of types of random phenomena, an outcome can be virtually anything: the result of a coin flip the results of a sequence of coin flips a shuffle of a deck of cards the weather conditions tomorrow in your city the path of a particular Atlantic hurricane the closing price of a certain stock tomorrow the result of a diagnostic medical test a sample of car insurance polices a sample of registered voters the result of an election the next World Series champion a play in a basketball game And on and on. In particular, an outcome does not have to be a number. Before the random phenomenon occurs it is unknown which outcome will be the result. When the phenomenon takes place, a particular outcome is observed. The first step in defining a probability model for a random phenomenon is to describe the possible outcomes. Definition 2.1 The sample space, denoted12 \\(\\Omega\\) (the uppercase Greek letter “omega”), is the set of all possible outcomes of a random phenomenon. An outcome, denoted \\(\\omega\\) (the lowercase Greek letter “omega”), is an element of the sample space: \\(\\omega\\in\\Omega\\). Mathematically, the sample space \\(\\Omega\\) is a set containing all possible outcomes, while an individual outcome \\(\\omega\\) is a point or element in \\(\\Omega\\). The symbol \\(\\omega\\) denotes a generic outcome, much like the symbol \\(u\\) in \\(\\sqrt{u}\\) denotes a generic input to the square root function. For example, the simplest random phenomena have just two distinct outcomes, in which case the sample space is just a set with two elements, e.g. \\(\\Omega=\\{\\text{no}, \\text{yes}\\}\\), \\(\\Omega=\\{\\text{off}, \\text{on}\\}\\), \\(\\Omega=\\{0, 1\\}\\), \\(\\Omega=\\{-1, 1\\}\\). For example, the sample space for a single coin flip could be \\(\\Omega = \\{H, T\\}\\). If the coin lands on heads, we observe the outcome \\(\\omega = H\\); if tails we observe \\(\\omega=T\\). A random phenomenon is modeled by a single sample space, upon which all objects are defined. These objects, which we will encounter later, include events and random variables. Whenever possible, a sample space outcome should be defined to provide the maximum amount of information about the outcome of random phenomenon. In the following examples we will describe the sample space by listing all possible outcomes. However, constructing a list of all possible outcomes is rarely done in practice. We do so here only to provide some concrete examples of sample spaces. While a random phenomenon always has a corresponding sample space, in many situations the sample space of outcomes is at best only vaguely specified and can not be feasibly enumerated. Example 2.1 Roll a four-sided die13 twice, and record the result of each roll in sequence as an ordered pair. For example, the outcome \\((3, 1)\\) represents a 3 on the first roll and a 1 on the second; this is not the same outcome as \\((1, 3)\\). Identify the sample space. We might be interested in the sum of the two dice. Explain why it is still advantageous to define the sample space as in the previous part, rather than as \\(\\Omega=\\{2, \\ldots, 8\\}\\). Solution. to Example 2.1 The sample space consists of 16 possible ordered pairs of rolls \\[\\begin{align*} \\Omega &amp; = \\{(1, 1), (1, 2), (1, 3), (1, 4),\\\\ &amp; \\qquad (2, 1), (2, 2), (2, 3), (2, 4),\\\\ &amp; \\qquad (3, 1), (3, 2), (3, 3), (3, 4),\\\\ &amp; \\qquad (4, 1), (4, 2), (4, 3), (4, 4)\\} \\end{align*}\\] Any element of this set is a possible outcome \\(\\omega\\). For example, the outcome \\(\\omega = (4, 2)\\) occurs when the first roll is a 4 and the second roll is a 2. The notation above makes it clear that the sample space is a set. But it is often helpful to conceptualize or visualizing the sample space as a list or table like the following. Table 2.1: Table representing the sample space of two rolls of a four-sided die First roll Second roll 1 1 1 2 1 3 1 4 2 1 2 2 2 3 2 4 3 1 3 2 3 3 3 4 4 1 4 2 4 3 4 4 Yes, we might be interested in the sum of the two dice. But we might also be interested in other things, like the larger of the two rolls, or if at least one 3 was rolled, or the result of the first roll. Knowing just the sum of the dice does not provide as much information about the outcome of the random phenomenon as the sequence of individual rolls does. Note: In the previous example, there was a single sample space whose outcomes represented the result of the pair of rolls. In particular, there was not a separate sample space for each of the individual rolls. Now, we could have written the sample space as the Cartesian product \\(\\Omega = \\{1, 2, 3, 4\\} \\times\\{1, 2, 3, 4\\}\\), where the first \\(\\{1, 2, 3, 4\\}\\) set in the product represents the result of the first roll (and similarly for the second.) But this Cartesian product represents a single set of ordered pairs, and it is that single set which is the sample space corresponding to outcomes of the pair of rolls. Example 2.2 Consider the outcome of a sequence of 4 flips of a coin. Identify an appropriate sample space. We might be interested in the number of heads flipped. Explain why it is still advantageous to define the sample space as in the previous part, rather than as \\(\\Omega=\\{0, 1, 2, 3, 4\\}\\). Solution. to Example 2.2 We can record the outcome as an ordered sequence representing the results of the four flips. For example, HTHT means heads on the first on third flips and tails on the second and fourth; this is not the same outcome as HHTT or THTH. (We could also write (H, T, H, T) but the HTHT notation is simpler.) The sample space is the following set composed of 16 distinct outcomes \\[\\begin{align*} \\Omega &amp; = \\{HHHH, HHHT, HHTH, HTHH, THHH, HHTT, HTHT, HTTH,\\\\ &amp; \\qquad THHT, THTH, TTHH, HTTT, THTT, TTHT, TTTH, TTTT\\} \\end{align*}\\] Again, it is helpful to conceptualize and visualize the sample space as a list or a table (which we will do later when we encounter this scenario again). Yes, we might be interested in the number of heads flipped, but we might also be interested in other things, such as whether the first flip was heads, the length of the longest streak of heads in a row, or the proportion of flips following H that resulted in H. Knowing just the number of heads flipped does not provide as much information about the outcome of the random phenomenon as the sequence of individual flips does. Note: We reiterate what we said after Example 2.1. In the previous example, there was a single sample space whose outcomes were sequences of coin flips. In particular, there was not a separate sample space for each of the individual flips. We could have written the sample space as the Cartesian product \\(\\Omega = \\{H, T\\}\\times \\{H, T\\}\\times \\{H, T\\}\\times \\{H, T\\} = \\{H, T\\}^4\\). But this Cartesian product represents a single set of sequences of 4 flips, and it is this single set which is the sample space. We’ll present a few more concrete examples where we list all the outcomes in the sample space. However, keep in mind that enumerating the sample space is rarely done in practice. Example 2.3 (Matching problem) The “matching problem” is one well known probability problem. The following version is from FiveThirtyEight. A geology museum in California has four different rocks sitting in a row on a shelf, with labels on the shelf telling what type of rock each is. An earthquake hits and the rocks all fall off the shelf and get mixed up. A janitor comes in and, wanting to clean the floor, puts the rocks back on the shelf in random order. We might be interested in things like whether all the rocks are put back in the correct spot, or none are, or if the heaviest rock is put back in the correct spot. Label the rocks 1, 2, 3, 4, and also label the spots 1, 2, 3, 4, with spot 1 the correct spot for rock 1, etc. Identify an appropriate sample space. Solution. to Example 2.3 We can consider each outcome to be a particular placement of rocks in the spots. For example, the outcome 3214 (or \\((3, 2, 1, 4)\\)) represents that rock 3 is placed in spot 1, rock 2 in spot 2, rock 1 in spot 3, and rock 4 in spot 4. (We say that an outcome is a permutation (or reordering) of the numbers 1, 2, 3, 4.) So the sample space consists of the following 24 outcomes14. \\[\\begin{align*} \\Omega &amp; = \\{1234, 1243, 1324, 1342, 1423, 1432 \\\\ &amp; \\qquad 2134, 2143, 2314, 2341, 2413, 2431 \\\\ &amp; \\qquad 3124, 3142, 3214, 3241, 3412, 3421 \\\\ &amp; \\qquad 4123, 4132, 4213, 4231, 4312, 4321\\} \\end{align*}\\] Recording outcomes in this way provides more information than if we had chosen the sample space to correspond to, for example, the number of rocks that were placed in the correct spot. Example 2.4 (Collector problem) The “collector problem” is one well known probability problem. Here is one version of it. The latest series of collectible Lego Minifigures contains 3 different Minifigures. Each package contains a single unknown Minifigure. We buy packages one at a time until we have a complete collection. We might be interested in things like how many packages we needed to buy to complete the collection, or which Minifigure we have the most of. Label the different Minifigures 1, 2, and 3. Identify an appropriate sample space. Is it possible to identify a sample space in which all outcomes have the same “length”? Solution. to Example 2.4 An outcome could represent the sequence of Minifigures we obtain in order. For example, (2, 3, 3, 2, 2, 2, 3, 1) represents figure 2 in the first package, figure 3 in the second and third packages, figure 2 in the fourth, and so on, completing the collection with figure 1 in the eighth package. Outcomes recorded in this way can have different lengths if we only record the packages we buy; for example (2, 3, 1) versus (2, 3, 3, 1) versus (2, 3, 3, 2, 1). However, it is often convenient for sample space outcomes to have the same length, as in the previous examples (two die rolls, four coin flips, four rocks in spots). We can define outcomes with the same “length” if we assume the process continues indefinitely, that is, if we continue to buy packages even after we complete a set. Now an outcome is an infinite sequence, with each component of the sequence taking a value of 1, 2, or 3; for example, (2, 3, 3, 2, 2, 2, 3, 1, 2, 1, 1, 3, \\(\\ldots\\)). Thus the sample space is the set of all infinite sequences whose components take values in \\(\\{1, 2, 3\\}\\), which can be written as \\(\\Omega=\\{1, 2, 3\\}^\\infty\\). Outcomes of this sample space all have the same “length” (infinite). Moreover, this sample space allows for a broader range of questions to be investigated. For example, we might be interested in the number of packages needed to obtain 5 complete collections (which might be relevant if you have 5 kids and they all want their own collection). Example 2.5 Many statistical applications involve random sampling. For example, polling organizations often select random samples of Americans. Typically the selection involves random digit dialing: a sample of say 1000 phone numbers are randomly selected from some large bank (hundreds of millions) of phone numbers; this is the population15. An outcome would consist of the 1000 phone numbers selected; this is the sample. As an extraordinarily unrealistic, oversimplified, but concrete example, suppose the bank only contains 5 phone numbers, labeled {1, 2, 3, 4, 5}, from which 3 are selected. Describe an appropriate sample space. Note: the order in which the numbers are selected does not matter; we only care which numbers are selected. Solution. to Example 2.5 An outcome consists of a subset of size 3 from the set \\(\\{1, 2, 3, 4, 5\\}\\), representing the list of the 3 phone numbers selected. For example, outcome \\(\\{1, 4, 5\\}\\) occurs if phone numbers 1, 4, and 5 are selected. There are 10 distinct outcomes \\[ \\Omega = \\{\\{1, 2, 3\\}, \\{1, 2, 4\\}, \\{1, 2, 5\\}, \\{1, 3, 4\\}, \\{1, 3, 5\\},\\\\ \\qquad\\quad \\{1, 4, 5\\}, \\{2, 3, 4\\},\\{2, 3, 5\\},\\{2, 4, 5\\},\\{3, 4, 5\\}\\} \\] Note that the sample space is a set whose elements are sets. Also note the difference between \\(\\{1, 2, 3\\}\\) and \\((1, 2, 3)\\); \\((1, 2, 3)\\) represents an ordered sequence. There is only one set containing the elements 1, 2, and 3, the set \\(\\{1, 2, 3\\}\\), but there are six different ordered sequences containing the values 1, 2, and 3: \\((1, 2, 3), (1, 3, 2), (2, 1, 3), (2, 3, 1), (3, 1, 2), (3, 2, 1)\\). In a more realistic setting, the population would consist of hundreds of millions of phone numbers, and the sample space would be composed of all possible subsets (samples) of 1000 phone numbers. Even if the order in which the numbers are selected is irrelevant, the sample space is enormous and could never be feasibly enumerated as in this oversimplified example. But the idea is the same: an outcome consists of a subset of numbers, and the sample space is a collection of possible subsets. (That is, the sample space is a set of sets.) Example 2.6 Regina and Cady plan to meet for lunch between noon and 1 but they are not sure of their arrival times. We might be interested in questions involving whether they arrive within 15 minutes of one another, who arrives first, or how long the first person to arrive needs to wait for the second. Describe an appropriate sample space. Note: rather than dealing with clock time, it is helpful to represent noon as time 0 and measure time as fraction of the hour after noon, so that times take values in the continuous interval [0, 1]. For example, 12:15 corresponds to a time of 0.25, 12:30 to 0.5, 12:42 to 0.7. Solution. to Example 2.6 An outcome is a pair of values \\(\\omega = (\\omega_1, \\omega_2)\\) corresponding to the arrival times of (Regina, Cady). For example, the outcome (0.5, 0.7) represents Regina arriving at time 0.5 (12:30) and Cady at time 0.7 (12:42), while (0.7, 0) represents Regina arriving at time 0.7 (12:42) and Cady at time 0 (noon). The sample space is \\(\\Omega = [0,1]\\times [0,1]=[0,1]^2\\), the Cartesian product \\(\\{(\\omega_1, \\omega_2): \\omega_1 \\in [0, 1], \\omega_2 \\in [0, 1]\\}\\), the set of ordered pairs whose components take values in \\([0, 1]\\). This sample space is an uncountable set, and it is impossible to enumerate outcomes like in the previous examples. (The sample space of infinite sequences in Example 2.4 is also an uncountable set.) We can visualize the sample space as the set of points within the blue square in Figure 2.1. Figure 2.1: The square represents the sample space \\(\\Omega=[0,1]\\times[0,1]\\) in Example 2.6. Each point within the blue square is a pair of values \\(\\omega = (\\omega_1, \\omega_2)\\) corresponding to the arrival times of (Regina, Cady). A value in \\([0, 1]\\) can be visualized with a circular spinner like the one in Figure 2.2 which returns values between 0 and 1. Such a spinner can be thought of as a continuous analog of a die roll. Imagine a needle anchored at the center of the circle which is spun and eventually lands pointing at a number on the outside of the circle (like a spinner in a kids game). The values in the picture are rounded to two decimal places, but consider an idealized model where the spinner is infinitely precise and the needle infinitely fine so that any real number between 0 and 1 is a possible outcome. Under certain assumptions in the meeting time problem, we can think of Regina and Cady each spinning the spinner, with the results of the pair of spins representing the outcome \\(\\omega\\). (But under other assumptions the spinner in Figure 2.2 might not be appropriate, if for example, Regina is more likely to arrive later in the hour and Cady is more likely to arrive earlier in the hour.) Figure 2.2: A Uniform(0, 1) spinner. The values in the picture are rounded to two decimal places, but in the idealized model the spinner is infinitely precise so that any real number between 0 and 1 is a possible outcome. In the previous example, outcomes were measured on a continuous scale; any real number between 0 and 1 was a possible arrival time (or a possible result of a spin). In practice we might round the arrival time to the nearest minute or second, but in principle and with infinite precision any real number in the continuous interval \\([0, 1]\\) is possible. Furthermore, even in situations where outcomes are inherently discrete, it is often more convenient to model them as continuous. For example, if an outcome represents the annual salary in dollars of a randomly selected U.S. household, it would be more convenient to model the sample space as the continuous interval16 \\([0, \\infty)\\) rather than \\(\\{0, 1, 2, \\ldots\\}\\) or \\(\\{0, 0.01, 0.02, \\ldots\\}\\). Example 2.7 Select a U.S. high school student and record the student’s SAT Math and Reading scores. Identify an appropriate sample space. Solution. to Example 2.7 An outcome will be an ordered pair representing (Math, Reading) score. Technically, possible scores are 200 through 800 in increments of 10. So we could consider the sample space to be \\(\\{200, 210, 220, \\ldots, 790, 800\\}\\times \\{200, 210, 220, \\ldots, 790, 800\\}\\). However, we could also model scores on a continuous scale, taking any value in the interval from 200 to 800. In this case, the sample space would be \\(\\Omega = [200, 800] \\times [200, 800]\\). This sample space could be represented in a square like the one in Figure 2.1, but with Math score on the horizonal axis, Reading score on the vertical, and axis limits of \\([200, 800\\) instead of \\([0, 1]\\). A continuous specification of a sample space is often more convenient mathematically than a discrete one. In the previous examples, the sample space could be defined rather explicitly, either by direct enumeration or using set notation (like a Cartesian product). However, explicitly defining a sample space in a compact way is often not possible, as in the following example. Example 2.8 Customers enter a deli and take a number to mark their place in line. When the deli opens the counter starts 0; the first customer to arrive takes number 1, the second 2, etc. We record the counter over time, continuously, as it changes as customers arrive. Time is measured in minutes after the deli opens (time 0). A sample space outcome could be represented as a path of the value of the counter over time; a few such paths are illustrated in Figure 1.2. Notice the stairstep feature: a customer arrives and takes a number then the counter stays on that number for some time (the flat spots) until another customer arrives and the counter increases by one (the jumps). In other words, an outcome is a nondecreasing function mapping the time interval \\([0, \\infty)\\) to nonnegative integers \\(\\{0, 1, 2, \\ldots\\}\\), that only jumps by one unit at a time. The sample space consists of all possible functions of this form. Figure 2.3: Sample space outcomes for Example 2.8. Left: a single sample path of the number of customer arrivals over time. Right: several possible paths. Any random phenomenon has a corresponding sample space but in some situations explicitly defining a outcome is not feasible. For example, consider a single play in a basketball game. The SportsVU system uses cameras in arenas to record NBA games. The outcome of a single play might look like the following video. In order to describe such an outcome, we need to specify (among other things): the location of each player and the ball, the passer and receiver of each pass, the defensive assignments, the location and shooter of each shot attempt and its result, and how it all evolves over time. Representing all of this information in a compact way to define an outcome is virtually impossible. Regardless, the sample space is still there in the background, whether we specify it or not. Without a sample space representing what is possible, we would not be able to assess the relative likelihood of, say, a play resulting in a made three point field goal. 2.1.1 Summary The sample space is the set of all possible outcomes of a random phenomenon. Outcomes can take a wide variety of forms. In particular, outcomes do not need to be numbers. Whenever possible, a sample space outcome should be defined to provide the maximum amount of information about the outcome of random phenomenon. In practice we rarely enumerate the sample space as we did for some of the examples in this section. Nonetheless, there is always some underlying sample space corresponding to all possible outcomes of the random phenomenon. Even though the sample space often plays a background role, it is important to first consider what is possible before determining what is probable. The sample space essentially defines the denominator in probability calculations. Considering the sample space can help distinguish between “what is the probability this happens to me?” and “what is the probability this happens to someone somewhere sometime?” (as discussed in Section XXX.) There is no one set of universally agreed on notation, but \\(\\Omega\\) is commonly used to represent a sample space. It is also common practice to use uppercase and lowercase letters to denote different objects.↩︎ Why four-sided? Simply to make the number of possibilities a little more manageable (e.g., for in-class simulation activities). Rolling a four-sided die twice yields 16 possible pairs, while rolling a six-sided die yields 36 possible pairs.↩︎ There are 4 rocks that could potentially go in spot 1, then 3 rocks that could potentially go in spot 2, 2 to spot 3, and 1 left for spot 4. This results in \\(4\\times3\\times2\\times1=4! = 24\\) possible outcomes. We will see more counting rules in XXXX.↩︎ Technically, the bank of phone numbers is the sampling frame while the population is all Americans. The population and the sampling frame need not be the same.↩︎ We could also try \\((0, m)\\) where \\(m\\) is some large dollar amount providing an upper bound on the maximum possible salary. But we would need to be sure that \\(m\\) is large enough so that all possible outcomes are in the sample space \\((0, m)\\). Without knowing this bound in advance, it is convenient to just choose the unbounded interval \\((0, \\infty)\\). There is really no harm in making the sample space bigger than it needs to be, but you can run into problems if you make it too small.↩︎ "],
["events.html", "2.2 Events", " 2.2 Events An event is something that could happen. For example, if we’re interested in the weather conditions in our city tomorrow, events include “the high temperature is 75°F” “the high temperature is above 75°F” “it rains” “it does not rain” “it rains and the high temperature is above 75°F” An outcome consists of all the information about tomorrow’s weather conditions, while an event is a collection of outcomes that satisfy some criteria. Definition 2.2 An event \\(A\\) is a subset of the sample space: \\(A\\subseteq \\Omega\\). If the random phenomenon yields outcome \\(\\omega\\), we say “event \\(A\\) occurred” if \\(\\omega\\in A\\). The collection of all events of interest17 is denoted \\(\\mathcal{F}\\). The sample space is the collection of all possible outcomes. An event represents only those outcomes which satisfy some criteria. Events are typically denoted with capital letters near the start of the alphabet, with or without subscripts (e.g. \\(A\\), \\(B\\), \\(C\\), \\(A_1\\), \\(A_2\\)). Events can be composed from others using basic set operations like unions (\\(A\\cup B\\)), intersections (\\(A \\cap B\\)), and complements (\\(A^c\\)). Read \\(A^c\\) as “not” \\(A\\). Read \\(A\\cap B\\) as “\\(A\\) and \\(B\\)” Read \\(A \\cup B\\) as “\\(A\\) or \\(B\\)”. Note that unions (\\(\\cup\\), “or”) are always inclusive. \\(A\\cup B\\) occurs if \\(A\\) occurs but \\(B\\) does not, \\(B\\) occurs but \\(A\\) does not, or both \\(A\\) and \\(B\\) occur. Example 2.9 Roll a four-sided die twice, and record the result of each roll in sequence. Using the sample space from Example 2.1, identify the following events. \\(A\\), the event that the sum of the two dice is 4. \\(B\\), the event that the sum of the two dice is at most 3. Donny Don’t says “we should just consider the sample space to be \\(\\{2, \\ldots, 8\\}\\)” so that \\(A = 4\\) and \\(B = \\{2, 3\\}\\). Do you agree? (Also, can you spot the subtle mistake that Donny made?) Identify \\(C\\), the event that the larger of the two rolls (or the common roll if a tie) is 3 Identify and interpret \\(A\\cap C\\). Donny Don’t says that \\(D\\), the event that the first roll is a 3, is \\(D=\\{3\\}\\). Explain to Donny his mistake, and identify event \\(D\\). Identify \\(E\\), the event that the second roll is a 3. Identify and interpret \\(D \\cap E\\). Identify and interpret \\(D \\cup E\\). If the outcome is \\((1, 3)\\), which of the events above occurred? Solution. to Example 2.9 Remember that the sample space consists of 16 possible ordered pairs of rolls \\[\\begin{align*} \\Omega &amp; = \\{(1, 1), (1, 2), (1, 3), (1, 4),\\\\ &amp; \\qquad (2, 1), (2, 2), (2, 3), (2, 4),\\\\ &amp; \\qquad (3, 1), (3, 2), (3, 3), (3, 4),\\\\ &amp; \\qquad (4, 1), (4, 2), (4, 3), (4, 4)\\} \\end{align*}\\] (See also Table 2.1.) All events must be defined as subsets of this sample space. So \\(A=\\{(1, 3), (2, 2), (3, 1)\\}\\) is the event that the sum of the two dice is 4. \\(B=\\{(1, 1), (1, 2), (2, 1)\\}\\) is the event that the sum of the two dice is at most 3. Tell Donny it’s better to use the sample space from Example 2.1 since we might be interested in events other than ones that involve the sum of the dice, like those in the following parts. Knowing just the sum of the dice does not provide enough information to investigate events like whether the larger of the two rolls is a 3. (Donny has also made a subtle mistake in writing \\(A = 4\\). An event is always a set, even if it contains just a single outcome. Given Donny’s sample space, he should have written \\(A = \\{4\\}\\).) \\(C=\\{(1, 3), (2, 3), (3, 1), (3, 2), (3, 3)\\}\\), the event that the larger of the two rolls (or the common roll if a tie) is 3 \\(A\\cap C=\\{(1, 3), (3, 1)\\}\\) is the event that both the sum of the two dice is 4 and the larger of the two rolls is 3. Tell Donny that each outcome in the sample space consists of a pair of rolls, so we must account for both rolls in defining events, even if the event of interest involves just the first roll. (Remember, there is always a single sample space upon which all events are defined.) \\(D=\\{(3, 1), (3, 2), (3, 3), (3, 4)\\}\\) is the event that the first roll is a 3. \\(E=\\{(1, 3), (2, 3), (3, 3), (4, 3)\\}\\), the event that the second roll is a 3. Note that this is not the same event as \\(D\\). \\(D \\cap E = \\{(3, 3)\\}\\) is the event that both rolls result in a 3. That is, (3, 3) is the only outcome that satisfies both events \\(D\\) and \\(E\\). While an event is always a set, it can be a set consisting of a single outcome (or the empty set). \\(D \\cup E = \\{(3, 1), (3, 2), (3, 3), (3, 4), (1, 3), (2, 3), (4, 3)\\}\\) is the event that at least one of the two rolls results in a 3. Notice that the union is inclusive: \\((3, 3)\\), the outcome that satisfies both \\(D\\) and \\(E\\), is an element of \\(D\\cup E\\). But also notice that the outcome \\((3, 3)\\) only appears once in the set \\(D \\cup E\\). If the outcome is \\((1, 3)\\) then events \\(A\\), \\(C\\), \\(A\\cap C\\), \\(E\\), \\(D\\cup E\\) all occur. Events \\(B,\\) \\(D,\\) and \\(D\\cap E\\) do not occur. We reiterate (again!) that there is a single sample space, upon which all events are defined. In the above example, events that involved only the first or second roll such as \\(D\\) and \\(E\\) were still defined in terms of pairs of rolls. An outcome in a sample space should be defined to record as much information as possible so that the occurrence or non-occurrence of all events of interest can be determined. While an event is always a set, it can be a set consisting of a single outcome, or a set consisting of no outcomes at all (the empty set \\(\\emptyset\\)). Definition 2.3 Two events \\(A\\) and \\(B\\) are disjoint (a.k.a. mutually exclusive) if \\(A\\cap B=\\emptyset\\). That is, \\(A\\) and \\(B\\) are disjoint if they have no outcomes in common. A collection of events \\(A_1, A_2, \\ldots\\) are disjoint (a.k.a. mutually exclusive) if \\(A_i \\cap A_j = \\emptyset\\) for all \\(i \\neq j\\). That is, multiple events are disjoint if none of the events have any outcomes in common. Example 2.10 Continuing Example 2.9. Identify two events that are disjoint. Are the events \\(A, B, C\\) disjoint? Solution. to Example 2.10 Events \\(A\\) and \\(B\\) are disjoint. It is not possible for an outcome to satisfy both criteria “the sum is 4” and “the sum is at most 3”. No, because \\(A\\cap C \\neq \\emptyset\\) since there are outcomes that satisfy both criteria “the sum is 4” and “the larger roll is 3”. Example 2.11 Consider the outcome of a sequence of 4 flips of a coin. Using the sample space from Example 2.2, identify the following events. Identify \\(A\\), the event that exactly 3 of the flips land on heads. Identify \\(B\\), the event that exactly 4 of the flips land on heads. Identify \\(C\\), the event that the at least 3 of the flips land on heads. How does \\(C\\) relate to \\(A\\) and \\(B\\)? The previous events all consider the number of heads flipped. Explain why we don’t just consider the sample space to be \\(\\{0, 1, 2, 3, 4\\}\\), so that for example \\(C = \\{3, 4\\}\\). Identify \\(D\\), the event that at least 3 heads are flipped in a row. Identify \\(E\\), the event that the first two flips results in tails. Identify \\(D\\cap E\\). If the outcome is HHTH, which of the events above occurred? Solution. to Example 2.11 \\(A = \\{HHHT, HHTH, HTHH, THHH\\}\\) is the event that exactly 3 of the flips land on heads \\(B = \\{HHHH\\}\\), the event that exactly 4 of the flips land on heads. While an event is always a set, it can be a set consisting of a single outcome. \\(C = \\{HHHT, HHTH, HTHH, THHH, HHHH\\}\\) is the event that the at least 3 of the flips land on heads. Also \\(C = A \\cup B\\). Yes, the previous events all consider the number of heads flipped, but we might be interested in events — like the ones in the following parts — whose occurrence cannot be determined simply by knowing the number of heads. The sample space should always to defined in such a way to provide enough information to investigate any relevant event of interest. There is always a single sample space upon which all events are defined. \\(D = \\{HHHT, THHH, HHHH\\}\\) is the event that at least 3 heads are flipped in a row. Note that \\(D\\) is not the same event as \\(C\\). \\(E = \\{TTHH, TTHT, TTTH, TTTT\\}\\) is the event that the first two flips result in tails. Note that each outcome consists of the results of 4 flips, so we must account for all 4 flips in defining events. There is always a single sample space upon which all events are defined. \\(D\\cap E=\\emptyset\\) so the events \\(D\\) and \\(E\\) are disjoint; it is not possible to have at least three heads in a row when the first two flips (out of 4) are tails. If the outcome is HHTH then events \\(A\\) and \\(C\\) occur. Events \\(B\\), \\(D\\), \\(E\\), and \\(D \\cap E\\) do not occur. Example 2.12 (Matching problem) Recall the “matching problem”. A geology museum in California has four different rocks sitting in a row on a shelf, with labels on the shelf telling what type of rock each is. An earthquake hits and the rocks all fall off the shelf and get mixed up. A janitor comes in and, wanting to clean the floor, puts the rocks back on the shelf in random order. We might be interested in things like whether all the rocks are put back in the correct spot, or none are, or if the heaviest rock is put back in the correct spot. Using the sample space from Example 2.3, identify the following events. \\(A\\), the event that all rocks are put in the correct spot. \\(B\\), the event that no rocks are put in the correct spot. \\(C\\), the event that exactly 3 rocks are put in the correct spot. \\(D\\), the event that rock 3 is put (correctly) in spot 3. Solution. to Example 2.12 Recall that each outcome is a particular placement of rocks in the spots. For example, the outcome 3214 (or \\((3, 2, 1, 4)\\)) represents that rock 3 is put in spot 1, rock 2 in spot 2, rock 1 in spot 3, and rock 4 in spot 4. There is only one outcome, 1234, for which all rocks are put in the correct spot, so \\(A=\\{1234\\}\\). Remember that an event is always a set, but it can be a set consisting of a single outcome. For each outcome in the sample space check to see if the criteria holds to identify \\(B=\\{2143, 2341, 2413, 3142, 3412, 3421, 4123, 4312, 4321\\}\\) as the event that no rocks are put in the correct spot. There are no outcomes in which exactly 3 rocks are put in the correct spot so \\(C=\\emptyset\\). (If three rocks are in their correct spots, then the remaining rock must be in its correct spot too.) \\(D=\\{1234, 1432, 2134, 2431, 4132, 4231\\}\\) is the event that rock 3 is put (correctly) in spot 3. Even though event \\(D\\) only concerns rock 3, since the sample space consists of the placements of each of the rocks then all events must be expressed in terms of these outcomes. When more than just a few events are of interest, subscripts are commonly used to identify different events, as in the following example. Example 2.13 In the context of Example 2.5, let \\(A_i\\) be the event that phone number \\(i\\) is selected for the sample, \\(i=1, 2, 3, 4, 5\\). Using the sample space from Example 2.5 identify the following events, both in terms of \\(A_i\\)’s and as subsets of the sample space. The event that phone number 1 is selected for the sample. The event that phone number 4 is selected for the sample. The event that phone numbers 1 and 4 are selected for the sample. The event that phone numbers 1 or 4 are selected for the sample. The event that phone numbers 1, 4, and 5 are selected for the sample. The event that phone numbers 1, 4, or 5 are selected for the sample. Solution. to Example 2.13 The event \\(A_1=\\{\\{1, 2, 3\\}, \\{1, 2, 4\\}, \\{1, 2, 5\\}, \\{1, 3, 4\\}, \\{1, 3, 5\\}, \\{1, 4, 5\\}\\}\\) consists of the samples which include phone number 1. Even though event \\(A_1\\) only concerns phone number 1, since the sample space consists of sets (samples) of size 3 then all events must be expressed in terms of these outcomes. The event \\(A_4=\\{\\{1, 2, 4\\}, \\{1, 3, 4\\}, \\{1, 4, 5\\}, \\{2, 3, 4\\}, \\{2, 4, 5\\}, \\{3, 4, 5\\}\\}\\) consists of the samples which include phone number 4. The event \\(A_1\\cap A_4=\\{\\{1, 2, 4\\}, \\{1, 3, 4\\}, \\{1, 4, 5\\}\\}\\) consists of the samples which include both phone numbers 1 and 4. The event \\(A_1\\cup A_4=\\{\\{1, 2, 3\\}, \\{1, 2, 4\\}, \\{1, 2, 5\\}, \\{1, 3, 4\\}, \\{1, 3, 5\\}, \\{1, 4, 5\\}, \\{2, 3, 4\\}, \\{2, 4, 5\\}, \\{3, 4, 5\\}\\}\\) consists of the samples which include either phone number 1 or 4 (or both). The event \\(A_1\\cap A_4\\cap A_5=\\{\\{1, 4, 5\\}\\}\\) consists of the only outcome in which phone numbers 1, 4, and 5 are selected. The event \\(A_1\\cup A_4\\cup A_5=\\Omega\\) is the event that phone numbers 1, 4, or 5 are selected for the sample. Since only two of the five numbers are not selected from the sample, at least one of the numbers 1, 4, or 5 must be included in the sample. Remember that intervals of real numbers such as \\((a,b), [a,b], (a,b]\\) are also sets, and so can also be events. For example, if an outcome is the result of a single spin of the spinner in Figure 2.2, events include \\([0, 0.5]\\), the result is between 0 and 0.5 (the needle lands in the right half of the spinner) \\([0.75, 1]\\), the result is between 0.75 and 1 (the needle lands in the northwest quarter of the spinner) \\([0.595, 0.605)\\), the result rounded to two decimal places is 0.6 \\(\\{0.6\\}\\), the result is 0.6 exactly (the needle points exactly at 0.60000000\\(\\ldots\\)) It is often helpful to conceptualize and visualize events (sets) with pictures, as in the following example. Example 2.14 Regina and Cady plan to meet for lunch between noon and 1 but they are not sure of their arrival times. Using the sample space from Example 2.6, identify the following events using both mathematical notation and symbols. (Hint: see Figure 2.1.) Identify \\(A\\), the event that Regina arrives after Cady. Identify \\(B\\), the event that either Regina or Cady arrives before 12:30. Identify \\(C\\), the event that Regina arrives at most 15 minutes after Cady (and Cady arrives first). Identify \\(D\\), the event that Regina arrives before 12:24. Solution. to Example 2.14 See Figure 2.4 for pictures. Recall that an outcome is a pair of values \\(\\omega = (\\omega_1, \\omega_2)\\) corresponding to the arrival times of (Regina, Cady), and that \\([0, 1]\\) corresponds to the one hour time interval from noon (0) to 1. \\(A = \\{(\\omega_1, \\omega_2): \\omega_1&gt;\\omega_2\\}\\) is the event that Regina arrives after Cady. (Throughout we only consider \\((\\omega_1, \\omega_2)\\) in the sample space \\([0, 1]\\times[0,1]\\); the conditions \\(0\\le \\omega_1 \\le 1, 0\\le \\omega_2 \\le 1\\) are assumed.) \\(B = \\{(\\omega_1, \\omega_2): \\omega_1&lt;0.5 \\text{ or } \\omega_2&lt;0.5\\}\\) is the event that either Regina or Cady arrives before 12:30. This event is the complement of the event that both arrive after 12:30, \\(B = ([0.5, 1]\\times[0.5, 1])^c\\). The event \\(B\\) can also be written as \\(\\{(\\omega_1, \\omega_2): \\min(\\omega_1,\\omega_2)&lt;0.5\\}\\), the event that the earlier of the two arrival times is before 12:30. \\(C = \\{(\\omega_1, \\omega_2): \\omega_2&lt;\\omega_1\\le \\omega_2+0.25\\} = \\{(\\omega_1, \\omega_2): \\omega_1 &gt; \\omega_2\\ge \\omega_1 - 0.25\\}\\) is the event that Regina arrives at most 15 minutes after Cady (and Cady arrives first). \\(D = \\{(\\omega_1, \\omega_2): \\omega_1&lt;0.4\\}\\) is the event that Regina arrives before 12:24. Even though event \\(D\\) only concerns Regina, since the sample space consists of pairs of arrival times then all events must be expressed in terms of these outcomes. Figure 2.4: Illustration of the events in Exercise 2.14. The square represents the sample space \\(\\Omega=[0,1]\\times[0,1]\\). Example 2.15 (Don’t do what Donny Don’t does.) Donny Don’t is asked a series of questions involving a pair of rolls of six-sided dice, such as “what is the event that the sum of the dice is at least 10”. Donny’s responses are below; explain to him what is wrong with his responses and help him understand the correct answers. The possible rolls are 1 through 6, so the sample space is \\(\\{1, 2, 3, 4, 5, 6\\}\\). The sum of the two dice can be 2 through 12, so the event that the sum of the two dice is at least 10 is \\(\\{10, 11, 12\\}\\). The event that the first roll is a 3 is \\(\\{3\\}\\). The event that the first roll is a 3 and the second roll is a 1 is \\(\\{3, 1\\}\\) Donny’s sample space from the first question might correspond to what dice rolling scenario? What does \\(\\{3, 1\\}\\) represent in this scenario? Solution. to Example 2.15 The questions involve a pair of rolls, so best to record an outcome as an ordered pair, e.g., (5, 2) for 5 on the first roll and 2 on the second. Therefore, the sample space would be the following set of 36 possible outcomes. \\[\\begin{align*} \\Omega = &amp; \\{ (1, 1), (1, 2), \\ldots, (1, 6),\\\\ &amp; \\;\\; (2, 1), (2, 2), \\ldots, (2, 6),\\\\ &amp; \\;\\; \\vdots\\qquad \\qquad \\quad \\cdots \\qquad \\vdots\\\\ &amp; \\;\\; (6, 1), (6, 2), \\ldots, (6, 6) \\} \\end{align*}\\] Donny’s answers to the first two parts are inconsistent, since there is always a single sample space. So if he says the answer to the first part is \\(\\{1, \\ldots, 6\\}\\), then any event must be a subset of that sample space and his answer to the second part must be wrong. Using the sample space of 36 ordered pairs from the previous answer, the correct event that the sum of the two dice is at least 10 is \\(\\{(4, 6), (5, 5), (5, 6), (6, 4), (6, 5), (6, 6)\\}\\). If Donny’s sample space in the first part had been \\(\\{2, \\ldots, 12\\}\\), corresponding to the sum of the two dice, then his answer of \\(\\{10, 11, 12\\}\\) would have been correct. However, using such a sample space, he would not have been able to answer the remaining questions (which don’t involve the sum of the rolls). There is always one sample space on which all events are defined. Donny didn’t take into account that an outcome is a pair of rolls. The correct event is \\(\\{(3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6)\\}\\), the set of all pairs of rolls for which the first roll is 3. Maybe Donny is just using bad notation here, but it sure looks like he is confusing an outcome with an event. The answer should be \\(\\{(3, 1)\\}\\), the set containing the single outcome \\((3, 1)\\). Notice that this is not the same set as \\(\\{(1, 3)\\}\\). (But the set \\(\\{3, 1\\}\\) is the same as the set \\(\\{1, 3\\}\\).) The sample space of \\(\\{1, 2, 3, 4, 5, 6\\}\\) could correspond to a single roll of a fair six-sided die. In this case, the event \\(\\{3, 1\\}\\) would be the event that the roll results in either either a 3 or a 1. (The set \\(\\{3, 1\\}\\) is the same as the set \\(\\{1, 3\\}\\).) 2.2.1 The collection of events of interest An event \\(A\\) is a set. The collection \\(\\mathcal{F}\\) of “events of interest” is a collection of sets. For the purposes of this text, \\(\\mathcal{F}\\) can be considered to be the set of all subsets of \\(\\Omega\\). As an example, consider a single roll of a four-sided die. (Don’t confuse this scenario with previous examples that involved two rolls.) The sample space consists of the four possible outcomes \\(\\Omega = \\{1, 2, 3, 4\\}\\). (Again, don’t confuse this scenario with previous examples.) Any subset of this sample space is an event. The following table lists he collection of all events (\\(\\mathcal{F}\\)), and whether they occur if the single roll results in a 3 (that is, for the outcome \\(\\omega=3\\)). Event Description Occurs upon observing outcome \\(\\omega=3\\)? \\(\\emptyset\\) Roll nothing (not possible) No \\(\\{1\\}\\) Roll a 1 No \\(\\{2\\}\\) Roll a 2 No \\(\\{3\\}\\) Roll a 3 Yes \\(\\{4\\}\\) Roll a 4 No \\(\\{1, 2\\}\\) Roll a 1 or a 2 No \\(\\{1, 3\\}\\) Roll a 1 or a 3 Yes \\(\\{1, 4\\}\\) Roll a 1 or a 4 No \\(\\{2, 3\\}\\) Roll a 2 or a 3 Yes \\(\\{2, 4\\}\\) Roll a 2 or a 4 No \\(\\{3, 4\\}\\) Roll a 3 or a 4 Yes \\(\\{1, 2, 3\\}\\) Roll a 1, 2, or 3 (a.k.a. do not roll a 4) Yes \\(\\{1, 2, 4\\}\\) Roll a 1, 2, or 4 (a.k.a. do not roll a 3) No \\(\\{1, 3, 4\\}\\) Roll a 1, 3, or 4 (a.k.a. do not roll a 2) Yes \\(\\{2, 3, 4\\}\\) Roll a 2, 3, or 4 (a.k.a. do not roll a 1) Yes \\(\\{1, 2, 3, 4\\}\\) Roll something Yes A random phenomenon corresponds to a single sample space, but there are many events of interest. Listing the collection of all possible events as in the previous table is rarely done in practice, but we do so here to provide a concrete example of \\(\\mathcal{F}\\). 2.2.2 Summary An outcome \\(\\omega\\) is a point. The sample space \\(\\Omega\\) is the set of all possible outcomes. An event \\(A\\) is a collection of outcomes that satisfy some particular criteria. That is, an event is a subset of the sample space, \\(A\\subseteq\\Omega\\). There are many events (sets) of interest associated with a random phenomenon. This collection of events (sets) is what \\(\\mathcal{F}\\) represents. All events of interest are defined in terms of a single sample space. An event can be a set consisting of a single outcome, or no outcomes at all (the empty set \\(\\emptyset\\)). Events can be composed from others using basic set operations like unions (\\(A\\cup B\\)), intersections (\\(A \\cap B\\)), and complements (\\(A^c\\)). Read \\(A^c\\) as “not” \\(A\\). Read \\(A\\cap B\\) as “\\(A\\) and \\(B\\)” Read \\(A \\cup B\\) as “\\(A\\) or \\(B\\)”. Note that unions (\\(\\cup\\), “or”) are always inclusive. \\(A\\cup B\\) occurs if \\(A\\) occurs but \\(B\\) does not, \\(B\\) occurs but \\(A\\) does not, or both \\(A\\) and \\(B\\) occur. Pictures can be used to conceptualize and visualize events. For the purposes of this text, \\(\\mathcal{F}\\) can be considered to be the set of all subsets of \\(\\Omega\\). Technically, \\(\\mathcal{F}\\) is a \\(\\sigma\\)-field of subsets of \\(\\Omega\\): \\(\\mathcal{F}\\) contains \\(\\Omega\\) and is closed under countably many elementary set operations (complements, unions, intersections). This requirement ensures that if \\(A\\) and \\(B\\) are “events of interest”, then so are \\(A\\cup B\\), \\(A\\cap B\\), and \\(A^c\\). While this level of technical detail is not needed, we prefer to introduce the idea of a “collection of events” now since a probability measure is a function whose input is an event (set) rather than an outcome (point).↩︎ "],
["rv.html", "2.3 Random variables", " 2.3 Random variables Statisticians use the terms observational unit and variable. Observational units are the people, places, things, etc., for which data are observed. Variables are the measurements made on the observational units. For example, the observational units in a study could be college students, while variables could be age, high school GPA, college GPA, SAT score, years in college, number of Statistics courses taken, etc. In probability, an outcome of a random phenomenon plays a role analogous to an observational unit in statistics. The sample space of outcomes is often only vaguely defined. In many situations we are less interested in detailing the outcomes themselves and more interested in whether or not certain events occur, or with measurements that we can make for the outcomes. For example, if the random phenomenon corresponds to randomly selecting a sample of students at a college, an outcome could be the list of students selected for the sample. But we are less interested in who the students are, and more interested in questions which involve variables, such as: what is the distribution of SAT scores? What is the relationship between high school GPA and college GPA? What is the average number of years before graduation? In probability, random variables play a role analogous to variables in statistics. Roughly, a random variable assigns a number measuring some quantity of interest to each outcome of a random phenomenon. For example, if we’re interested in the weather conditions in our city tomorrow, random variables include high temperature (°F) amount of precipitation (inches) Humidity (%) Maximum wind speed (mph) Definition 2.4 A random variable (RV) \\(X\\) is a function that takes an outcome in the sample space as input and returns a real number as output; that is, \\(X:\\Omega \\mapsto \\mathbb{R}\\). The value that the random variable \\(X\\) assigns to the outcome \\(\\omega\\) is denoted \\(X(\\omega)\\). Example 2.16 Consider the outcome of a sequence of 4 flips of a coin. One random variable is \\(X\\), the number of heads flipped. Use the sample space from Example 2.2 to answer the following. Explain why \\(X\\) is a random variable. Evaluate each of the following: \\(X(HHHH), X(HTHT), X(TTHH)\\). Identify the possible values of \\(X\\). Why not let the sample space just consist of this set of possible values? Solution. to Example 2.16 \\(X\\) maps each outcome to a number via the function “count the number of heads”. \\(X(HHHH) = 4, X(HTHT) = 2, X(TTHH) = 2\\). The possible values of \\(X\\) are \\(0, 1, 2, 3, 4\\). (Don’t forget 0.) You might ask: if we only care about the number of heads, why bother with the coin flip sequence at all? That is, why not define the sample space as \\(\\{0, 1, 2, 3, 4\\}\\) rather than \\(\\{HHHH, HHHT, HHTH, \\ldots\\}\\). The main reason18 is that recording only the number of heads would not allow us to investigate other random variables like the longest number of heads in a row, or the proportion of heads on trials that follow heads. The main reason for modeling a sample space as the set of possible outcomes rather than the set of all possible values of some random variable is that we often want to define many random variables on the same sample space, and study relationships between them. As a statistics analogy, you would not be able to study the relationship between SAT scores and college GPA unless you measured both variables for the same set of observational units. In statistics, data is often stored in a spreadsheet (or flat file) with rows corresponding to observational units and columns to variables. Likewise, in probability it helps to conceptualize or visualize a table with rows corresponding to outcomes and columns to random variables. Example 2.17 Roll a four-sided die twice, and record the result of each roll in sequence. Recall the sample space from Example 2.1. Let \\(X\\) be the sum of the two dice, and let \\(Y\\) be the larger of the two rolls (or the common value if both rolls are the same). Evaluate \\(X((1, 3))\\), \\(X((4, 3))\\), and \\(X((2,2))\\). Evaluate \\(Y((1, 3))\\), \\(Y((4, 3))\\), and \\(Y((2,2))\\). Construct a table identifying the values of \\(X\\) and \\(Y\\) for each outcome in the sample space. Identify the possible values of \\(X\\). Identify the possible values of \\(Y\\). Identify the possible values of the pair \\((X, Y)\\). Solution. to Example 2.17 \\(X\\) is the sum of the two rolls, so \\(X((1, 3))=4\\), \\(X((4, 3))=7\\), and \\(X((2,2))=4\\). \\(Y\\) is the larger of the two rolls (or the common value if a tie) so \\(Y((1, 3))=3\\), \\(Y((4, 3))=4\\), and \\(Y((2,2))=2\\). See Table 2.2. The first column corresponds to sample space outcomes, and there is a column for each random variable. Table 2.2: Table representing the sum (\\(X\\)) and larger (\\(Y\\)) of two rolls of a four-sided die Outcome (First roll, second roll) X (sum) Y (max) (1, 1) 2 1 (1, 2) 3 2 (1, 3) 4 3 (1, 4) 5 4 (2, 1) 3 2 (2, 2) 4 2 (2, 3) 5 3 (2, 4) 6 4 (3, 1) 4 3 (3, 2) 5 3 (3, 3) 6 3 (3, 4) 7 4 (4, 1) 5 4 (4, 2) 6 4 (4, 3) 7 4 (4, 4) 8 4 The possible values of \\(X\\) are \\(\\{2, 3, 4,5,6,7, 8\\}\\) The possible values of \\(Y\\) are \\(\\{1, 2, 3, 4\\}\\) The possible values of the pair \\((X, Y)\\) are \\(\\{(2, 1), (3, 2), (4, 2), (4, 3), (5, 3), (5, 4), (6, 3), (6, 4), (7, 4), (8,4)\\}\\). Notice that while, for example, 8 is a possible value of \\(X\\) and 1 is a possible value of \\(Y\\), (8, 1) is not a possible value of the pair \\((X, Y)\\); it’s not possible for the larger of the two dice to be 1 but their sum to be 8. Random variables are typically denoted by capital letters near the end of the alphabet, with or without subscripts: e.g. \\(X\\), \\(Y\\), \\(Z\\), or \\(X_1\\), \\(X_2\\), \\(X_3\\), etc. The random variable itself is typically denoted with a capital letter (\\(X\\)); possible values of that random variable are denoted with lower case letters (\\(x\\)). Think of the capital letter \\(X\\) as a label standing in for a formula like “the number of heads in 4 flips of a coin” and \\(x\\) as a dummy variable standing in for a particular value like 3. In the previous example, the pair \\(V=(X, Y)\\) is a random vector. The output of each of \\(X\\) and \\(Y\\) is a number; the output of \\(V\\) is an ordered pair of numbers. A \\(d\\)-dimensional random vector \\(V\\) maps sample space outcomes to \\(d\\)-dimensional vectors, \\(V:\\Omega \\mapsto \\mathbb{R}^d\\). The output of a random vector is a vector (or tuple) of numbers. More simply, a random vector is a vector of random variables. We introduce the notion of a random vector mainly to emphasize that there are often multiple random variables of interest in a problem. For example, considering tomorrow’s weather conditions, we might measure all of (high temperature, precipitation, humidity, max wind speed). There are two main types of random variables. Discrete random variables take at most countably many possible values (e.g., \\(0, 1, 2, \\ldots\\)). They are often counting variables (e.g., the number of Heads in 10 coin flips). Continuous random variables can take any real value in some interval (e.g., \\([0, 1]\\), \\([0,\\infty)\\), \\((-\\infty, \\infty)\\).). That is, continuous random variables can take uncountably many different values. Continuous random variables are often measurement variables (e.g., height, weight, income). In some problems, there are many random variables of interest, as in the following example. Example 2.18 Customers enter a deli and take a number to mark their place in line. When the deli opens the counter starts 0; the first customer to arrive takes number 1, the second 2, etc. We record the counter over time, continuously, as it changes as customers arrive. Time is measured in minutes after the deli opens (time 0). A sample space outcome could be represented as a path of the number of customers over time; a few such paths are illustrated in Figure 1.2. Notice the stairstep feature: a customer arrives and takes a number then the counter stays on that number for some time (the flat spots) until another customer arrives and the counter increases by one (the jumps). There are many random variables that could be of interest, including \\(N_t\\), the number of customers that have arrived by time \\(t\\), where \\(t\\ge0\\) is minutes after time 0 \\(T_j\\), the time (in minutes after time 0) at which the \\(j\\)th customer arrives, for \\(j=1, 2, \\ldots\\) \\(W_j\\), the “waiting” time (in minutes) between the arrival of the \\(j\\)th and the \\((j-1)\\)th customer. Figure 2.5: Sample space outcomes for Example 2.18. Left: a single sample path of the number of customer arrivals over time. Right: several possible paths. Classify each of the following random variables as discrete or continuous. Then for the outcome represented by the path in the plot on the left in Figure 2.5, identify (as best as you can from the plot) the value of the following random variables. \\(N_4\\) \\(N_{6.5}\\) \\(T_4\\) \\(T_5\\) \\(W_1\\) \\(W_5\\) Solution. to Example 2.18 The random variables \\(N_4\\) and \\(N_{6.5}\\) count the number of customers who have arrived so far at different times; these are discrete random variables each taking values in the countable set \\(\\{0, 1, 2, \\ldots \\}\\). The random variables \\(T_4\\), \\(T_5\\), \\(W_1\\), and \\(W_5\\) are continuous random variables; they each take values in the continuous time interval \\([0, \\infty)\\). Find time \\(t=3\\) on the horizontal axis and find the corresponding value on the vertical axis. If \\(\\omega\\) is the outcome represented by the plot on the left, then for this outcome \\(N_4(\\omega)=3\\); the number of customers that have arrived by time 4 is 3. For this outcome \\(N_{6.5}(\\omega)=5\\); the number of customers that have arrived by time 6.5 is 5. The number of customers is a whole number, but time is measured continuously (e.g., 6.5 minutes after opening). There is a different random variable \\(N_t\\) corresponding to each value of time \\(t\\ge 0\\), but the possible values of each of these variables are \\(\\{0, 1, 2, \\ldots\\}\\). The fourth customer arrives when the path jumps from 3 customers so far to 4. For this outcome the path jumps from 3 to 4 a little after time 5 so \\(T_4(\\omega)\\approx 5.1\\). The fifth customer arrives when the path jumps from 4 customers so far to 5. For this outcome the path jumps from 4 to 5 a little before time 6 so \\(T_5(\\omega)\\approx 5.9\\). There is a random variable \\(T_j\\) for each customer \\(j=1, 2, \\ldots\\), but the possible values of each of these random variables is \\([0,\\infty)\\). \\(W_1\\) is the waiting time from open until the first customer arrives (when the counter jumps from 0 to 1) which seems to happen at about time 2, so \\(W_1(\\omega)\\approx 2\\). For this outcome \\(W_5(\\omega)\\approx 0.8\\). \\(W_5\\) is the time elapsed between the arrival of the fourth customer (at roughly time 5.1 for outcome \\(\\omega\\)) and fifth customer (at roughly time 5.9 for outcome \\(\\omega\\)), which is about 0.8 minutes. 2.3.1 A random variable is a function Recall that for a mathematical function19 \\(g\\), given an input \\(u\\), the function returns a real number \\(g(u)\\). For example, if \\(g(u) = \\sqrt{u}\\) then \\(g(9) = 3\\). If the input comes from some set \\(S\\) (i.e. \\(u\\in S\\)), we often write \\(g:S\\mapsto \\mathbb{R}\\). Likewise, a random variable \\(X\\) is a function which maps each outcome \\(\\omega\\) in the sample space \\(\\Omega\\) to a real number \\(X(\\omega)\\); \\(X:\\Omega\\mapsto\\mathbb{R}\\). For a single outcome \\(\\omega\\), the value \\(x = X(\\omega)\\) is a single number; notice that \\(x\\) represents the output of the function \\(X\\) rather than the input. However, it is important to remember that the RV \\(X\\) itself is a function, and not a single number. You are probably familiar with functions expressed as simple closed form formulas of their inputs: \\(g(u)=5u\\), \\(g(u)=u^2\\), \\(g(u)=e^u\\), etc. While any random variable is some function, the function is rarely specified as an explicit mathematical formula of its input \\(\\omega\\). Often, outcomes are not even numbers (e.g., sequences of coin flips), or only vaguely specified if at all (e.g., possible paths of a hurricane, tomorrow’s weather conditions). In Example 2.16 we defined \\(X\\) only through the words “number of flips that land on heads”; translating even this simple situation into a formula of \\(\\omega\\) requires some notation20. It is more appropriate to think of a random variable as a function in the sense of a scale at a grocery store which maps a fruit to its weight, \\(X: \\text{fruit}\\mapsto\\text{weight}\\). Put an apple on the scale and the scale returns a number, \\(X(\\text{apple})\\), the weight of the apple. Likewise, \\(X(\\text{orange})\\), \\(X(\\text{banana})\\). The random variable \\(X\\) is the scale itself. This simplistic analogy assumes a sample space outcome is a single fruit. Of course, it’s even more complicated in reality since an outcome can be considered a set of fruits, so that we have for example \\(X(\\{\\text{2 apples}, \\text{3 oranges}\\})\\), and all fruits do not weigh the same, so that \\(X(\\text{this apple})\\) is not the same as \\(X(\\text{that apple})\\). But the idea is that a function is like a scale, with an input (fruits) and an output (weight). The input does not have to be a number, but the output does. Suppose I’m going to randomly select some fruits, put them in a brown grocery bag, and place it on the scale. It wouldn’t be feasible to enumerate all the combinations of fruits I could put in the bag, but even so you know that any possible combination has some weight which could be measured by the scale. There is still a function (scale) that maps an input (fruits in the bag) to a numerical output (weight), even if that function is not explicitly specified with a mathematical formula. Now suppose I’ve selected some fruits and put the bag on the scale. Even if you can’t see what fruits are inside the bag, you can still read the weight off the scale. But even if you only observe the weight, you know there was still a background random process of putting fruits in a bag which resulted in a particular outcome having the observed weight. The “weighing fruits in a bag” scenario in the previous paragraph illustrates how probability usually works: We typically don’t explicitly specify outcomes or the sample space, but we know that different outcomes can result in different values of random variables. That is, we know there is some function which maps outcomes of the random phenomenon to values of the random variable, even if we don’t have an explicit formula for the inputs to the function (the outcomes) or the function itself. We might not observe outcomes in detail, but we often can still observe values of random variables. Example 2.19 Regina and Cady plan to meet for lunch between noon and 1 but they are not sure of their arrival times. Recall the sample space from Example 2.6. Let \\(R\\) be the random variable representing Regina’s arrival time in \\([0, 1]\\), and \\(Y\\) for Cady. Identify the function that defines \\(R\\). (Hint: remember the sample space.) Identify the function that defines \\(Y\\). Solution. to Example 2.19 Recall that an outcome is an ordered pair representing the arrival times of (Regina, Cady); we can write an outcome as \\(\\omega\\equiv(\\omega_1, \\omega_2)\\). Remember there is a single sample space corresponding to the pairs of arrival times, rather than a separate sample space for each. Therefore, random variables need to be defined on this single sample space; inputs to random variables defined on this sample space are pairs of arrival times. Regina’s arrival time is defined by the function \\(R(\\omega) \\equiv R((\\omega_1, \\omega_2))=\\omega_1\\). That is, \\(R\\) maps the ordered pair \\((\\omega_1, \\omega_2)\\) to its first coordinate \\(\\omega_1\\). For example, \\(R((0.60, 0.52)) = 0.60\\). On this sample space, Cady’s arrival time is defined by the function \\(Y(\\omega) \\equiv Y((\\omega_1, \\omega_2))=\\omega_2\\). That is, \\(Y\\) maps the ordered pair to its second coordinate. The input to \\(Y\\) is a pair of numbers (Regina, Cady) and the output is Cady’s arrival time only. For example, \\(Y((0.60, 0.52)) = 0.52\\). 2.3.2 Events involving random variables We are often interested in events which involve random variables. In the weather example, the event “tomorrow’s high temperature is 75°F” involves the random variable “tomorrow’s high temperature”. Each possible outcome of tomorrow’s weather conditions will correspond to a value of high temperature, but only some of these outcomes will result in values of high temperature equal to 75 °F. The expressions \\(X=x\\) or \\(\\{X=x\\}\\) are shorthand for the event \\(\\{\\omega\\in\\Omega: X(\\omega)=x\\}\\), the set of outcomes \\(\\omega\\) for which \\(X(\\omega)=x\\). Remember that any event is a subset of the sample space. So objects like \\(\\{X=x\\}\\) are subsets21 of \\(\\Omega\\). Example 2.20 Consider the outcome of a sequence of 4 flips of a coin. One random variable is \\(X\\), the number of heads flipped. Use the sample space from Example 2.2 to answer the following. Identify and interpret the event \\(\\{X=3\\}\\). That is, identify the outcomes \\(\\omega\\) for which \\(X(\\omega)=3\\). Identify and interpret the event \\(\\{X=4\\}\\). Identify and interpret the event \\(\\{X\\ge3\\}\\). How is this event related to the previous two? Solution. to Example 2.20 \\(\\{X=3\\} = \\{HHHT, HHTH, HTHH, THHH\\}\\) is the event that exactly 3 of the flips land on heads. This is an event because it is a subset of the sample space. \\(\\{X=4\\}= \\{HHHH\\}\\), the event that exactly 4 of the flips land on heads. Notice that the event is the set \\(\\{HHHH\\}\\), which consists of the single outcome \\(HHHH\\). \\(\\{X\\ge3\\} = \\{HHHT, HHTH, HTHH, THHH, HHHH\\}\\) is the event that the at least 3 of the flips land on heads. Also \\(\\{X\\ge 3\\} = \\{X=3\\}\\cup \\{X=4\\}\\). The RV itself is denoted with a capital letter; possible values of that random variable are denoted with lower case letters. For example \\(\\{X=x\\}\\) is shorthand for the event \\(\\{\\omega\\in\\Omega: X(\\omega)=x\\}\\), the set of outcomes \\(\\omega\\) for which \\(X(\\omega)=x\\). Think of the capital letter \\(X\\) as a label standing in for a formula like “the number of heads in 4 flips of a coin” and \\(x\\) as a dummy variable standing in for a particular value like 3. Remember that any event is a subset of the sample space. So objects like \\(\\{X=x\\}\\) are subsetsof \\(\\Omega\\). Example 2.21 Roll a four-sided die twice, and record the result of each roll in sequence. Recall the sample space from Example 2.1. Let \\(X\\) be the sum of the two dice, and let \\(Y\\) be the larger of the two rolls (or the common value if both rolls are the same). Identify and interpret each of the following. \\(\\{X = 4\\}\\). \\(\\{X = 3\\}\\). \\(\\{X \\le 3\\}\\). \\(\\{Y = 4\\}\\). \\(\\{Y = 3\\}\\). \\(\\{Y \\le 3\\}\\). \\(\\{X = 4, Y = 3\\}\\) (that is, \\(\\{X = 4\\}\\cap \\{Y = 3\\}\\)). \\(\\{X = 4, Y \\le 3\\}\\). \\(\\{X = 3, Y = 3\\}\\). \\(\\{X \\ge Y\\}\\). Solution. to Example 2.21 \\(\\{X = 4\\} =\\{(1, 3), (2, 2), (3, 1)\\}\\) is the event that the sum of the two dice is 4. \\(\\{X = 3\\} =\\{(1, 2), (2, 1)\\}\\) is the event that the sum of the two dice is 3. \\(\\{X \\le 3\\}=\\{(1, 1), (1, 2), (2, 1)\\}\\) is the event that the sum of the two dice is at most 3. \\(\\{Y = 4\\}=\\{(1, 4), (2, 4), (3, 4), (4, 4), (4, 1), (4, 2), (4,3)\\}\\) is the event that the larger of the two rolls is 4. \\(\\{Y = 3\\}=\\{(1, 3), (2, 3), (3, 3), (3, 1), (3, 2)\\}\\) is the event that the larger of the two rolls is 3. \\(\\{Y \\le 3\\}=\\{(1, 1), (1, 2), (1, 3), (2, 1), (2, 2), (2, 3), (3, 1), (3, 2), (3, 3)\\}\\) is the event that the larger of the two rolls is at most 3. Notice that since in this example \\(Y\\) can only take values 1, 2, 3, 4, we have \\(\\{Y\\le 3\\} = \\{Y=4\\}^c\\). \\(\\{X = 4, Y = 3\\} \\equiv \\{X = 4\\}\\cap \\{Y = 3\\}=\\{(1, 3), (3, 1)\\}\\) is the event that both the sum of the two dice is 4 and the larger of the two rolls is 3. Even though this involves two random variables, it is a single event (that is, a single subset of the sample space). There are only two outcomes for which both the sum of the two dice is 4 and the larger of the two dice is 3. \\(\\{X = 4, Y \\le 3\\} \\equiv \\{X = 4\\}\\cap \\{Y \\le 3\\}=\\{(1, 3), (2, 2), (3, 1)\\}\\) is the event that both the sum of the two dice is 4 and the larger of the two rolls is at most 3. Notice that since in this example \\(\\{X=4\\} \\subset \\{Y\\le 3\\}\\), we have \\(\\{X = 4, Y \\le 3\\} = \\{X=4\\}\\). If the sum is 4 we know the larger roll must be at most 3. \\(\\{X = 3, Y = 3\\} \\equiv \\{X = 3\\}\\cap \\{Y = 3\\}=\\emptyset\\), since there are no outcomes for which both the sum is 3 and the larger of the two dice is 3. (If the the larger of the two dice is 3, then the sum must be at least 4.) The event \\(\\{X\\ge Y\\}\\) represents the set of outcomes \\(\\{\\omega: X(\\omega) \\ge Y(\\omega)\\}\\). In this example, for every possible outcome the sum of the two dice is at least as large as the larger of the two die, so \\(\\{X \\ge Y\\} = \\Omega\\). When dealing with probabilities, it is common to write \\(X=3\\) instead of \\(\\{X=3\\}\\), and \\(X = 4, Y = 3\\) instead of \\(\\{X = 4\\}\\cap \\{Y = 3\\}\\); read the comma in \\(X = 4, Y = 3\\) as “and”. But keep in mind that an expression like “\\(X=3\\)” really represents an event \\(\\{X=3\\}\\), an expression which itself represents \\(\\{\\omega\\in\\Omega: X(\\omega) = 3\\}\\), a subset of \\(\\Omega\\). Example 2.22 Regina and Cady plan to meet for lunch between noon and 1 but they are not sure of their arrival times. Recall the sample space from Example 2.6. Let \\(R\\) be the random variable representing Regina’s arrival time in \\([0, 1]\\), and \\(Y\\) for Cady. Identify and interpret the following. \\(\\{R &gt; Y\\}\\). \\(\\{\\min(R, Y) &lt; 0.5\\}\\). \\(\\{Y&lt;R&lt;Y+0.25\\}\\). \\(\\{R &lt; 0.4\\}\\). Solution. to Example 2.22 The parts of this problem are almost identical to those in Example 2.14; the main difference is in notation. See Figure 2.6 for pictures. \\(\\{R&gt;Y\\} = \\{(\\omega_1, \\omega_2): \\omega_1&gt;\\omega_2\\}\\) is the event that Regina arrives after Cady (event \\(A\\) from Example 2.14.) \\(\\{\\min(R, Y)&lt;0.5\\} = \\{(\\omega_1, \\omega_2): \\omega_1&lt;0.5 \\text{ or } \\omega_2&lt;0.5\\}\\), is the event that the earlier of the two arrival times is before 12:30 (event \\(B\\) from Example 2.14.) This event can also be written as \\(\\{R &lt; 0.5\\}\\cup \\{Y &lt; 0.5\\}\\), the event that either Regina or Cady arrives before 12:30. \\(\\{Y&lt;R&lt;Y+0.25\\} = \\{(\\omega_1, \\omega_2): \\omega_2&lt;\\omega_1\\le \\omega_2+0.25\\} = \\{(\\omega_1, \\omega_2): \\omega_1 &gt; \\omega_2\\ge \\omega_1 - 0.25\\}\\) is the event that Cady arrives first and Regina arrives at most 15 minutes after Cady (event \\(C\\) from Example 2.14.) \\(\\{R &lt; 0.4\\} = \\{(\\omega_1, \\omega_2): \\omega_1&lt;0.4\\}\\) is the event that Regina arrives before 12:24 (event \\(D\\) from Example 2.14.) Figure 2.6: Illustration of the events in Exercise 2.22. The square represents the possible values of \\((R, Y)\\), the random vector representing the arrival times of Regina and Cady. 2.3.3 Transformations of random variables We are often interested in random variables that are derived from others. If the random variable \\(X\\) represents the radius of a randomly selected circle, then \\(Y = \\pi X^2\\) is a random variable representing the circle’s area. If the random variables \\(W\\) and \\(T\\) represent the weight (kg) and height (m), respectively, of a randomly selected person, then \\(S = W / T^2\\) is a random variable representing the person’s body mass index (\\(\\text{kg}/\\text{m}^2\\)). In this section we introduce random variables that are derived from transformations of others. A function of a random variable is also a random variable. That is, if \\(X\\) is a random variable and \\(g:\\mathbb{R}\\mapsto\\mathbb{R}\\) is a function, then \\(Y=g(X)\\) is a random variable22. For example, if \\(u\\) is a radius of a circle, the function \\(g(u) = \\pi u^2\\) outputs its area. If \\(X\\) is a random variable representing the radius of a randomly selected circle then \\(Y = g(X)=\\pi X^2\\) is a random variable representing the circle’s area. Example 2.23 Flip a coin 3 times and record the results in sequence. Let \\(X\\) be the number of flips that result in H, and let \\(Y=(X-1.5)^2\\). (We will see later why we might be interested in such a transformation.) Construct a table identifying the values of \\(X\\) and \\(Y\\) for each outcome in the sample space. What are the possible values of \\(X\\)? \\(Y\\)? Solution. Solution to Example 2.23. See Table 2.3. The possible values of \\(X\\) are \\(\\{0, 1, 2, 3\\}\\). The possible values of \\(Y\\) are \\(\\{0.25, 2.25\\}\\). Table 2.3: Table representing \\(X\\), the number of heads in 3 flips of a coin, and \\(Y=(X-1.5)^2\\) Outcome X Y HHH 3 2.25 HHT 2 0.25 HTH 2 0.25 THH 2 0.25 HTT 1 0.25 THT 1 0.25 TTH 1 0.25 TTT 0 2.25 Sums and products, etc., of random variables defined on the same sample space are random variables. That is, if random variables \\(X\\) and \\(Y\\) are defined on the same sample space then \\(X+Y\\), \\(X-Y\\), \\(XY\\), and \\(X/Y\\) are also random variables. Similarly, it is possible to make comparisons such as \\(X\\ge Y\\) and apply other transformations for random variables defined on the same probability space. Example 2.24 Regina and Cady plan to meet for lunch between noon and 1 but they are not sure of their arrival times. Recall the sample space from Example 2.6. Let \\(R\\) be the random variable representing Regina’s arrival time in \\([0, 1]\\), and \\(Y\\) for Cady. What does the random variable \\(T = \\min(R, Y)\\) represent? What are the possible values of \\(T\\)? What does the random variable \\(W = |R - Y|\\) represent? What are the possible values of \\(W\\)? Solution. to Example 2.24 \\(T=\\min(R, Y)\\) represents the time at which the first person arrives. \\(T\\) takes values in \\([0, 1]\\). If either Regina and Cady arrives at time 0 (noon) then \\(T\\) is 0; if both arrive at time 1 (1:00) then \\(T\\) is 1. \\(W=|R-Y|\\) represents the amount of time the first person to arrive waits for the second person to arrive. \\(W\\) takes values in \\([0, 1]\\). If both Regina and Cady arrive at the same time then \\(W\\) is 0; if one arrives at noon and the other at 1:00 then \\(W\\) is 1. The following example emphasizes why we need random variables to be “defined on the same sample space”. Example 2.25 Select a U.S. high school student and record the student’s SAT Math and Reading score. Recall the sample space from Example 2.7. What function defines \\(M\\), SAT Math score? (Hint: remember how we defined an outcome in Example 2.7.) What function defines \\(R\\), SAT Reading score? What function defines \\(T\\), total SAT score? Solution. Solution to 2.25. Recall that an outcome is an ordered pair representing (Math, Reading) score; we can write an outcome as \\(\\omega\\equiv(\\omega_1, \\omega_2)\\). Remember there is a single sample space corresponding to the pairs of scores, rather than a separate sample space for each of the scores. Therefore, random variables need to be defined on this single sample space; inputs to random variables defined on this sample space are pairs of scores. Math score is defined by the function \\(M(\\omega) \\equiv M((\\omega_1, \\omega_2))=\\omega_1\\). That is, \\(M\\) maps the ordered pair \\((\\omega_1, \\omega_2)\\) to its first coordinate \\(\\omega_1\\). For example, \\(M((600, 520)) = 600\\). On this sample space, Reading score is defined by the function \\(R(\\omega) \\equiv R((\\omega_1, \\omega_2))=\\omega_2\\). That is, \\(R\\) maps the ordered pair to its second coordinate. The input to \\(R\\) is a pair of numbers (Math, Reading) and the output is the Reading score only. For example, \\(M((600, 520)) = 520\\). On this sample space, total score is defined by the function \\(T(\\omega) \\equiv T((\\omega_1, \\omega_2))=\\omega_1 + \\omega_2\\). For example, \\(T((600, 520)) = 600 + 520=1120\\). Note that \\(T = M + R\\) because for each outcome \\(\\omega\\), \\(T(\\omega) = M(\\omega) + R(\\omega)\\). The previous example probably seems like notational overkill. And of course we could have defined \\(T\\) directly as \\(T((\\omega_1,\\omega_2))=\\omega_1+\\omega_2\\) without the need for \\(M, R\\). But we introduced the example to emphasize that it only makes sense to add random variables if they are defined on the same sample space. Remember that adding two random variables involves adding two functions, in the way that the function \\(g = g_1 + g_2\\) is defined by \\(g(u) = g_1(u) + g_2(u)\\). It only makes sense to add two functions together if they have the same inputs. For example, consider the random variable \\(X\\) from Example 2.16 and the random variable \\(Y\\) from Example 2.17. It wouldn’t make much practical sense to consider \\(X+Y\\), but it would make no mathematical sense. How would \\(X+Y\\) even be defined? \\(X\\) is defined for sequences of coin flips like HHTH, while \\(Y\\) is defined for pairs of die rolls like (3, 1). If you attempted to add \\(X\\) and \\(Y\\), which outcomes would go together? Would you add \\(X(HHTH)\\) to \\(Y((3, 1))\\)? Why not add \\(X(HHTH)\\) to \\(Y((2, 2))\\)? Again, adding two random variables involves adding two functions, and it doesn’t make sense to add those functions if they have different inputs. As a more practical example, requiring \\(M\\) and \\(R\\) in Example 2.25 to be defined on the same probability space is like requiring the Math scores to be measured for the same students as the Reading scores. For example, Antwan has both a Math score \\(M(\\text{Antwan})\\) and a Reading score \\(R(\\text{Antwan})\\), so we can consider the total score \\((M+R)(\\text{Antwan}) = M(\\text{Antwan})+R(\\text{Antwan})\\). (In statistical terms, the variables are measured for the same observational units.) It wouldn’t make sense to add SAT Math scores from one set of students to SAT Reading scores for a different set of students; for example \\(M(\\text{Antwan}) + R(\\text{Maria})\\) makes no sense. Remember that we can visualize outcomes as rows in a spreadsheet with random variables as columns. Random variables defined on the same sample space can be put in a single spreadsheet. Each row corresponds to an outcome, and reading across any row there is a value in the column corresponding to each random variable. Transformations can be applied rowwise for each outcome to define new random variables. Example 2.26 Consider the outcome of a sequence of 4 flips of a coin; recall the sample space from Example 2.2 Example 2.16 concerned the random variable \\(X\\), the number of heads flipped. Now we’ll consider a few more random variables. In Section 1.5 we considered the proportion of the flips which immediately follow a H that result in H. Remember that we do not define this proportion if no flips follow a H, that is, if the outcome is either TTTT or TTTH. Let: \\(Z\\) be the number of flips immediately following H. \\(Y\\) be the number of flips immediately following H that result in H. \\(W\\) be the proportion of flips immediately following H that result in H. Is \\(W\\) a random variable? How does it relate to \\(Y\\) and \\(Z\\)? For each of the possible outcomes in the sample space, find the value of \\((Z, Y, W)\\). Solution. to Example 2.26 Yes, \\(W\\) is a random variable because it maps each coin flip sequence to the value of proportion of the flips which immediately follow a H that result in H for that sequence; see the table below. Also, \\(W=Y/Z\\). Technically \\(Y\\) and \\(Z\\) are not defined for outcomes TTTT and TTTH, but we’re ignoring those sequences for the purposes of investigating the proportion of the flips which immediately follow a H that result in H. See Table 2.4. For each outcome, the flips which follow head are in bold. Table 2.4: Possible values of (1) \\(Z\\), the number of flips immediately following H, (2) \\(Y\\), the number of flips immediately following H that result in H, and (3) \\(X\\), the proportion of flips immediately following H that result in H, for four flips of a fair coin. Outcome (\\(\\omega\\)) \\(Z\\) \\(Y\\) \\(X = Y/Z\\) HHHH 3 3 1 HHHT 3 2 2/3 HHTH 2 1 1/2 HTHH 2 1 1/2 THHH 2 2 1 HHTT 2 1 1/2 HTHT 2 0 0 HTTH 1 0 0 THHT 2 1 1/2 THTH 1 0 0 TTHH 1 1 1 HTTT 1 0 0 THTT 1 0 0 TTHT 1 0 0 TTTH 0 not defined not defined TTTT 0 not defined not defined Example 2.27 (Don’t do what Donny Don’t does.) At various points in his homework, Donny Don’t writes the following. Explain to Donny why each of the following symbols is nonsense, both mathematically and intuitively using a simple example (like tomorrow’s weather). Below, \\(A\\) and \\(B\\) represent events, \\(X\\) and \\(Y\\) represent random variables. \\(A = 0.5\\) \\(A + B\\) \\(X = A\\) \\(X + A\\) \\(X \\cap Y\\) Solution. to Example 2.27 We’ll respond to Donny using tomorrow’s weather as an example, with \\(A\\) representing the event that it rains tomorrow, \\(X\\) tomorrow’s high temperature (degrees F), \\(B=\\{X&gt;80\\}\\) the event that tomorrow’s high temperature is above 80 degrees, and \\(Y\\) tomorrow’s rainfall (inches). \\(A\\) is a set and 0.5 is a number; it doesn’t make mathematical sense to equate them. It doesn’t make sense to say “it rains tomorrow equals 0.5”. \\(A\\) and \\(B\\) are sets; it doesn’t make mathematical sense to add them. It doesn’t make sense to say “the sum of (it rains tomorrow) and (tomorrow’s high temperature is above 80 degrees F)”. If we want “(it rains tomorrow) OR (tomorrow’s high temperature is above 80 degrees F)”, then we need \\(A\\cup B\\). Union is an operation on sets; addition is an operation on numbers. \\(X\\) is a random variable (a function) and \\(A\\) is an event (a set), and it doesn’t make sense to equate these two different mathematical objects. Suppose that \\(X\\) represents tomorrow’s high temperate (degrees F). It doesn’t make sense to say “tomorrow’s high temperature equals the event that it rains tomorrow”. \\(X\\) is a random variable (a function) and \\(A\\) is an event (a set), and it doesn’t make sense to add these two different mathematical objects. It doesn’t make sense to say “the sum of (tomorrow’s high temperature) and (the event that it rains tomorrow)”. \\(X\\) and \\(Y\\) are random variables (functions) and intersection is an operation on sets. \\(X \\cap Y\\) is attempting to say “tomorrow’s high temperature in degrees F and the amount of rainfall in inches tomorrow”. If we’re talking about a random vector containing these two variables, we would write \\((X, Y)\\) not \\(X \\cap Y\\). If we’re interested in an event involving \\(X\\) and \\(Y\\), we’re missing qualifying information to define a valid event. We could write \\(X &gt;80, Y &lt; 2\\) or \\(\\{X &gt; 80\\} \\cap \\{Y &lt; 2\\}\\) to represent “the event that (tomorrow’s high temperature is greater than 80 degrees F) AND (the amount of rainfall tomorrow is less than 2 inches)”. 2.3.4 Indicator random variables and counting Random variables that only take two possible values, 0 and 1, have a special name. Definition 2.5 An indicator (a.k.a. Bernoulli) random variable can take only the values 0 or 1. If \\(A\\) is an event then the corresponding indicator random variable \\(\\textrm{I}_A\\) is defined as \\[ \\textrm{I}_A(\\omega) = \\begin{cases} 1, &amp; \\omega \\in A,\\\\ 0, &amp; \\omega \\notin A \\end{cases} \\] That is, \\(\\textrm{I}_A\\) equals 1 if event \\(A\\) occurs, and \\(\\textrm{I}_A\\) equals 0 if event \\(A\\) does not occur. Indicators provide the bridge between events (sets) and random variables (functions). Example 2.28 Flip a coin 3 times and record the results in sequence. Let \\(A_i\\) be the event that flip \\(i\\) lands on H, for \\(i=1, 2, 3\\). Construct a table identifying the values of the indicator random variables \\(\\textrm{I}_{A_1}\\), \\(\\textrm{I}_{A_2}\\), and \\(\\textrm{I}_{A_3}\\) for each outcome in the sample space. Identify and interpret the event \\(\\{I_{A_1}=1\\}\\). Identify and interpret the event \\(\\{I_{A_1}=0\\}\\). Identify and interpret the event \\(\\{I_{A_2}=1\\}\\). Identify and interpret the event \\(\\{I_{A_1 \\cap A_2}=1\\}\\). Identify and interpret the event \\(\\{I_{A_1 \\cup A_2}=1\\}\\). How is \\(\\textrm{I}_{A_1^c}\\) related to \\(\\textrm{I}_{A_1}\\)? How is \\(\\textrm{I}_{A_1\\cap A_2}\\) related to \\(\\textrm{I}_{A_1}\\) and \\(\\textrm{I}_{A_2}\\)? (Can you think of two ways?) How is \\(\\textrm{I}_{A_1\\cup A_2}\\) related to \\(\\textrm{I}_{A_1}\\) and \\(\\textrm{I}_{A_2}\\)? (Can you think of two ways?) How is \\(X\\), the number of flips that result in H, related to \\(\\textrm{I}_{A_1}\\), \\(\\textrm{I}_{A_2}\\), and \\(\\textrm{I}_{A_3}\\)? Solution. Solution to Example 2.28. See Table 2.5. We’ve also added columns for \\(I_{A_1^c}\\), \\(I_{A_1 \\cap A_2}\\), \\(I_{A_1 \\cup A_2}\\), and \\(X\\), the number of H. Table 2.5: Indicators of H on each flip in a sequence of 3 flips of a coin Outcome IA1 IA2 IA3 Inot_A1 IA1_and_A2 IA1_or_A2 X HHH 1 1 1 0 1 1 0 HHT 1 1 0 0 1 1 1 HTH 1 0 1 0 0 1 1 HTT 1 0 0 0 0 1 1 THH 0 1 1 1 0 1 2 THT 0 1 0 1 0 1 2 TTH 0 0 1 1 0 0 2 TTT 0 0 0 1 0 0 3 \\(\\{I_{A_1}=1\\}=\\{HHH, HHT, HTH, HTT\\}\\) is the event that the first flip results in H. Since \\(I_{A_1}\\) is either 1 or 0, \\(\\{I_{A_1}=0\\}=\\{I_{A_1}=1\\}^c = \\{HHH, HHT, HTH, HTT\\}^c\\) is the event that the first flip does not result in H. \\(\\{I_{A_2}=1\\}=\\{HHH, HHT, THH, THT\\}\\) is the event that the second flip results in H. \\(\\{I_{A_1\\cap A_2}=1\\}=\\{HHH, HHT\\}\\) is the event that the first two flips result in H. \\(\\{I_{A_1 \\cup A_2}=1\\} = \\{TTH, TTT\\}^c\\) is the event that at least one of the first two flips results in H. Reading across each row, we see that for every outcome \\(\\textrm{I}_{A_1^c} = 1 - \\textrm{I}_{A_1}\\). If \\(A_1\\) occurs (\\(\\omega \\in A_1\\), flip 1 is H), \\(I_{A_1}=1\\) and \\(I_{A_1^c}=0\\); if \\(A_1\\) does not occurs (\\(\\omega \\in A_1^c\\), flip 1 is not H), \\(I_{A_1}=0\\) and \\(I_{A_1^c}=1\\). Reading across each row, we see that for every outcome \\(\\textrm{I}_{A_1\\cap A_2} = \\textrm{I}_{A_1}\\textrm{I}_{A_2}\\). If both \\(A_1\\) and \\(A_2\\) occur then \\(A_1\\cap A_2\\) occurs (flip 1 is H and flip 2 is H), so \\(\\textrm{I}_{A_1\\cap A_2} = 1\\) and \\(\\textrm{I}_{A_1} \\textrm{I}_{A_2}=1\\). If \\(A_1\\) does not occur (flip 1 is not H) then \\(A_1\\cap A_2\\) does not occur, so \\(I_{A_1}=0\\), \\(\\textrm{I}_{A_1\\cap A_2} = 0\\) and \\(\\textrm{I}_{A_1} \\textrm{I}_{A_2}=0\\). (Similarly if \\(A_2\\) does not occur.). Reading across each row we also see that for every outcome \\(I_{A_1 \\cap A_2} = \\min(I_{A_1}, I_{A_2})\\). \\(\\min(I_{A_1}, I_{A_2})=1\\) if and only if both \\(I_{A_1}=1\\) and \\(I_{A_2}=1\\), which happens if and only if both \\(A_1\\) and \\(A_2\\) occur. Reading across each row, we see that for every outcome \\(\\textrm{I}_{A_1\\cup A_2} = \\textrm{I}_{A_1}+\\textrm{I}_{A_2}-\\textrm{I}_{A_1}\\textrm{I}_{A_2}\\) If neither \\(A_1\\) and \\(A_2\\) occur then \\(I_{A_1}=0\\), \\(I_{A_2} = 0\\), and \\(\\textrm{I}_{A_1\\cup A_2} = 0\\), and the relationship holds in this case. If \\(A_1\\) occurs but \\(A_2\\) does not then \\(I_{A_1}=1\\), \\(I_{A_2} = 0\\), and \\(\\textrm{I}_{A_1\\cup A_2} = 1\\), and the relationship holds in this case. (Similarly if \\(A_2\\) occurs but \\(A_1\\) does not.) If both \\(A_1\\) and \\(A_2\\) occur then \\(I_{A_1}=1\\), \\(I_{A_2} = 1\\), and \\(\\textrm{I}_{A_1\\cup A_2} = 1\\), and the relationship holds in this case. Reading across each row we also see that for every outcome \\(I_{A_1 \\cup A_2} = \\max(I_{A_1}, I_{A_2})\\). \\(\\max(I_{A_1}, I_{A_2})=0\\) if and only if both \\(I_{A_1}=0\\) and \\(I_{A_2}=0\\), which happens if and only if \\((A_1^c \\cap A_2^c) = (A_1 \\cup A_2)^c\\) occurs. Reading across each row, we see that for every outcome \\(X= I_{A_1} + I_{A_2} + I_{A_3}\\). We discuss this idea in more detail below. The previous example illustrates that for two events \\(A\\) and \\(B\\) \\[\\begin{align*} \\textrm{I}_{A^c} &amp; = 1 - I_A &amp; &amp; \\\\ \\textrm{I}_{A \\cap B} &amp; = \\textrm{I}_A \\textrm{I}_B &amp; &amp; =\\min(I_A, I_B)\\\\ \\textrm{I}_{A \\cup B} &amp; = \\textrm{I}_A + \\textrm{I}_B - \\textrm{I}_{A \\cap B} &amp; &amp; = \\max(I_A, I_B) \\end{align*}\\] In particular, the indicator of an intersection is the product of the indicators of each event. The \\(\\min, \\max\\), and product formulas work for more than two events, but the addition formula is more complicated23. Even though they seem simple, indicator random variables are very useful. In particular, many probability problems are of the form “find the expected number of (blank)”. In these problems, representing a count as a sum of indicator random variables, as in the last part of Example 2.28, is a very common and useful strategy. We elaborate on this idea below, but first a little story. Imagine a dad and his young child are reading a picture book. They come to a page that has twenty pictures of fruits, of which seven are bananas. The following conversation ensues. Dad: Can you count all the bananas? Let’s see! How many bananas have we counted so far? Kid: We haven’t started counting yet! Dad: Right, so how many bananas have we counted so far? Kid: Zero! Dad: That’s right! We’ve counted zero bananas so far. (Points to a banana.) Is that a banana? Kid: Yes! Dad: So how many more bananas did we just count? Kid: One! Dad: So how many bananas have we counted so far? Kid: One! Dad: Great job! We’ve counted one banana so far. (Points to a different banana.) Is that a banana? Kid: Yes! Dad: So how many more bananas did we just count? Kid: We counted one more banana! Dad: So how many bananas have we counted so far? Kid: Two! Dad: Great job! We’ve counted two bananas so far. (Points to a different banana.) Is that a banana? Kid: Yes! Dad: So how many more bananas did we just count? Kid: We counted one more banana! Dad: So how many bananas have we counted so far? Kid: Three! Dad: Great job! We’ve counted three bananas so far. (Points to an orange24.) Is that a banana? Kid: No, that’s an orange! Dad: So how many more bananas did we just count? Kid: Zero! It was not a banana! Dad: So how many bananas have we counted so far? Kid: Still three! Dad: Great job! We’ve counted three bananas so far. (Continues in this manner until Dad points to the twentieth and last fruit on the page, a banana.) Almost done. We’ve counted six bananas so far. Is that a banana? Kid: Yes! Dad: So how many more bananas did we just count? Kid: We counted one more banana! Dad: So how many bananas have we counted so far? Kid: Seven! Dad: We looked at each fruit on the page. How many were bananas? Kid: Seven! Dad: Great job! Now you know how indicator random variables can be used to count. In the story, the kid counted the bananas by examining each object, determining whether or not it was a banana, and then incrementing the banana counter by 1 for each object that was a banana (and by 0 for the objects that were not bananas). The kid essentially created an indicator (of “banana”) variable for each object on the page (\\(I_{B_1}=1\\), \\(I_{B_2}=1\\), \\(I_{B_3}=1\\), \\(I_{B_4}=0\\ldots\\), \\(I_{B_{20}}=1\\)) and then summed these indicators to obtain the total count of bananas. This strategy gives a way of breaking down a complicated counting problem into smaller pieces and counting incrementally. Example 2.29 (Matching problem) Recall the “matching problem”. A geology museum in California has four different rocks sitting in a row on a shelf, with labels on the shelf telling what type of rock each is. An earthquake hits and the rocks all fall off the shelf and get mixed up. A janitor comes in and, wanting to clean the floor, puts the rocks back on the shelf in random order. We might be interested in things like whether all the rocks are put back in the correct spot, or none are, or if the heaviest rock is put back in the correct spot. Recall the sample space from Example 2.3. Let the random variable \\(Y\\) count the number of rocks that are put back in the correct spot. Evaluate \\(Y(1234)\\), \\(Y(1243)\\), and \\(Y(2143)\\). Construct a table identifying the value of \\(Y\\) for each outcome in the sample space. How could you represent \\(Y\\) in terms of indicator random variables? Define appropriate indicators and add the corresponding columns to the table. What is the relationship between \\(Y\\) and the indicators you defined in the previous part? Solution. to Example 2.29 \\(Y(1234)=4\\) because for this outcome all rocks are put in the correct spot, \\(Y(1243)=2\\) because rocks 1 and 2 are in the correct spot but 3 and 4 aren’t, and \\(Y(2143)=0\\) because none of the rocks are in the correct spot. See the first two columns of Table 2.6. Table 2.6: Indicators for each item and total number of matches in Matching Problem Outcome Y I1 I2 I3 I4 1234 4 1 1 1 1 1243 2 1 1 0 0 1324 2 1 0 0 1 1342 1 1 0 0 0 1423 1 1 0 0 0 1432 2 1 0 1 0 2134 2 0 0 1 1 2143 0 0 0 0 0 2314 1 0 0 0 1 2341 0 0 0 0 0 2413 0 0 0 0 0 2431 1 0 0 1 0 3124 1 0 0 0 1 3142 0 0 0 0 0 3214 2 0 1 0 1 3241 1 0 1 0 0 3412 0 0 0 0 0 3421 0 0 0 0 0 4123 0 0 0 0 0 4132 1 0 0 1 0 4213 1 0 1 0 0 4231 2 0 1 1 0 4312 0 0 0 0 0 4321 0 0 0 0 0 We want to know whether each rock was put in the correct spot. Let \\(C_j\\) be the event that rock \\(j\\) is placed correctly in spot \\(j\\), \\(j=1, 2, 3, 4\\). Then define the indicator random variables corresponding to these events \\(I_{C_j}\\equiv I_j\\). There is one indicator for each rock. See Table 2.6. For example, \\(I_1(1243)=1\\), \\(I_2(1243)=1\\), \\(I_3(1243) = 0\\) and \\(I_4(1243)=0\\). The indicators define the incremental counters like in the banana story, so \\(Y=I_1 + I_2 + I_3+I_4\\). Remember that this is a relationship between functions; within each row the total number of matches is the sum of the values of the indicator random variables. In the matching problem, it is not feasible to enumerate the outcomes and count when there are a large number of items and spots. Using indicators allows you to focus on one item at time — is just this item in the correct spot? — rather than all at once. We will see that indicators often provide a useful strategy for tackling probability problems. 2.3.5 Summary A random variable is a function whose input is a sample space outcome and whose output is a real number. A random vector is a vector of random variables. Many events of interest involve random variables. A function of a random variable is also a random variable. Sums and products, etc., of random variables defined on the same probability space are random variables. Another less important reason is that is often convenient to work with sample spaces in which the outcomes are equally likely. For four flips of a fair coin the outcomes \\(HHHH, HHHT, HHTH, \\ldots\\) are equally likely, but the values \\(0, 1, 2, 3, 4\\) are not equally likely for the number of heads.↩︎ Throughout, we use \\(g\\) to denote a generic function, and reserve \\(f\\) to represent a probability density function. Likewise, we represent a generic function argument (or “dummy variable”) with \\(u\\), since \\(x\\) is often used to represent possible values of a random variable \\(X\\). In the context of a random variable, \\(x\\) typically represents the output of the function \\(X\\) rather than the input (which is a sample space outcome \\(\\omega\\).)↩︎ It’s easiest if we label a flip of heads as 1 and tails as 0. Represent an outcome \\(\\omega\\) as \\((\\omega_1, \\omega_2, \\omega_3, \\omega_4)\\), where \\(\\omega_i\\in\\{0,1\\}\\) is the result of the \\(i\\)th flip. Then \\(X(\\omega)=\\sum_{i=1}^{4} \\omega_i\\) represents the number of heads. For example, outcome HHTH would be represented as \\((1, 1, 0, 1)\\) and \\(X((1, 1, 0, 1)) = 1 + 1 + 0 + 1 = 3\\). This could be coded as sum(omega).↩︎ Technically, we have some collection \\(\\mathcal{F}\\) of events of interest, and so we require sets like \\(\\{X\\le x\\}\\) to be in \\(\\mathcal{F}\\). This requirement is satisfied by requiring \\(X\\) to be an \\(\\mathcal{F}\\)-measurable function. We will ignore this technicality and always assume events like \\(\\{X\\le x\\}\\) are always include in the collection of events of interest.↩︎ \\(Y(\\omega) = g(X(\\omega))\\) so \\(Y\\) maps \\(\\Omega\\) to \\(\\mathbb{R}\\) via the composition of the functions \\(g\\) and \\(X\\); that is, \\(Y=g\\circ X\\) where \\((g\\circ X):\\Omega\\mapsto \\mathbb{R}\\)↩︎ See the inclusion-exclusion principle↩︎ Orange you glad I didn’t say banana↩︎ "],
["probspace.html", "2.4 Probability spaces", " 2.4 Probability spaces In the previous sections we defined outcomes, events, and random variables, the main mathematical objects associated with a random phenomenon. But we haven’t actually computed any probabilities yet! So far we have only been concerned with what is possible. You might have noticed that the examples did not include any assumptions like “the coin is fair”, “the die is weighted”, “Regina is more likely to arrive late and Cady is more likely to arrive early”, “the janitor is equally likely to put any rock in any spot.” Now we will incorporate assumptions of the random phenomenon to determine how probable various events are. In keeping with the theme of this chapter, we will focus on what it means to assign probabilities to events, rather than how to actually compute probabilities. Later chapters will focus in much more detail on solving a wide variety of probability problems. A probability measure assigns probabilities to events to quantify their relative likelihoods. As we saw in Section 1.4, there are some basic logical consistency requirements that probabilities must satisfy. These requirements are formalized in the following definition. Definition 2.6 A probability space is a triple \\((\\Omega, \\mathcal{F}, \\textrm{P})\\) where \\(\\Omega\\) is a sample space of outcomes \\(\\mathcal{F}\\) is a collection of events of interest25 \\(A\\subseteq\\Omega\\) \\(\\textrm{P}\\) is a probability measure which assigns a probability \\(\\textrm{P}(A)\\) to events \\(A\\in\\mathcal{F}\\). A probability measure satisfies the following three axioms \\(\\textrm{P}(\\Omega)=1\\) For all events \\(A\\in\\mathcal{F}\\), \\(0\\le \\textrm{P}(A)\\le 1\\) (Countable additivity.) If events \\(A_1, A_2, \\ldots\\in\\mathcal{F}\\) are disjoint (a.k.a. mutually exclusive) — that is \\(A_i\\cap A_j = \\emptyset\\) for all \\(i\\neq j\\) — then \\[\\begin{equation*} \\textrm{P}\\left(\\bigcup_{i=1}^\\infty A_i\\right) = \\sum_{i=1}^\\infty \\textrm{P}\\left(A_i\\right) \\end{equation*}\\] A probability space puts all the objects we have seen in this chapter together in a model for the random phenomenon. Even though random variables are not an explicit component of a probability space, remember that many events of interest are defined in terms of random variables. Think of a probability space as the collection of all outcomes, events, and random variables associated with a random phenomenon along with the probabilities of all events of interest. A probability measure is a set function: \\(\\textrm{P}:\\mathcal{F}\\mapsto[0, 1]\\) takes as an input an event (set) \\(A\\) (from the collection of events of interest \\(\\mathcal{F}\\)) and returns as an output a number \\(\\textrm{P}(A)\\in[0,1]\\) quantifying the probability of the event. The requirement \\(0\\le \\textrm{P}(A)\\le 1\\) makes sense in light of the relative frequency interpretation: an event \\(A\\) can not occur on more than 100% of repetitions or less than 0% of repetitions of the random phenomenon. The requirement that \\(\\textrm{P}(\\Omega)=1\\) just ensures that the sample space accounts for all of the possible outcomes. If outcome \\(\\omega\\) is observed, then event \\(A\\) occurs if \\(\\omega\\in A\\). If \\(\\textrm{P}(\\Omega)&lt;1\\) then it would be possible to observe outcomes \\(\\omega\\notin \\Omega\\); but this violates the requirement that \\(\\Omega\\) is the set of all possible outcomes. Basically, \\(\\textrm{P}(\\Omega)=1\\) says that on any repetition of the random phenomenon, “something has to happen”. If \\(\\Omega\\) is a countable set, countable additivity and \\(\\textrm{P}(\\Omega)=1\\) imply that probability of all the outcomes must add up to 1. For example, in Example 1.1 \\(\\textrm{P}(\\Omega)=1\\), together with countable additivity, is what requires that the probability that a team other than those four teams win to be 26%. Countable additivity is best understood through a diagram with areas representing probabilities, as in the figure below which represents two events (yellow / and blue \\). On the left, there is no “overlap” between areas so the total area is the sum of the two pieces; this depicts countable additivity for two disjoint events. On the right, there is overlap between the two areas, so simply adding the two areas “double counts” the intersection (green \\(\\times\\)) and does not result in the correct total area. Countable additivity applies to any countable number26 of events, as long as there is no “overlap”. Figure 2.7: Illustration of countable additivity for two events. The events in the picture on the left are disjoint, but not on the right. In Example 1.1, the events \\(A\\)=“the Astros win the 2020 World Series” and \\(D\\)=“the Dodgers win the 2020 World Series” are disjoint \\(A\\cap D = \\emptyset\\); in a single World Series, both teams cannot win. Therefore, the probability of \\(A\\cup D\\), the event that either the Astros or the Dodgers win, must be 46%. The three axioms of a probability measure are minimal logical consistency requirements that must be satisfied by any probability model. There are also many physical aspects of the random phenomenon or assumptions (e.g. “fairness”, independence, conditional relationships) that must be considered when determining a reasonable probability measure for a particular situation. Sometimes \\(\\textrm{P}(A)\\) is defined explicitly for an event \\(A\\) via a formula. But it is much more common for a probability measure to be defined only implicitly through modeling assumptions; probabilities of events then follow from the axioms and related properties. Probabilities are always defined for events (sets) but remember than many events are defined in terms of random variables. For example, if \\(X\\) is tomorrow’s high temperature (degrees F) we might be interested in \\(\\textrm{P}(\\{X&gt;80\\})\\), the probability of the event that tomorrow’s high temperature is above 80 degrees F. If \\(Y\\) is the amount of rainfall tomorrow (inches) we might be interested in \\(\\textrm{P}(\\{X &gt; 80\\}\\cap \\{Y &lt; 2\\})\\), the probability of the event that tomorrow’s high temperature is above 80 degrees F and the amount of rainfall is less than 2 inches. To simplify notation, it is common to write \\(\\textrm{P}(X&gt;80)\\) instead of \\(\\textrm{P}(\\{X&gt;80\\})\\), or \\(\\textrm{P}(X &gt; 80, Y &lt; 2)\\) instead of \\(\\textrm{P}(\\{X &gt; 80\\}\\cap \\{Y &lt; 2\\})\\). (Read the comma in \\(\\textrm{P}(X &gt; 80, Y &lt; 2)\\) as “and”.) But keep in mind that an expression like “\\(X&gt;80\\)” really represents an event \\(\\{X&gt;80\\}\\), an expression which itself represents \\(\\{\\omega\\in\\Omega: X(\\omega) &gt; 80\\}\\), a subset of the sample space \\(\\Omega\\). In the next few sections we’ll work with some actual numerical probabilities. But let’s first pause to think about some of the concepts we have seen so far. It’s easy to get confused between things like events, random variables, and probabilities, and the symbols that represent them. But a strong understanding of these fundamental concepts will help you solve probability problems. Examples like the following do more than encourage proper use of notation. Explaining to Donny why he is wrong will help you better understand the objects that symbols represent, how they are different from one another, and how they connect to real-world contexts. Example 2.30 (Don’t do what Donny Don’t does.) At various points in his homework, Donny Don’t writes the following. Explain to Donny why each of the following symbols is nonsense, both mathematically and intuitively using a simple example (like tomorrow’s weather). Below, \\(A\\) and \\(B\\) represent events, \\(X\\) and \\(Y\\) represent random variables. \\(\\textrm{P}(A = 0.5)\\) \\(\\textrm{P}(A + B)\\) \\(\\textrm{P}(A) \\cup \\textrm{P}(B)\\) \\(\\textrm{P}(X)\\) \\(\\textrm{P}(X = A)\\) \\(\\textrm{P}(X \\cap Y)\\) Solution. to Example 2.30 We’ll respond to Donny using tomorrow’s weather as an example, with \\(A\\) representing the event that it rains tomorrow, \\(X\\) tomorrow’s high temperature (degrees F), \\(B=\\{X&gt;80\\}\\) the event that tomorrow’s high temperature is above 80 degrees, and \\(Y\\) tomorrow’s rainfall (inches). \\(A\\) is a set and 0.5 is a number; it doesn’t make mathematical sense to equate them. It doesn’t make sense to say “it rains tomorrow equals 0.5”. Donny probably means “the probability that it rains tomorrow equals 0.5” which he should write as \\(\\textrm{P}(A) = 0.5\\). \\(A\\) and \\(B\\) are sets; it doesn’t make mathematical sense to add them. What Donny has written reads as “the probability that it rains tomorrow or the probability that tomorrow’s high temperature is above 80 degrees F,” which doesn’t make much sense. Donny probably means “the probability that (it rains tomorrow) or (tomorrow’s high temperature is above 80 degrees),” which he should write as \\(\\textrm{P}(A \\cup B)\\). (Mathematically, \\(\\textrm{P}(A)\\) and \\(\\textrm{P}(B)\\) are numbers while union is an operation on sets, so it doesn’t make mathematical sense to take a union of numbers.) Donny might have meant to write \\(\\textrm{P}(A) + \\textrm{P}(B)\\), which is valid expression since \\(\\textrm{P}(A)\\) and \\(\\textrm{P}(B)\\) are numbers. However, he should keep in mind that \\(\\textrm{P}(A) + \\textrm{P}(B)\\) is not necessarily a probability of anything; this sum could even be greater than one. In particular, since there are some rainy days with high temperatures above 80 degrees — that is, \\(A\\) and \\(B\\) are not disjoint — \\(\\textrm{P}(A) + \\textrm{P}(B)\\) is greater than \\(\\textrm{P}(A\\cup B)\\). (See the general addition rule and related discussion in Section 2.4.2.) \\(\\textrm{P}(A)\\) and \\(\\textrm{P}(B)\\) are numbers; union is an operation on sets, and it doesn’t make mathematical sense to take a union of numbers. See the previous part for related discussion. \\(X\\) is a random variable, and probabilities are assigned to events. \\(P(X)\\) reads “the probability that tomorrow’s high temperature in degrees F”, a subject in need of a predicate; the phrase is missing any qualifying information that could define an event . We assign probabilities to things that could happen (events) like “tomorrow’s high temperature is above 80 degrees,” which has probability \\(\\textrm{P}(X &gt; 80)\\). \\(X\\) is a random variable (a function) and \\(A\\) is an event (a set), and it doesn’t make sense to equate these two different mathematical objects. It doesn’t make sense to say “tomorrow’s high temperature in degrees F equals the event that it rains tomorrow”. We’re not sure what Donny was thinking here. \\(X\\) and \\(Y\\) are RVs (functions) and intersection is an operation on sets. \\(X \\cap Y\\) is attempting to say “tomorrow’s high temperature in degrees F and the amount of rainfall in inches tomorrow”, but this is still missing qualifying information to define a valid event for which a probability can be assigned. We could say \\(\\textrm{P}(X &gt; 80, Y &lt; 2)\\) to represent “the probability that (tomorrow’s high temperature is greater than 80 degrees F) AND (the amount of rainfall tomorrow is less than 2 inches)”. (Remember,“\\(X &gt; 80, Y &lt; 2\\)” is short for the event \\(\\{X &gt; 80\\} \\cap \\{Y &lt; 2\\}\\) 2.4.1 Some probability measures for a roll of a four-sided Consider a single roll of a four-sided die. The sample space consists of four possible outcomes \\(\\Omega = \\{1, 2, 3, 4\\}\\). Recall that we identified all possible events in Section 2.2.1. Let’s first assume that the die is fair, so all four outcomes are equally likely, each with probability27 1/4. Given that the probability of each outcome28 is 1/4, countable additivity implies \\[ \\textrm{P}(A) = \\frac{\\text{number of elements in $A$}}{4}, \\qquad{\\text{$\\textrm{P}$ assumes a fair four-sided die}} \\] Table 2.7 lists all the possible events, and their probabilities according to the probability measure \\(\\textrm{P}\\). Table 2.7: All possible events associated with a single roll of a four-sided die, and their probabilities assuming the die is fair. Event Description Probability of event assuming equally likely outcomes \\(\\emptyset\\) Roll nothing (not possible) 0 \\(\\{1\\}\\) Roll a 1 1/4 \\(\\{2\\}\\) Roll a 2 1/4 \\(\\{3\\}\\) Roll a 3 1/4 \\(\\{4\\}\\) Roll a 4 1/4 \\(\\{1, 2\\}\\) Roll a 1 or a 2 2/4 \\(\\{1, 3\\}\\) Roll a 1 or a 3 2/4 \\(\\{1, 4\\}\\) Roll a 1 or a 4 2/4 \\(\\{2, 3\\}\\) Roll a 2 or a 3 2/4 \\(\\{2, 4\\}\\) Roll a 2 or a 4 2/4 \\(\\{3, 4\\}\\) Roll a 3 or a 4 2/4 \\(\\{1, 2, 3\\}\\) Roll a 1, 2, or 3 (a.k.a. do not roll a 4) 3/4 \\(\\{1, 2, 4\\}\\) Roll a 1, 2, or 4 (a.k.a. do not roll a 3) 3/4 \\(\\{1, 3, 4\\}\\) Roll a 1, 3, or 4 (a.k.a. do not roll a 2) 3/4 \\(\\{2, 3, 4\\}\\) Roll a 2, 3, or 4 (a.k.a. do not roll a 1) 3/4 \\(\\{1, 2, 3, 4\\}\\) Roll something 1 The above assignment satisfies all the axioms and so it represents a valid probability measure. But assuming that the outcomes are equally likely is a much stricter assumption than the basic logical consistency requirements of the axioms. There are many other possible probability measures, like in the following. Example 2.31 Now consider a single roll of a four-sided die, but suppose the die is weighted so that the outcomes are no longer equally likely. Suppose that the probability of event \\(\\{2, 3\\}\\) is 0.5, of event \\(\\{3, 4\\}\\) is 0.7, and of event \\(\\{1, 2, 3\\}\\) is 0.6. Complete a table, like Table 2.7, listing the probability of each event for this particular weighted die. In what particular way is the die weighted? That is, what is the probability of each the four possible outcomes? Solution. to Example 2.31 Since the probability of not rolling a 4 is 0.6, the probability of rolling a 4 must be 0.4. Since \\(\\{3, 4\\} = \\{3\\} \\cup \\{4\\}\\), a union of disjoint sets, the probability of rolling a 3 must be 0.3. Similarly, the probability of rolling a 2 must be 0.2, and the probability of rolling a 1 must be 0.1. From there we can find the probabilities of all possible events for this particular weighted die, displayed in Table 2.8. Table 2.8: All possible events associated with a single roll of a four-sided die, and their probabilities assuming the die is weighted: roll a 1 with probability 0.1, 2 with probability 0.2, 3 with probability 0.3, 4 with probability 0.4. Event Description Probability of event assuming a particular weighted die \\(\\emptyset\\) Roll nothing (not possible) 0 \\(\\{1\\}\\) Roll a 1 0.1 \\(\\{2\\}\\) Roll a 2 0.2 \\(\\{3\\}\\) Roll a 3 0.3 \\(\\{4\\}\\) Roll a 4 0.4 \\(\\{1, 2\\}\\) Roll a 1 or a 2 0.3 \\(\\{1, 3\\}\\) Roll a 1 or a 3 0.4 \\(\\{1, 4\\}\\) Roll a 1 or a 4 0.5 \\(\\{2, 3\\}\\) Roll a 2 or a 3 0.5 \\(\\{2, 4\\}\\) Roll a 2 or a 4 0.6 \\(\\{3, 4\\}\\) Roll a 3 or a 4 0.7 \\(\\{1, 2, 3\\}\\) Roll a 1, 2, or 3 (a.k.a. do not roll a 4) 0.6 \\(\\{1, 2, 4\\}\\) Roll a 1, 2, or 4 (a.k.a. do not roll a 3) 0.7 \\(\\{1, 3, 4\\}\\) Roll a 1, 3, or 4 (a.k.a. do not roll a 2) 0.8 \\(\\{2, 3, 4\\}\\) Roll a 2, 3, or 4 (a.k.a. do not roll a 1) 0.9 \\(\\{1, 2, 3, 4\\}\\) Roll something 1 The symbol \\(\\textrm{P}\\) is more than just shorthand for the word “probability”. \\(\\textrm{P}\\) denotes the underlying probability measure, which represents all the assumptions about the random phenomenon. Changing assumptions results in a change of the probability measure and a different probability model. We often consider several probability measures for the same sample space and collection of events; these several measures represent different sets of assumptions and different probability models. In the dice example above, suppose \\(\\textrm{P}\\) represents the probability measure corresponding to the assumption of a fair die (equally likely outcomes). With this measure \\(\\textrm{P}(A) = 2/4\\) for \\(A = \\{1, 2\\}\\). Now let \\(\\textrm{Q}\\) represent the probability measure corresponding to the assumption of the weighted die; then \\(\\textrm{Q}(A) = 0.3\\). The outcomes and events are the same in both scenarios, because both scenarios involve a four sided-die. What is different is the probability measure that assigns probabilities to the events. One scenario assumes the die is fair while the other assumes the die has a particular weighting, resulting in two different probability measures. Both probability measures in the dice example could be written as explicit set functions: for an event \\(A\\) \\[\\begin{align*} \\textrm{P}(A) &amp; = \\frac{\\text{number of elements in $A$}}{4}, &amp; &amp; {\\text{$\\textrm{P}$ assumes a fair four-sided die}} \\\\ \\textrm{Q}(A) &amp; = \\frac{\\text{sum of elements in $A$}}{10}, &amp; &amp; {\\text{$\\textrm{Q}$ assumes a particular weighted four-sided die}} \\end{align*}\\] We provide the above descriptions to illustrate that a probability measure operates on sets. However, in many situations there does not exist a simple closed form expression for the set function defining the probability measure which maps events to probabilities. Example 2.32 Consider again a single roll of a weighted four-sided die. Suppose that Rolling a 1 is twice as likely as rolling a 4 Rolling a 2 is three times as likely as rolling a 4 Rolling a 3 is 1.5 times as likely as rolling a 4 Let \\(\\tilde{\\textrm{Q}}\\) be the probability measure corresponding to this die. Compute \\(\\tilde{\\textrm{Q}}(A)\\) for each event in Table 2.7. In what particular way is the die weighted? That is, what is the probability of each the four possible outcomes? Solution. to Example 2.32. Let \\(q = \\tilde{\\textrm{Q}}(\\{4\\})\\) denote the probability of rolling a 4. Then \\(\\tilde{\\textrm{Q}}(\\{1\\}) = 2q\\), \\(\\tilde{\\textrm{Q}}(\\{2\\}) = 3q\\), and \\(\\tilde{\\textrm{Q}}(\\{3\\}) = 1.5q\\). Since these probabilities must sum to 1, we have \\(2q + 3q + 1.5q + q = 1\\) so \\(q = 2/15\\). From there we can find the probabilities of all possible events for this particular weighted die, displayed in Table 2.9. Note this probability measure does not have a simple closed formula for \\(\\tilde{\\textrm{Q}}(A)\\). Table 2.9: All possible events associated with a single roll of a four-sided die, and their probabilities assuming the die is weighted: roll a 1 with probability 4/15, 2 with probability 6/15, 3 with probability 3/15, 4 with probability 2/15. Event Description Probability of event assuming a particular weighted die \\(\\emptyset\\) Roll nothing (not possible) 0 \\(\\{1\\}\\) Roll a 1 4/15 \\(\\{2\\}\\) Roll a 2 6/15 \\(\\{3\\}\\) Roll a 3 3/15 \\(\\{4\\}\\) Roll a 4 2/15 \\(\\{1, 2\\}\\) Roll a 1 or a 2 10/15 \\(\\{1, 3\\}\\) Roll a 1 or a 3 7/15 \\(\\{1, 4\\}\\) Roll a 1 or a 4 6/15 \\(\\{2, 3\\}\\) Roll a 2 or a 3 9/15 \\(\\{2, 4\\}\\) Roll a 2 or a 4 8/15 \\(\\{3, 4\\}\\) Roll a 3 or a 4 5/15 \\(\\{1, 2, 3\\}\\) Roll a 1, 2, or 3 (a.k.a. do not roll a 4) 13/15 \\(\\{1, 2, 4\\}\\) Roll a 1, 2, or 4 (a.k.a. do not roll a 3) 12/15 \\(\\{1, 3, 4\\}\\) Roll a 1, 3, or 4 (a.k.a. do not roll a 2) 9/15 \\(\\{2, 3, 4\\}\\) Roll a 2, 3, or 4 (a.k.a. do not roll a 1) 11/15 \\(\\{1, 2, 3, 4\\}\\) Roll something 1 The dice rolling example is not the most exciting or practical scenario. But the example does illustrate the idea of several probability measures, each corresponding to a different set of assumptions about the random phenomenon. If it’s difficult to imagine how to physically weight a die in these particular ways, consider the spinners (like from a kids game) in 2.8. Figure 2.8: Three possible spinners corresponding to the roll of a four-sided die. Left: a fair die. Middle: the weighted die of Example 2.31. Right: the weighted die of Example 2.32. Perhaps the concept of multiple potential probability measures is easier to understand in a subjective probability situation. For example, each model that is used to forecast the 2020-2021 NFL season corresponds to a probability measure which assigns probabilities to events like “the Eagles win the 2021 Superbowl”. Different sets of assumptions and models can assign different probabilities for the same events. As another example, the weather forecaster on one local news station might report that the probability of rain tomorrow is 0.6, while an online source might report it as 0.5. Each weather forecasting model corresponds to a different probability measure which encodes a set of assumptions about the random phenomenon. A single probability measure corresponds to a particular set of assumptions about the random phenomenon. There can be many probability measures defined on a single sample space, each one corresponding to a different probability model for the random phenomenon. Probabilities of events can change if the probability measure changes. 2.4.2 Properties of probability measures Many other properties follow from the axioms. The main “meat” of the axioms is countable additivity. Thus, the key to many proofs of probability properties is to write relevant events in terms of disjoint events. Theorem 2.1 (Properties of a probability measure.) Complement rule29. For any event \\(A\\), \\(\\textrm{P}(A^c) = 1 - \\textrm{P}(A)\\). In particular, since \\(\\Omega^c=\\emptyset\\), \\(\\textrm{P}(\\emptyset)=0\\). Subset rule30. If \\(A \\subseteq B\\) then \\(\\textrm{P}(A) \\le \\textrm{P}(B)\\). General addition rule for two events31. If \\(A\\) and \\(B\\) are any two events \\[\\begin{align*} \\textrm{P}(A\\cup B) = \\textrm{P}(A) + \\textrm{P}(B) - \\textrm{P}(A \\cap B) \\end{align*}\\] Law of total probability. If \\(B_1,\\ldots, B_k\\) are disjoint with \\(B_1\\cup \\cdots \\cup B_k=\\Omega\\), then \\[\\begin{align*} \\textrm{P}(A) &amp; = \\sum_{i=1}^k \\textrm{P}(A \\cap B_i) \\end{align*}\\] The key to the proofs is to represent relevant events in terms of disjoint events and use countable additivity (and the other axioms). Example 2.33 Donny Don’t says: “Wait a minute. You said unions are inclusive; \\(\\textrm{P}(A\\cup B)\\) means the probability of \\(A\\) or \\(B\\) OR BOTH. So \\(\\textrm{P}(A\\cup B)\\) should just be \\(\\textrm{P}(A)+\\textrm{P}(B)\\).” Explain to Donny his mistake, using the picture on the right in Figure 2.7 as an example. Solution. to Example 2.33. \\(A\\cup B\\) is inclusive so we do want to count the possibility of both, \\(A\\cap B\\). The problem with simply adding \\(\\textrm{P}(A)\\) and \\(\\textrm{P}(B)\\) is that their sum double counts \\(A \\cap B\\). We do want to count the outcomes that satisfy both \\(A\\) and \\(B\\), but we only want to count them once. Subtracting \\(\\textrm{P}(A \\cap B)\\) in the general addition rule for two events corrects for the double counting. For example, consider the picture on the right in Figure 2.7. Suppose each rectangular cell represents a distinct outcome; there are 16 outcomes in total. Assume the outcomes are equally likely, each with probability \\(1/16\\). Let \\(A\\) represent the yellow / event which has probability \\(4/16\\) and let \\(B\\) represent the blue \\ event which has probability 4/16. Then \\(\\textrm{P}(A\\cup B) = 6/16\\), since there are 6 outcomes which satisfy either event \\(A\\) or \\(B\\) (or both). However, simply adding \\(\\textrm{P}(A)+\\textrm{P}(B)\\) yields \\(8/16\\) because the two outcomes that satisfy the green event \\(A\\cap B\\) are counted both in \\(\\textrm{P}(A)\\) and \\(\\textrm{P}(B)\\). So to correct for this double counting, we subtract out \\(\\textrm{P}(A\\cap B)\\): \\[ \\textrm{P}(A)+\\textrm{P}(B)-\\textrm{P}(A\\cap B) = 4/16 + 4/16 -2/16 = 6/16 = \\textrm{P}(A\\cup B) \\] Warning: The general addition rule for more than two events is more complicated32; see the inclusion-exclusion principle. In the law of total probability the events \\(B_1, \\ldots, B_k\\), which represent “cases”, form a partition of the sample space; each outcome \\(\\omega\\in\\Omega\\) lies in exactly one of the \\(B_i\\). The law of total probability says that we can interpret the “overall” probability \\(\\textrm{P}(A)\\) by summing the probability of \\(A\\) in each “case” \\(\\textrm{P}(A\\cap B_i)\\). (We will see a different and more useful expression of the law of total probability, involving conditional probabilities, in Section ??.) Example 2.34 Computer monitors are given a final inspection following assembly. Three types of defects are identified as minor, major, and critical and are coded \\(A\\), \\(B\\), and \\(C\\), respectively. The following data are found through the inspection: 15% have minor defects 12% have major defects 10% have critical defects 4% have both minor and major defects 5% have both minor and critical defects 4% have both major and critical defects 1% have all three types of defects Use a Venn diagram below and the information above to partition the sample space into 8 disjoint regions, along with their probabilities. (Hint: Work your way out from the center.) One of the 8 pieces of the partition has a probability of 0.07. Identify the event in symbols, and then interpret the event in words. Find the probability that a randomly selected computer monitor has at least one of these three types of defects. Find the probability that a randomly selected computer monitor has no defects. Find the probability that a randomly selected computer monitor has exactly one of these three types of defects. Find the probability that a randomly selected computer monitor has either a minor or major defect (or both), but not a critical defect. Solution. to Example 2.34. The following example involves random selecting a U.S. household. Note that while “randomly select” is commonly used terminology, it is not the best wording. Remember that “random” simply means uncertain, so technically “randomly select” just means selecting in a way that the outcome is uncertain. Suppose I want to “randomly select” one of two households, A or B. I could put 10 tickets in a hat, with 9 labeled A and 1 labeled B, and then draw a ticket; this is random selection because the outcome of the draw is uncertain. However, what is often meant by “randomly select” is selecting in a way that each outcome is equally likely. To give households A and B the same chance of being selected, I would put a single ticket for each in the hat. Randomly selecting in a way that each outcome is equally likely could be described more precisely as “selecting uniformly at random”. (We discuss equally likely outcomes in more detail starting in Section 2.4.3.) Example 2.35 The probability that a randomly selected U.S. household has a pet dog is 0.47. The probability that a randomly selected U.S. household has a pet cat is 0.25. (These values are based on the 2018 General Social Survey (GSS).) Represent the information provided using proper symbols. Donny Don’t says: “the probability that a randomly selected U.S. household has a pet dog OR a pet cat is \\(0.47 + 0.25=0.72\\).” Do you agree? What must be true for Donny to be correct? Explain. What is the largest possible value of the probability that a randomly selected U.S. household has a pet dog AND a pet cat? Describe the (unrealistic) situation in which this extreme case would occur. (Hint: for the remaining parts it helps to consider two-way tables.) What is the smallest possible value of the probability that a randomly selected U.S. household has a pet dog AND a pet cat? Describe the (unrealistic) situation in which this extreme case would occur. Donny Don’t says: “I remember hearing once that in probability OR means add and AND means multiply. So the probability that a randomly selected U.S. household has a pet dog AND a pet cat is \\(0.47 \\times 0.25=0.1175\\).” Do you agree? Explain. According to the GSS, the probability that a randomly selected U.S. household has a pet dog AND a pet cat is \\(0.15\\). Compute the probability that a randomly selected U.S. household has a pet dog OR a pet cat. Solution. to Example 2.35. The sample space consists of U.S. households. Let \\(C\\) be the event that the household has a pet cat, and let \\(D\\) be the event that the household has a pet dog. Let \\(\\textrm{P}\\) be the probability measure corresponding to randomly selecting a U.S. household. (The probability measure corresponds to however the random selection is done; though not specified, it’s assumed to be uniformly at random.) Then \\(\\textrm{P}(C) = 0.25\\) and \\(\\textrm{P}(D) = 0.47\\). Donny would be correct if the events \\(C\\) and \\(D\\) were disjoint, which would only be true if the probability that a randomly selected U.S. household has a pet dog AND a pet cat were 0. This is unrealistic, since I’m sure you know households (maybe even your own!) that have both pet cats and dogs. \\(\\textrm{P}(C \\cup D) = \\textrm{P}(C) + \\textrm{P}(D) - \\textrm{P}(C \\cap D) = 0.25 + 0.42 - \\textrm{P}(C\\cap D)\\). So \\(\\textrm{P}(C\\cup D)\\) is the largest it can be when \\(\\textrm{P}(C \\cap D)\\) is the smallest it can be. The smallest \\(\\textrm{P}(C \\cap D)\\) can be is 0, and hence the largest \\(\\textrm{P}(C\\cup D)\\) can be is 0.72, which would only be true if no households had both a pet cat and a pet dog. The following two-way table of percents represents this unrealistic scenario. D not D Total C 0 25 25 not C 47 28 75 Total 47 53 100 \\(\\textrm{P}(C \\cup D) = \\textrm{P}(C) + \\textrm{P}(D) - \\textrm{P}(C \\cap D) = 0.25 + 0.42 - \\textrm{P}(C\\cap D)\\). \\(\\textrm{P}(C\\cup D)\\) is the smallest it can be when \\(\\textrm{P}(C \\cap D)\\) is the largest it can be. The probability that the household has both a pet cat and a pet dog can not be larger than either of the two component probabilities; that is \\(\\textrm{P}(C\\cap D)\\le \\textrm{P}(C) = 0.25\\) and \\(\\textrm{P}(C\\cap D)\\le \\textrm{P}(D) = 0.42\\). The largest \\(\\textrm{P}(C \\cap D)\\) can be is 0.25, and hence the smallest \\(\\textrm{P}(C\\cup D)\\) can be is 0.42, which would only be true if every household that has a pet cat also has a pet dog. The following two-way table of percents represents this unrealistic scenario. D not D Total C 25 0 25 not C 22 53 75 Total 47 53 100 Tell Donny to check the axioms of probability. There is no requirement that the probability of an intersection must be the product of the probabilities. The two previous parts show that \\(0\\le \\textrm{P}(C \\cap D) \\le 0.25\\), but without further information we can’t determine the value of \\(\\textrm{P}(C\\cap D)\\). It helps to think it in percentage terms. The extreme of 0 occurs when 0% of households with a pet cat also have a pet dog; the extreme of 0.25 occurs when 100% of households with a pet cat also have a pet dog. We might expect that that the true value of \\(\\textrm{P}(C \\cap D)\\) depends on the actual percentage of households with a pet cat that also have a pet dog. Without knowing that percentage (or equivalent information), we cannot determine \\(\\textrm{P}(C \\cap D)\\). (We will explore this topic in more depth in Chapter XXX.) \\(\\textrm{P}(C \\cup D) = \\textrm{P}(C) + \\textrm{P}(D) - \\textrm{P}(C \\cap D) = 0.25 + 0.42 - 0.15 = 0.52\\). Notice that this is between the hypothetical extremes of 0.42 and 0.72. Also notice that the actual \\(\\textrm{P}(C \\cap D)\\) is between the hypothetical extremes of 0 and 0.25, but it is not equal to the product of 0.25 and 0.42. The moral is that we are not able to compute probabilities involving both events (\\(\\textrm{P}(C\\cup D)\\), \\(\\textrm{P}(C \\cap D\\))) based on the probability of each event alone. The following two-way table of percents represents the actual scenario. D not D Total C 15 10 25 not C 32 43 75 Total 47 53 100 Probabilities involving multiple events, such as \\(\\textrm{P}(A \\cap B)\\) or \\(\\textrm{P}(X&gt;80, Y&lt;2)\\), are often called joint probabilities. Note that the axioms do not specify any direct requirements on probabilities of intersections. In particular, is not necessarily true that \\(\\textrm{P}(A\\cap B)\\) equals \\(\\textrm{P}(A)\\textrm{P}(B)\\). It is true that probabilities of intersections can be obtained by multiplying, but the product generally involves at least one conditional probability that reflects any association between the events involved. In general, joint probabilities (\\(\\textrm{P}(A \\cap B)\\)) can not be computed based on the individual probabilities (\\(\\textrm{P}(A)\\), \\(\\textrm{P}(B)\\)) alone. We will explore this topic in more depth in Chapter XXX. Exercise 2.1 Consider a Cal Poly student who frequently has blurry, bloodshot eyes, generally exhibits slow reaction time, always seems to have the munchies, and disappears at 4:20 each day. Which of the following events, \\(A\\) or \\(B\\), has a higher probability? (Assume the two probabilities are not equal.) \\(A\\): The student has a GPA above 3.0. \\(B\\): The student has a GPA above 3.0 and smokes marijuana regularly. Warning! Your psychological judgment of probabilities is often inconsistent with the mathematical logic of probabilities. 2.4.3 Equally likely outcomes Sometimes a probability \\(\\textrm{P}(A)\\) is defined explicitly for an event \\(A\\) via a formula. For example, in the case of a finite sample space with equally likely outcomes, \\[ \\textrm{P}(A) = \\frac{|A|}{|\\Omega|} = \\frac{\\text{number of outcomes in $A$}}{\\text{number of outcomes in $\\Omega$}} \\qquad{\\text{when outcomes are equally likely}} \\] Example 2.36 Consider the outcome of a sequence of 4 flips of a coin. Recall the sample space from Example 2.2 consisting of 16 possible outcomes. Let \\(X\\) be the number of H. One choice of probability measure \\(\\textrm{P}\\) corresponds to assuming the 16 possible outcomes are equally likely, consistent with the assumption that the coin is fair and the flips are independent. (We’ll discuss independence in Section XXX.) Specify the probability of each individual outcome, e.g. \\(\\{HHTH\\}\\). Find \\(\\textrm{P}(E_1)\\), the event that the first flip results in heads. (Hint: remember the sample space.) Find \\(\\textrm{P}(E_2)\\), the event that the second flip results in heads. Find and interpret \\(\\textrm{P}(E_1 \\cup E_2)\\). (Can you do it two ways?) Find and interpret \\(\\textrm{P}(X=3)\\). Find and interpret \\(\\textrm{P}(X = 4)\\). Find and interpret \\(\\textrm{P}(X \\ge 3)\\). (Can you do it two ways?) We assumed the 16 outcomes are equally likely. Do the axioms or probability require this assumption? Are the possible values are \\(X\\) equally likely? Provide a “long run relative frequency” interpretation of \\(\\textrm{P}(X = 3)\\). Solution. to Example 2.36 The sample space is composed of 16 outcomes which are assumed to be equally likely, so the probability of each outcome is 1/16. Intuitively this is 1/2, but sample space outcomes consist of sequences of four coin flips, so we should define the proper event. \\[ E_1 = \\{HHHH, HHHT, HHTH, HTHH, HHTT, HTHT, HTTH, HTTT\\} \\] So \\(\\textrm{P}(E_1) = 8/16 = 1/2\\). Similar to the previous part. \\[ E_2 = \\{HHHH, HHHT, HHTH, THHH, HHTT, THHT, THTH, THTT\\} \\] So \\(\\textrm{P}(E_2) = 8/16 = 1/2\\). \\(E_1 \\cup E_2\\) is the event that at least one of the first two flips is heads. We can identify the event and compute its probability directly. \\[\\begin{align*} E_1 \\cup E_2 &amp; = \\{HHHH, HHHT, HHTH, HTHH, THHH, HHTT, \\\\ &amp; \\quad HTHT, HTTH, THHT, THTH, HTTT, THTT\\} \\end{align*}\\] So \\(\\textrm{P}(E_1 \\cup E_2) = 12/16\\). Note that \\(\\textrm{E}_1\\) and \\(\\textrm{E}_2\\) are not disjoint — it is possible for the first two flips to both be H — so we cannot just add their probabilities. But we can use the general addition rule for two events. \\[ E_1 \\cap E_2 = \\{HHHH, HHHT, HHTH, HHTT\\} \\] So \\(\\textrm{P}(E_1 \\cup E_2) = \\textrm{P}(E_1) + \\textrm{P}(E_2) - \\textrm{P}(E_1 \\cap E_2) = 8/16 + 8/16 - 4/16 = 12/16\\). \\(\\{X=3\\} = \\{HHHT, HHTH, HTHH, THHH\\}\\) is the event that exactly 3 of the flips land on heads, so \\(\\textrm{P}(X=3) = 4/16\\). \\(\\{X=4\\} = \\{HHHH\\}\\), an event consisting of a single outcome, so \\(\\textrm{P}(X=4) = 1/16\\). Directly, \\(\\{X \\ge 3\\} = \\{HHHT, HHTH, HTHH, THHH, HHHH\\}\\), so \\(\\textrm{P}(X\\ge 3) = 5/16\\). Also \\(\\{X\\ge 3\\}=\\{X=3\\}\\cup\\{X=4\\}\\), a union of disjoint events, so \\(\\textrm{P}(X \\ge 3) = \\textrm{P}(X = 3) + \\textrm{P}(X = 4) = 4/16 + 1/16 = 5/16\\). No, the axioms do not require equally likely outcomes. If, for example, the coin were biased in favor of landing on Heads, we would want a different probability measure. No, \\(\\textrm{P}(X=3)\\neq \\textrm{P}(X = 4)\\). Even though the underlying sample space outcomes are equally likely, the possible values of \\(X\\) are not. Over many sets of 4 flips of a fair coin the number of H will be equal to 3 in about 25% of sets. Remember that events often involve random variables. Even if the sample space outcomes are equally likely, the possible values of related random variables might not be. Example 2.37 (Matching problem) Recall the “matching problem”. A geology museum in California has four different rocks sitting in a row on a shelf, with labels on the shelf telling what type of rock each is. An earthquake hits and the rocks all fall off the shelf and get mixed up. A janitor comes in and, wanting to clean the floor, puts the rocks back on the shelf in random order. Recall the sample space from Example 2.3. Let the random variable \\(Y\\) count the number of rocks that are put back in the correct spot. (Hint: recall Table 2.6.) Let \\(\\textrm{P}\\) denote the probability measure corresponding to the assumption that the janitor is equally likely to put any rock in any spot, so that the 24 possible placements are equally. Find \\(\\textrm{P}(Y=0)\\). What are the possible values of \\(Y\\)? Make a table displaying \\(\\textrm{P}(Y=y)\\) for each possible value of \\(y\\). Let \\(C\\) be the event that at least one rock is put in the correct spot. Find \\(\\textrm{P}(C)\\). Let \\(C_1\\) be the event that rock 1 (say the heaviest rock) is put correctly in spot 1. Find \\(\\textrm{P}(C_1)\\). Let \\(C_2\\) be the event that rock 2 (say the next heaviest rock) is put correctly in spot 2. Find \\(\\textrm{P}(C_2)\\). Define \\(C_3\\), and \\(C_4\\) similarly. Represent the event \\(C\\) in terms of \\(C_1, C_2, C_3, C_4\\). Find and interpret \\(\\textrm{P}(C_1\\cap C_2 \\cap C_3 \\cap C_4)\\). Donny Don’t says: “the events are not disjoint so by the general addition rule \\(\\textrm{P}(C_1 \\cup C_2 \\cup C_3 \\cup C_4)\\) is equal to \\(\\textrm{P}(C_1)+\\textrm{P}(C_2)+\\textrm{P}(C_3)+\\textrm{P}(C_4)-\\textrm{P}(C_1\\cap C_2 \\cap C_3 \\cap C_4)\\).” Explain to Donny his mistake. Solution. to Example 2.37 Each of the 24 outcomes in Table 2.6 is equally likely. There are 9 outcomes for which \\(Y=0\\), so \\(\\textrm{P}(Y=0)=9/24=0.375\\). The possible values of \\(Y\\) are 0, 1, 2, 4. \\(Y\\) cannot be 3, since if 3 rocks are in the correct spot, then the fourth must be too. \\(\\textrm{P}(Y=y)\\) for \\(y=0, 1, 2, 4\\) can be found as in the previous part. See Table 2.10. Table 2.10: Probability of each possible value of the number of matches, \\(Y\\), in the matching problem in Example 2.37. y P(Y=y) 0 0.3750 1 0.3333 2 0.2500 4 0.0417 \\(C=\\{Y\\ge 1\\}\\) is the event that at least one rock is put in the correct spot. \\(\\textrm{P}(Y \\ge 1) = 1-\\textrm{P}(Y=0)=1-9/24 = 15/24 = 0.625\\). Intuitively, \\(\\textrm{P}(C_1)=1/4\\) since rock 1 is equally likely to be put in any of the 4 spots. In terms of the sample space outcomes, \\(C_1 =\\{1234, 1234, 1243, 1324, 1342, 1423, 1432\\}\\), so \\(\\textrm{P}(C_1)=6/24=1/4\\). Similar to the previous part, \\(\\textrm{P}(C_2)=1/4\\). Also \\(C_2=\\{I_2=1\\}\\), and we see that there are 6 outcomes (rows) in Table 2.6 corresponding to \\(I_2=1\\). Similarly, \\(\\textrm{P}(C_3)=\\textrm{P}(C_4)=1/4\\). \\(C = C_1\\cup C_2\\cup C_3\\cup C_4\\). \\(\\textrm{P}(C_1\\cap C_2 \\cap C_3 \\cap C_4) = \\textrm{P}(\\{1234\\}) = 1/24\\) is the probability that all four rocks are put in their correct spots. As we mentioned previously, the general addition rule is complicated for more than two events. There are some terms missing from Donny’s calculation. There is one point about Example 2.37 worth emphasizing. Probability problems often involve finding “the probability of at least one…,” which on the surface involves unions (OR). However, the general addition rule for multiple events is complicated. It is often more convenient to use the complement rule and compute “the probability of at least one…” as one minus “the probability of none…”; the latter probability involves intersections (AND). We will see more about probabilities of intersections in Chapter XXX. 2.4.4 Uniform probability measures For a finite sample space with equally likely outcomes, computing the probability of an event reduces to counting the number of outcomes that satisfy the event. The continuous analog of equally likely outcomes is a uniform probability measure. When the sample space is uncountable, size is measured continuously (length, area, volume) rather that discretely (counting). \\[ \\textrm{P}(A) = \\frac{|A|}{|\\Omega|} = \\frac{\\text{size of } A}{\\text{size of } \\Omega} \\qquad \\text{if $\\textrm{P}$ is a uniform probability measure} \\] Example 2.38 Regina and Cady plan to meet for lunch between noon and 1 but they are not sure of their arrival times. We’ll consider only Regina’s arrival time for now. (We’ll get back to Cady in the next example.) Assume that Regina arrives at a time chosen uniformly at random between noon and 1. We can model Regina’s arrival with the sample space \\([0, 1]\\) and a uniform probability measure. Find the probability that Regina arrives before 12:15. Find the probability that Regina arrives after 12:45. Find the probability that Regina arrives between 12:15 and 12:45. Find the probability that Regina arrives between 12:15:00 and 12:16:00. Find the probability that Regina arrives between 12:15:00 and 12:15:01. Find the probability that Regina arrives at the exact time 12:15:00 (with infinite precision). Solution. to Example 2.38 Since the sample space is \\([0, 1]\\), a continuous (one-dimensional) interval, “size” is measured by length (which in this context represents fractions of an hour). Let \\(\\textrm{P}\\) be the uniform probability measure on \\([0, 1]\\). The interval from noon to 12:15 has length 0.25 hours and the sample space has length 1 hour, so the probability she arrives before 12:15 is \\(0.25/1 = 0.25\\); \\(\\textrm{P}([0, 0.25)) = 0.25\\). Similar to the previous part, the probability she arrives after 12:45 is 0.25; \\(\\textrm{P}((0.75, 1]) = 0.25\\). The probability that Regina arrives between 12:15 and 12:45, an interval of length 0.5 hours, is 0.5; \\(\\textrm{P}((0.25, 0.75)) = 0.5\\). A one minute interval has length \\(1/60 = 0.0167\\) hours, so the probability she arrives between 12:15 and 12:16 is 0.0167; \\(\\textrm{P}([0.25, 0.25+1/60]) = 1/60\\). A one second interval has length \\(1/3600 = 0.000278\\) hours, so the probability she arrives between 12:15:00 and 12:15:01 is 0.000278; \\(\\textrm{P}([0.25, 0.25+1/3600]) = 1/3600\\). The exact time 12:15:00 represents a single point the sample space, an interval of length 0. The probability that Regina arrives at the exact time 12:15:00 (with infinite precision) is 0; \\(\\textrm{P}(\\{0.25\\}) = 0\\). The last part in the previous example might seem counterintuitive at first. There was nothing special about 12:15; pick any time in the continuous interval from noon to 1:00, and the probability that Regina arrives at that exact time, with infinite precision, is 0. This idea can be understood as a limit. The probability that Regina arrives within one minute of the specified time is small, within one second of the specified time is even smaller, within one millisecond of the specified time is even smaller still; with infinite precision these time increments can get smaller and smaller indefinitely. Of course, infinite precision is not practical, but assuming the possible arrival times are represented by a continuous interval provides a reasonable mathematical model. Even though any particular time has probability 0 of being the exact arrival time, intervals of time still have positive probability of containing the arrival time. We will revisit this idea in more detail in Section XXX. This is one reason why probabilities are defined for events and not outcomes. Example 2.39 Regina and Cady plan to meet for lunch between noon and 1 but they are not sure of their arrival times. Recall the sample space from Example 2.6. Assume that the (Regina, Cady) pair of arrival times is chosen uniformly at random from the sample space \\([0, 1]\\times[0, 1]\\). We can model the pair of arrival times with the sample space \\([0, 1]\\times [0, 1]\\) and a uniform probability measure. Find the probability that Regina arrives after Cady. Find the probability that either Regina or Cady arrives before 12:30. Find the probability that Regina arrives at most 15 minutes after Cady (and Cady arrives first). Find the probability that Regina arrives before 12:24. Find the probability that Regina arrives at most 1 minute after Cady (and Cady arrives first). Find the probability that Regina arrives at most 1 second after Cady (and Cady arrives first). Find the probability that Regina and Cady arrive at exactly the same time, with infinite precision. Solution. to Example 2.39 See Figure 2.9 for pictures. Since the sample space is \\([0, 1]\\times[0, 1]\\), a continuous two-dimensional region, “size” is measured by area. Let \\(\\textrm{P}\\) be the uniform probability measure on \\([0, 1]\\times [0, 1]\\). The sample space has area 1. The triangular region corresponding to the event that Regina arrives after Cady has area 0.5. So the probability that Regina arrives after Cady is \\(0.5/1=0.5\\). The L-shaped region corresponding to the event that Regina or Cady arrives before 12:30 has area 0.75, so the probability is 0.75. The trapezoidal region corresponding to the event that that Regina arrives at most 15 minutes after Cady (and Cady arrives first) has area \\(7/32 = 0.21875\\). (It’s easiest to find the area of the two unshaded triangles and subtract from the total area of 1; \\(1 - 0.5 - (1-0.25)^2/2=7/32\\).) So the probability that Regina arrives at most 15 minutes after Cady (and Cady arrives first) is 0.21875. The rectangular region corresponding to the event that that Regina arrives before 12:24 has area 0.4, so the probability is 0.4. Similar to part 3, the probability that Regina arrives at most 1 minute after Cady (and Cady arrives first) is \\(1 - 0.5 - (1-1/60)^2/2=0.0165\\). Similar to part 3, the probability that Regina arrives at most 1 second after Cady (and Cady arrives first) is \\(1 - 0.5 - (1-1/3600)^2/2=0.000278\\). The event that Regina and Cady arrive at exactly the same time, with infinite precision, corresponds to the line segment \\(\\{(\\omega_1,\\omega_2):\\omega_1 = \\omega_2\\}\\). The area of this line segment is 0, so the probability that Regina and Cady arrive at exactly the same time, with infinite precision, is 0. Figure 2.9: Illustration of the events in Exercise 2.39. The square represents the sample space \\(\\Omega=[0,1]\\times[0,1]\\). The latter parts of Example 2.39 illustrate ideas similar to those discussed after Example 2.38. Regardless of the precise time in the continuous interval \\([0, 1]\\) at which Regina arrives, the probability that Cady arrives at that exact time, with infinite precision, is 0. Example 2.40 Continuing Example 2.39, let \\(R\\) be the random variable representing Regina’s arrival time in \\([0, 1]\\), and \\(Y\\) for Cady. The random variable \\(W = |R - Y|\\) represents the amount of time the first person to arrive waits for the second person to arrive. Find and interpret \\(\\textrm{P}(W &lt; 0.25)\\). (Hint: draw a picture representing the event in terms of the pairs of arrival times.) Find and interpret \\(\\textrm{P}(W &gt; 0.75)\\). Are the values of \\(W\\) uniformly distributed over \\([0, 1]\\)? Solution. to Example 2.40 The event corresponding to \\(W&lt;0.25\\) is depicted on the left in Figure 2.10. If Cady arrives first (\\(R&gt;Y\\), below the diagonal in the plot) then \\(W=R-Y\\) so \\(W&lt;0.25\\) if \\(R -0.25 &lt; Y\\). If Regina arrives first (\\(R&lt;Y\\), above the diagonal in the plot) then \\(W=Y-R\\) so \\(W&lt;0.25\\) if \\(Y &lt; R + 0.25\\). Putting the two cases together \\(W&lt;0.25\\) if \\(R - 0.25 &lt; Y &lt; R + 0.25\\); the corresponding region of \\((R, Y)\\) pairs is shaded in the plot. According to the uniform probability measure on \\([0, 1]\\times[0,1]\\), \\(\\textrm{P}(W &lt;0.25)\\) is the area of the shaded region (divided by the area of the sample space which is 1). The area of the shaded region is 0.4375. (It is easiest to find the areas of the unshaded triangles and subtract from 1, \\(1 - 0.75^2/2 - 0.75^2/2\\).) So \\(\\textrm{P}(W &lt; 0.25)=0.4375\\) is the probability that Regina and Cady arrive within 15 minutes of each other. The event corresponding to \\(W&gt;0.75\\) is depicted on the right in Figure 2.10. The probability is the area of the shaded region. So \\(\\textrm{P}(W &gt; 0.75)=0.25^2/2 + 0.25^2/2=0.0625\\) is the probability that Regina and Cady arrive more than 45 minutes apart. The values of \\(W\\) are not uniformly distributed over \\([0, 1]\\). For uniform probability measures, regions of the same size have the same probability. But the probability that \\(W\\) lies in the interval \\([0, 0.25]\\) is seven times greater than the probability that \\(W\\) lies in the interval \\([0.75, 1]\\), even though these intervals have the same length. Figure 2.10: Illustration of the events in Example 2.40. The square represents the sample space \\(\\Omega=[0,1]\\times[0,1]\\). We saw in Example 2.37 on the matching problem that even though the possible placements of the rocks were equally likely, the possible values of the number of correct matches were not. Example 2.40 illustrates a similar idea on a continuous scale. Even though the pairs of arrival times are uniformly distributed over \\([0, 1]\\times[0, 1]\\), the values of the waiting time \\(W\\) are not uniformly distributed over \\([0, 1]\\). 2.4.5 Non-uniform probability measures Most random phenomenon do not involve equally likely outcomes or uniform probability measures. Even when the underlying outcomes are equally likely, the values of related random variables are usually not. Therefore, most interesting probability problems involve non-uniform probability measures. For countable sample spaces, a probability measure is often defined by specifying the probability of each individual outcome. The probability of any event can then be obtained (using countable additivity) by summing the probabilities of the outcomes which comprise the event. Such was the case in Example 2.32. We specified the relative likelihood of each outcome, and then we obtained probabilities of all the events in Table 2.9 by adding the appropriate outcome probabilities. For example, the probability that the result of a single roll of the die in Example 2.32 results in an even number is \\(\\tilde{\\textrm{Q}}(\\{2, 4\\}) = \\tilde{\\textrm{Q}}(\\{2\\}) + \\tilde{\\textrm{Q}}(\\{4\\}) = 6/15 + 2/15 = 8/15\\). For uncountable sample spaces, specifying probabilities for individual outcomes is not a feasible strategy. As illustrated by Example 2.38 and the discussion following it, reasonable mathematical models for outcomes taking values on a continuous scale, with infinite precision, assign 0 probability to any exact outcome. Therefore, we specify a probability measure for uncountable sample spaces by assigning probabilities to intervals or regions of the sample space. Example 2.41 Regina and Cady plan to meet for lunch between noon and 1 but they are not sure of their arrival times. We’ll consider only Regina’s arrival time for now. We will model Regina’s arrival time with the sample space \\([0, 1]\\) and a non-uniform probability measure which reflects that she is more likely to arrive closer to 1 than to noon. In particular, we assume that the probability that Regina arrives before time \\(x\\in [0, 1]\\) is equal to \\(x^2\\); let \\(\\textrm{Q}\\) denote the corresponding probability measure. (We will see where such a probability measure might come from later. For now, we’ll just use it to compute probabilities and observe that it is a non-uniform measure.) In addition to computing probabilities below, compare your answers to the corresponding parts from Example 2.38. Find the probability that Regina arrives before 12:15. Find the probability that Regina arrives after 12:45. How does this compare to the previous part? What does that say about Regina’s arrival time? Find the probability that Regina arrives between 12:15 and 12:45. Find the probability that Regina arrives between 12:15:00 and 12:16:00. Find the probability that Regina arrives between 12:15:00 and 12:15:01. Find the probability that Regina arrives at the exact time 12:15:00 (with infinite precision). Find the probability that Regina arrives between 12:59:00 and 1:00:00. How does this compare to the probability for 12:15:00 to 12:16:00? What does that say about Regina’s arrival time? Find the probability that Regina arrives between 12:59:59 and 1:00:00. How does this compare to the probability for 12:15:00 to 12:15:01? What does that say about Regina’s arrival time? Find the probability that Regina arrives at the exact time 1:00:00 (with infinite precision). Solution. to Example 2.41 Notice that \\(\\textrm{Q}([0, 1]) = 1^2 = 1\\), so \\(\\textrm{Q}\\) is a valid probability measure. 12:15 corresponds to arriving at time \\(0.25\\) in \\([0, 1]\\), so by assumption the probability she arrives before 12:15 is \\(0.25^2 =0.0625\\); \\(\\textrm{Q}([0, 0.25)) = 0.0625\\). (She is now less likely to arrive with 15 minutes of noon than in the uniform case.) 12:45 corresponds to arriving at time \\(0.75\\) in \\([0, 1]\\) and by assumption the probability she arrives before 12:45 is \\(0.75^2 =0.5625\\). Therefore, the probability that she arrives after 12:45, i.e., in the interval \\([0.75, 1]\\) is \\(\\textrm{Q}([0.75, 1]) = 1 - 0.5625 = 0.4375\\). So she is 7 times more likely to arrive within 15 minutes of 1:00 than within 15 minutes of noon. (She is now more likely to arrive with 15 minutes of 1:00 than in the uniform case.) The probability that Regina arrives between 12:15 and 12:45 is \\(\\textrm{Q}((0.25, 0.75)) = 1 - 0.0625 - 0.4375 = 0.5\\). (This probability happens to be the same as in the uniform case.) The probability that she arrives before 12:16 is the sum of the probability that she arrives before 12:15 and the probability that she arrives between 12:15 and 12:16. Therefore, \\[\\begin{align*} \\textrm{Q}([0.25, 0.25+1/60]) &amp; = \\textrm{Q}([0, 0.25+1/60]) - \\textrm{Q}([0, 0.25])\\\\ &amp; = (0.25 + 1/60)^2 - 0.25^2 = 0.0086. \\end{align*}\\] (This probability is less than what it was in the uniform case.) Similar to the previous part, \\(\\textrm{Q}([0.25, 0.25+1/3600]) = (0.25 + 1/3600)^2 - 0.25^2 = 0.00014\\). (This probability is less than what it was in the uniform case.) The exact time 12:15:00 represents a single point the sample space, an interval of length 0. The probability that Regina arrives at the exact time 12:15:00 (with infinite precision) is 0; \\(\\textrm{Q}(\\{0.25\\}) = 0\\). 12:59:00 is time \\(1 - 1/60=0.9833\\) in [0, 1]. \\(\\textrm{Q}([1 - 1/60, 1]) = \\textrm{Q}([0, 1]) - \\textrm{Q}([0, 1-1/60]) = 1^2 - (1-1/60)^2 = 0.0331\\). Notice that this one minute interval around 1:00 has higher probability that a one minute interval around 12:15. (This probability is more than what it was in the uniform case.) Similar to the previous part, \\(\\textrm{Q}([1-1/3600, 1]) = 1^2 - (1-1/3600)^2 = 0.00056\\). Notice that this one second interval around 1:00 has higher probability that a one second interval around 12:15, though both probabilities are small. (This probability is more than what it was in the uniform case.) The exact time 1:00:00 represents a single point the sample space, an interval of length 0. The probability that Regina arrives at the exact time 1:00:00 (with infinite precision) is 0; \\(\\textrm{Q}(\\{1\\}) = 0\\). In Example 2.41, the probability that Regina arrives at any exact time in \\([0, 1]\\), with infinite precision, is 0, just as in Example 2.38. But the values of the probabilities in Example 2.41 illustrate the non-uniform probability assumption. Regina is much more likely to arrive between 12:45 and 1:00 than she is to arrive between 12:00 and 12:15, even though both these intervals have the same length. Also, while the probability that she arrives at any exact time with infinite precision is 0, the probability that she arrives “close to” 1:00 is larger than the probability that she arrives “close to” 12:15 (where “close to” might mean within a minute or within a second.) In some sense, some values in \\([0, 1]\\) are “more likely” than others. We will explore this idea further in Section XXX, where we will see that integration plays the analogous role for uncountable sample spaces that summation plays for countable sample spaces. Technically, \\(\\mathcal{F}\\) is a \\(\\sigma\\)-field of subsets of \\(\\Omega\\): \\(\\mathcal{F}\\) contains \\(\\Omega\\) and is closed under countably many elementary set operations (complements, unions, intersections). While this level of technical detail is not needed, we prefer to refer to a probability space as a triple to emphasize that probabilities are assigned directly to events rather than just outcomes.↩︎ It’s the number of events that must be countable. The events themselves can be uncountable sets like intervals.↩︎ That the probability of each outcome must be 1/4 when there are four equally likely outcomes follows from the axioms, by writing \\(\\{1, 2, 3, 4\\} = \\{1\\}\\cup\\{2\\}\\cup \\{3\\}\\cup \\{4\\}\\), a union of disjoint sets, and applying countable additivity and \\(\\textrm{P}(\\Omega)=1\\).↩︎ Probabilities are always defined for events (sets). When we say loosely \"the probability of an outcome \\(\\omega\\)’’ we really mean the probability of the event consisting of the single outcome \\(\\{\\omega\\}\\). In this example \\(\\textrm{P}(\\{1\\})=\\textrm{P}(\\{2\\})=\\textrm{P}(\\{3\\})=\\textrm{P}(\\{4\\})=1/4\\).↩︎ Proof: Since \\(\\Omega = A \\cup A^c\\) and \\(A\\) and \\(A^c\\) are disjoint the axioms imply that \\(1=\\textrm{P}(\\Omega) = \\textrm{P}(A \\cup A^c) = \\textrm{P}(A) + \\textrm{P}(A^c)\\).↩︎ Proof. If \\(A \\subseteq B\\) then \\(B = A \\cup (B \\cap A^c)\\). Since \\(A\\) and \\((B \\cap A^c)\\) are disjoint, \\(\\textrm{P}(B) = \\textrm{P}(A) + \\textrm{P}(B \\cap A^c) \\ge \\textrm{P}(A)\\).↩︎ The proof is easiest to see by considering a picture like the one in Figure 2.7 .↩︎ For three events, \\[\\begin{align*} \\textrm{P}(A\\cup B\\cup C) &amp; = \\textrm{P}(A) + \\textrm{P}(B) + \\textrm{P}(C)\\\\ &amp; \\qquad - \\textrm{P}(A\\cap B) - \\textrm{P}(A \\cap C) - \\textrm{P}(B \\cap C)\\\\ &amp; \\qquad + \\textrm{P}(A \\cap B \\cap C). \\end{align*}\\]↩︎ "],
["probability-distributions-a-brief-introduction.html", "2.5 Probability distributions (a brief introduction)", " 2.5 Probability distributions (a brief introduction) Even when outcomes of a random phenomenon are equally likely, values of related random variable are usually not. The probability distribution of a random variable summarizes the possible values that the random variable can take and their relative likelihoods. The probability distribution of a discrete random variable \\(X\\) is often displayed in a table containing the probability of the event \\(\\{X=x\\}\\) for each possible value \\(x\\). For example, the distribution of the number of matches \\(Y\\) in the matching problem in Example 2.37 is represented by Table 2.10. Example 2.42 Roll a four-sided die twice; recall the sample space in Example 2.17 and Table 2.2. One choice of probability measure corresponds to assuming that the die is fair and that the 16 possible outcomes are equally likely. Let \\(X\\) be the sum of the two dice, and let \\(Y\\) be the larger of the two rolls (or the common value if both rolls are the same). Construct a table displaying the distribution of \\(X\\). Construct a table displaying the distribution of \\(Y\\). Construct a two-way table displaying the distribution of \\((X, Y)\\) pairs. Starting with the two-way table from the previous part, how could you obtain the distribution of \\(X\\)? of \\(Y\\)? Starting with the distribution of \\(X\\) and the distribution of \\(Y\\) from parts 1 and 2, but without Table 2.2, could you construct the two-way table of the distribution of \\((X, Y)\\) pairs? Solution. to Example 2.42 The possible values of \\(X\\) are \\(2, 3, 4, 5, 6, 7, 8\\). Find the probability of each value using Table 2.2. For example \\(\\textrm{P}(X = 3) = \\textrm{P}(\\{(1, 2), (2, 1)\\}) = 2/16\\). Table 2.11 displays the distribution. Table 2.11: The distribution of \\(X\\), the sum of two rolls of a fair four-sided die. x P(X=x) 2 0.0625 3 0.1250 4 0.1875 5 0.2500 6 0.1875 7 0.1250 8 0.0625 The possible values of \\(Y\\) are \\(1, 2, 3, 4\\). For example \\(\\textrm{P}(Y = 3) = \\textrm{P}(\\{(1, 3), (2, 3), (3, 1), (3, 2), (3, 3)\\}) = 5/16\\). Table 2.12 displays the distribution. Table 2.12: The distribution of \\(Y\\), the larger (or common value if a tie) of two rolls of a fair four-sided die. y P(Y=y) 1 0.0625 2 0.1875 3 0.3125 4 0.4375 Similar to the previous parts, we can first construct a table with each row corresponding to a possible \\((X, Y)\\) pair. Basically, collapse Table 2.13. For example \\(\\textrm{P}((X, Y) = (4, 3))=\\textrm{P}(X = 4, Y=3) = \\textrm{P}(\\{(1, 3), (3, 1)\\}) = 2/16\\). Table 2.13: Table representing the joint distribution of sum (\\(X\\)) and larger (\\(Y\\)) of two rolls of a four-sided die (x, y) P(X = x, Y = y) (2, 1) 0.0625 (3, 2) 0.1250 (4, 2) 0.0625 (4, 3) 0.1250 (5, 3) 0.1250 (5, 4) 0.1250 (6, 3) 0.0625 (6, 4) 0.1250 (7, 4) 0.1250 (8, 4) 0.0625 Table 2.14 reorganizes Table 2.13 into a two-way table with rows corresponding to possible values of \\(X\\) and columns corresponding to possible values of \\(Y\\). Table 2.14: Two-way table representation of the joint distribution of \\(X\\) and \\(Y\\), the sum and the larger (or common value if a tie) of two rolls of a fair four-sided die. Possible values of \\(X\\) are in the leftmost column; possible values of \\(Y\\) are in the top row. \\(x\\) \\ \\(y\\) | 1 2 3 4 2 | 1/16 0 0 0 3 | 0 2/16 0 0 4 | 0 1/16 2/16 0 5 | 0 0 2/16 2/16 6 | 0 0 1/16 2/16 7 | 0 0 0 2/16 8 | 0 0 0 1/16 For each possible value \\(x\\) of \\(X\\) sum the values in the corresponding row to find \\(\\textrm{P}(X=x)\\). For example, \\[\\begin{align*} \\textrm{P}(X=4) &amp; = \\textrm{P}(X=4, Y=1) + \\textrm{P}(X=4, Y=2)\\\\ \\&amp; \\quad + \\textrm{P}(X=4, Y=3) + \\textrm{P}(X=4, Y=4) = 0 + 1/16 + 2/16 + 0=3/16. \\end{align*}\\] Similarly, for each possible value \\(y\\) of \\(Y\\) sum the values in the corresponding column to find \\(\\textrm{P}(Y = y)\\). No, you could not construct the two-way table of the distribution of \\((X, Y)\\) pairs based on the distributions of \\(X\\) and \\(Y\\) alone. Essentially, just because you know the row totals and column totals doesn’t necessarily mean you know the values of the interior cells. Table 2.14 and Table 2.13 represent the joint distribution of \\(X\\) and \\(Y\\). The joint distribution of two random variables summarizes the possible pairs of values and their relative likelihoods. In the context of multiple random variables, the distribution of any one of the random variables is called a marginal distribution. In Example 2.42 , we can obtain the marginal distributions of \\(X\\) and \\(Y\\) from the joint distribution by summing rows and columns. Think of adding a total column (for \\(X\\)) and a total row (for \\(Y\\)) in the “margins” of the table. It is possible to obtain marginal distributions from a joint distribution. However, in general you cannot recover the joint distribution from the marginal distributions alone. Just because you know the row and column totals doesn’t mean you know all the values of the interior cells in the joint distribution table. Consider the following two-way table representing the joint distribution of two random variables \\(X\\) and \\(Y\\). You can check that the marginal distribution of \\(X\\) is the same as in Table 2.11. You can also check that the marginal distribution of \\(Y\\) is the same as in Table 2.12. However, clearly the joint distribution of \\(X\\) and \\(Y\\) is not the same as in Table 2.13. \\(x\\) \\ \\(y\\) | 1 2 3 4 2 | 0 1/16 0 0 3 | 1/16 1/16 0 0 4 | 0 1/16 2/16 0 5 | 0 0 1/16 3/16 6 | 0 0 1/16 2/16 7 | 0 0 0 2/16 8 | 0 0 1/16 0 Example 2.43 Continuing Example 2.42, suppose that instead of a fair die, the weighted die in Example 2.31 is rolled twice. Answer the following without doing any computations. Are the possible values of \\(X\\) the same as in Table 2.11? Is the distribution of \\(X\\) the same as in Table 2.11? Are the possible values of \\(Y\\) the same as in Table 2.12? Is the distribution of \\(Y\\) the same as in Table 2.12? Are the possible values of \\((X, Y)\\) the same as in Table 2.14? Is the joint distribution of \\(X\\) and \\(Y\\) the same as in Table 2.14? Solution. to Example 2.43 In all parts, yes the possible values are the same. There are still 16 possible outcomes and the random variables are still measuring the same quantities as before. But the distributions are all different. With the weighted die some outcomes are more likely than others, and some values of the random variables are more likely than before. For example, the probabilities of the events \\(\\{X = 8\\}\\), \\(\\{Y=4\\}\\), and \\(\\{X = 8, Y=4\\}\\) are larger with the weighted die than with the fair die (because each roll of the weighted die is more likely to result in a 4 than the fair die). The distribution of a random variable depends on the underlying probability measure. Changing the probability measure can change the distribution of the random variable. We will see the importance of this idea when we cover conditional probability and distributions in Chapter XXX. Example 2.44 Flip a coin 3 times and record the results in sequence. Let \\(X\\) be the number of flips that result in H. Let \\(Y\\) be the number of flips that result in T, and let \\(Z\\) be the length of the longest streak of H in a row (which could be 0 if all T or 1 if no H is followed by H). (Hint: recall Table 2.3.) One choice of probability measure \\(\\textrm{P}\\) corresponds to assuming the 8 possible outcomes are equally likely, consistent with the assumption that the coin is fair and the flips are independent. Identify the distribution of \\(X\\). Identify the distribution of \\(Y\\). Are \\(X\\) and \\(Y\\) the same random variable? Do they have the same distribution? Donny Don’t says “\\(X\\) and \\(Y\\) have the same distribution so \\(\\textrm{P}(X=Y)=1\\).” Explain to Donny his mistake, and find \\(\\textrm{P}(X = Y)\\). Donny Don’t says “OK, I see why \\(\\textrm{P}(X=Y)\\) is not 1. But then I don’t understand what it means for \\(X\\) and \\(Y\\) to have the same distribution.” Explain this to Donny using a long run relative frequency interpretation. Identify the distribution of \\(Z\\). Are \\(X\\) and \\(Z\\) the same random variable? Do \\(X\\) and \\(Z\\) have the same distribution? Donny says “\\(X\\) and \\(Y\\) have the same distribution but \\(X\\) and \\(Z\\) don’t, so \\(\\textrm{P}(X = Y)\\) must be greater than \\(\\textrm{P}(X = Z)\\)”. Explain to Donny his mistake, and find \\(\\textrm{P}(X = Z)\\). Suppose that the coin was biased in favor of landing on H. Without doing any computations, would \\(X\\) and \\(Y\\) have the same distribution in this scenario? Explain. Solution. to Example 2.44 Table 2.15 lists the possible outcomes and corresponding values of \\(X, Y, Z\\). Table 2.15: Table representing \\(X\\) the number of heads, \\(Y\\) the number of tails, and \\(Z\\) the length of the longest streak of heads in a row in 3 flips of a coin. Outcome X Y Z HHH 3 0 3 HHT 2 1 2 HTH 2 1 1 THH 2 1 2 HTT 1 2 1 THT 1 2 1 TTH 1 2 1 TTT 0 3 0 One way to “identify a distribution” of a discrete random variable is to make a table of possible values along with their probabilities. Collapse Table 2.15 to see that \\(X\\) takes values 0, 1, 2, 3 with respective probability \\(1/8, 3/8, 3/8, 1/8\\). \\(Y\\) takes values 0, 1, 2, 3 with respective probability \\(1/8, 3/8, 3/8, 1/8\\). \\(X\\) and \\(Y\\) are different random variables; they measure different things. Remember, random variables are functions, and the random variables \\(X\\) and \\(Y\\) are different functions, one counts H and one counts T. But \\(X\\) and \\(Y\\) do have the same distribution; they take the same possible values with the same respective probabilities. The event \\(X=Y\\) represents the set of outcomes for which the value of the number of H is equal to the value of the number of T. But this is impossible for an odd number of coin flips, so \\(\\textrm{P}(X = Y) = 0\\). \\(X\\) and \\(Y\\) have the same long run pattern of variability over many sets of 3 coin flips. Over many sets of 3 coin flips, about 1/8 of sets will have 0 H, about 3/8 of sets will have 1 H, etc. \\(Y\\) follows the same pattern: Over many sets of 3 coin flips, about 1/8 of sets will have 0 T, about 3/8 of sets will have 1 T, etc. \\(Z\\) takes values 0, 1, 2, 3 with respective probability \\(1/8, 4/8, 2/8, 1/8\\). \\(X\\) and \\(Z\\) are not the same random variable. Remember, random variables are functions; two functions are the same if for any given input the two functions have the same output. But \\(X(HTH)=2\\) and \\(Z(HTH)=1\\). \\(X\\) and \\(Z\\) also do not have the same distribution; \\(X\\) is 2 with probability 3/8 but \\(Z\\) is 2 with probability 2/8. We have already explained that \\(\\textrm{P}(X = Y)=0\\), so it can’t be greater than \\(\\textrm{P}(X = Z)\\). The only outcome that does not satisfy the event \\(\\{X=Z\\}\\) is \\(HTH\\), so \\(\\textrm{P}(X=Z)=7/8\\). No. If the coin were biased in favor of landing on H then \\(X\\) and \\(Y\\) would not follow the same pattern of variability. For example, the probability that \\(X=3\\) would be greater than 1/8 and the probability that \\(Y=3\\) would be less than 1/8. Remember, the distribution of a random variable depends on the underlying probability measure. The previous example illustrates two ideas of “sameness” of random variables. Two random variables are the same if for each outcome of the random phenomenon they return the same value. Statements like \\(\\textrm{P}(X=Y)\\) involve events; for which individual outcomes is the value of \\(X\\) equal to the value of \\(Y\\). Essentially \\(\\textrm{P}(X=Y)\\) is determined by checking if \\(X(\\omega)=Y(\\omega)\\) on an individual outcome-by-outcome \\(\\omega\\) basis. On the other hard, the distribution of a random variable describes its overall pattern of variability over all possible outcomes, summarized in aggregate (and not on an outcome-by-outcome basis). As the previous example shows, two random variables can have the same distribution even if they are never equal for any outcomes. Also, two random variables can take the same values for “most” outcomes, but still have different distributions. Two random variables can have the same distribution even if they are not defined on the same probability space. For example, assuming boys and girls are equally likely, then the number of girls in a random sample of 3 births has the same distribution as the number of heads in 3 flips of a fair coin. Two ideas illustrated in the examples in this section are worth emphasizing. In general, marginal distributions alone are not enough to determine a joint distribution. Do not confuse a random variable with its distribution. Many common mistakes in probability result from not heeding these principles, so we will introduce many related examples to help you practice your understanding. In almost all of the examples in this Chapter, we specified the probability space. In this section, we derived distributions by considering the underlying sample space and probability measure. However, in many problems we often assume or identify distributions directly, without any mention of the underlying sample space or probability measure. Recall the brown bag analogy in Section 2.3.1. The probability space corresponds to the random selection of fruits to put in the bag. The random variable is weight. The distribution of weight can be obtained by randomly selecting fruits to put in the bag, weighing the bag, and then repeating this process many times to observe many weights. For example, 10% of bags have weights less than 5 pounds, 75% of bags have weights less than 20 pounds. But we can observe the distribution of weights even if we never observe the actual fruits in the bag. We will explore distributions in much more detail in the remaining chapters. We will see several other ways of describing distributions. "],
["simulation.html", "Chapter 3 Simulation", " Chapter 3 Simulation A probability model of a random phenomenon consists of a sample space of possible outcomes, associated events and random variables, and a probability measure which specifies probabilities of events (and determines distributions of random variables). Simulation involves artificially recreating the random phenomenon, usually using a computer. Given a probability model, we can simulate outcomes, occurrences of events, and values of random variables, according to the specifications of the probability measure. Simulation can be used to approximate probabilities of events and distributions of random variables. In general, a simulation involves the following steps. Set up. Define a probability space, and related random variables and events. The probability measure \\(\\IP\\) encodes all the assumptions of a probability model, but \\(\\IP\\) is often only specified indirectly. Simulate. Simulate, according to the probability measure, outcomes, occurrences of events, and values of random variables. Summarize. Summarize simulation output in plots and summary statisics (relative frequencies, mean, standard deviation, correlation, etc) to approximate probabilities, distributions, and related characteristics. Recall from Section 1.2.1 that probabilities can be interpreted as long run relative frequencies. Therefore the probability of event \\(A\\) can be approximated by simulating the random phenomenon a large number of times and computing the relative frequency of \\(A\\). \\[ \\IP(A) \\approx \\frac{\\text{number of repetitions on which $A$ occurs}}{\\text{number of repetitions}}, \\quad \\text{for a large number of simulated repetitions} \\] "],
["tactile.html", "3.1 Tactile simulation: Boxes and spinners", " 3.1 Tactile simulation: Boxes and spinners While we generally use technology to conduct large scale simulations, it is helpful to first consider how we might conduct a simulation by hand using physical objects like coins, dice, cards, or spinners. Many random phenomena can be represented in terms of a “box model”. Imagine a box containing “tickets” with labels. Examples include: Fair coin flip. 2 tickets: 1 labeled H and 1 labeled T 90% free throw shooter. 10 tickets: 9 labeled “make” and 1 labeled “miss” Card shuffling. 52 cards: each card with a pair of labels (face value, suit). Random digit dialing. 10 tickets: labeled 0 through 9 (corresponding to single digits). The tickets are shuffled in the box, some number are drawn out — either with replacement or without replacement of the tickets before the next draw33 In some cases, the order in which the tickets are drawn matters; in other cases the order is irrelevant. For example, Dealing a 5 card poker hand: Select 5 cards without replacement, order does not matter Random digit dialing: Select 10 cards with replacement (for a phone number with area code), order matters (e.g., 805-555-1234 is a different outcome than 805-555-4321) Then something is done with the tickets, typically to measure random variables of interest. For example, you might flip a coin 10 times (by drawing from the H/T box 10 times with replacement) and count the number of H. If the draws are made with replacement from a single box, we can think of a single circular “spinner” instead of a box, spun multiple times. For example: Fair coin flip. Spinner with half of the area corresponding to H and half T 90% free throw shooter. Spinner with 90% of the area correspoding to “make” and 10% “miss”. Random digit dialing. Spinner marked with digits 0-9, possibly with some digits more likely than others. spun multiple times. Depending on what regions you are trying to sample, you might have three spinners: one to generate area code, one to generate the next three digits, and one to generate the last four digits. Example 3.1 Let \\(X\\) be the sum of two rolls of a fair four-sided die, and let \\(Y\\) be the larger of the two rolls (or the common value if a tie). Set up a box model and explain how you would use it to simulate a single realization of \\((X, Y)\\). Could you use a spinner instead? Solution. to Example 3.1 Use a box with four tickets, labeled 1, 2, 3, 4. Draw two tickets with replacement. Let \\(X\\) be the sum of the two numbers drawn and \\(Y\\) the larger of the two numbers drawn. It’s also possible to use a spinner with 4 sectors, corresponding to 1, 2, 3, 4, each with 25% of the total area; see Figure 3.1. Spin the spinner twice. Let \\(X\\) be the sum of the two numbers spun and \\(Y\\) the larger of the two numbers spun. Figure 3.1: Spinner corresponding to a single roll of a fair four-sided die. The spinner in Figure 3.1 simulates the individual die rolls. We will see in Figure 3.5 below a separate spinner for generating \\((X, Y)\\) pairs directly. Note that we were able to simulate outcomes of the rolls and values of \\(X\\) and \\(Y\\) without defining the probability space in detail. Instead, the probability space is defined implicitly via the specification to “roll a fair four-sided die twice” or “draw two tickets with replacement from a box with four tickets labeled 1, 2, 3, 4” or “spin the spinner in Figure 3.1 twice”. The random variables are defined by what is being measured for each outcome, the sum (\\(X\\)) and the max (\\(Y\\)) of the two draws or spins. A simulation involves repeatedly artificially recreating the random phenomenon a large number of repetitions and using the results to investigate properties of interest. It is important to distinguish between what entails (1) one repetition of the simulation and its output, and (2) the simulation itself and output from many repetitions. Example 3.2 Use a four-sided die (or a box or a spinner) and perform by hand 10 repetitions of the simulation in Example 3.1. For each repetition, record the results of the first and second rolls (or draws or spins) and the values of \\(X\\) and \\(Y\\). Based only on the results of your simulation, how would you approximate the following? \\(\\IP(A)\\), where \\(A\\) is the event that the first roll is 3. \\(\\IP(X=6)\\) \\(\\IP(X \\ge 6)\\) \\(\\IP(Y = 3)\\) \\(\\IP(Y \\ge 3)\\) \\(\\IP(X=6, Y=3)\\) \\(\\IP(X\\ge6, Y \\ge 3)\\) Solution. to Example 3.2. Table 3.1 summarizes the results of 10 repetitions. Results vary naturally so your simulation results will be different, but the same ideas apply. Table 3.1: Results of 10 repetitions of two rolls of a fair four-sided die Repetition First roll Second roll X Y Event A occurs? I[A] 1 2 1 3 2 False 0 2 1 1 2 1 False 0 3 3 3 6 3 True 1 4 4 3 7 4 False 0 5 3 2 5 3 True 1 6 3 4 7 4 True 1 7 2 3 5 3 False 0 8 2 4 6 4 False 0 9 1 2 3 2 False 0 10 3 4 7 4 True 1 Approximate \\(\\IP(A)\\) by 4/10, the proportion of repetitions where the first roll is 3. Approximate \\(\\IP(X=6)\\) by 2/10, the proportion of repetitions where the sum is 6. Approximate \\(\\IP(X\\ge 6)\\) by 5/10, the proportion of repetitions where the sum is at least 6. Approximate \\(\\IP(Y=3)\\) by 3/10, the proportion of repetitions where the max is 3. Approximate \\(\\IP(Y\\ge 3)\\) by 7/10, the proportion of repetitions where the max is at least 7. Approximate \\(\\IP(X=6, Y = 3)\\) by 1/10, the proportion of repetitions where both the sum is 6 and the max is 3. Approximate \\(\\IP(X\\ge 6, Y \\ge 3)\\) by 5/10, the proportion of repetitions where both the sum is at least 6 and the max is at least 3. In practice, many repetitions of a simulation are performed on a computer. But carrying out a few repetitions by hand helps make the process more concrete. Remember that it is important to distinguish between what entails (1) one repetition of the simulation and its output, and (2) the simulation itself and output from many repetitions. Refrain from making vague statements like “repeat this” or “do it again”, because “this” or “it” could refer to different elements of the simulation. In the dice example, (1) rolling a die is repeated to generate a single \\((X, Y)\\) pair, and (2) the process of generating \\((X, Y)\\) pairs is repeated to obtain the simulation34 results. That is, a single repetition involves an ordered pair of die rolls, resulting in an outcome \\(\\omega\\), and the values of the sum \\(X(\\omega)\\) and max \\(Y(\\omega)\\) are computed for the outcome \\(\\omega\\). This process is repeated many times to generate many outcomes and \\((X, Y)\\) pairs according to the probability model. Think of simulation results being organized in a table like Table 3.1, where each row corresponds to a different repetition of the simulation and each column corresponds to a different random variable. Remember that indicators are the bridge between events and random variables. On each repetition of the simulation an event either occurs or not. We could record the occurrence of an event as “True/False” for each repetition, or we could record the 1/0 value of the corresponding indicator random variable; see the last two columns in Table 3.1 for an example. Simulation results are summarized in tables and plots. Figure 3.2 displays two plots summarizing the results in Table 3.1. Each dot represents the results of one repetition; the plot on the left displays the \\((X, Y)\\) pairs, and the plot on the right displays the values of \\(X\\) alone along with their frequencies. While this simulation only consists of 10 repetitions, a larger scale simulation and the summarization of results would follow the same process. Figure 3.2: Results of 10 repetitions of two rolls of a fair four-sided die, where \\(X\\) is the sum and \\(Y\\) is the larger (or common value if a tie) of the two rolls; see Table 3.1. A particular event either occurs or not or any particular repetition of the simulation. Summarizing simulation results for events involves counting the number of repetition on which the event occurs and finding related proportions. On the other hand, random variables typically take many possible values over the course of many repetitions. We are still interested in relative frequencies of events, like \\(\\{X=6\\}\\) and \\(\\{Y \\ge 3\\}\\) in the die example. But for random variables we also also interested distributions, average values, degree of variability, and quantities that measure relationships between random variables. We will investigate these ideas soon. Example 3.3 Flip a coin 4 times and let \\(X\\) be the number of H. Specify how to use a box model to simulate a single value of \\(X\\), with tickets labeled H and T. Specify how to use a box model to simulate a single value of \\(X\\), using tickets that are labeled with appropriate numbers (not H and T) and without counting. Specify how to use simulation to approximate \\(\\IP(X = 3)\\). Solution. to Example 3.3. Put two tickets in the box, one labeled H and one labeled T. Shuffle and deal 4 tickets with replacement. Count the number of times H was drawn to obtain the value of \\(X\\) for this repetition. Put two tickets in the box, one labeled 1 (for H) and one labeled 0 (for T). Shuffle and deal 4 tickets with replacement. Sum the 4 values drawn to obtain the value of \\(X\\) for this repetition. Repeat step 1 (or 2) many times to generate many simulated values of \\(X\\). Approximate \\(\\IP(X=3)\\) with the proportion of simulated values of \\(X\\) that are equal to 3. “With replacement” always implies replacement at a uniformly random point in the box. Think of “with replacement” as “with replacement and reshuffling” before the next draw.↩︎ Do we perform “a simulation”, or “many simulations”? Throughout, “a simulation” refers to the collection of results corresponding to repreatedly artificially recreating the random process. “A repetition” refers to a single artificial recreating resulting in a single simulated outcome.↩︎ "],
["technology-intro.html", "3.2 Computer simulation: Symbulate", " 3.2 Computer simulation: Symbulate Note: some of the plots and tables in this and the following sections are not displayed properly in the text. See the accompanying Jupyter notebooks for a better representation of Symbulate output. We will perform computer simulations using the Python package Symbulate. The syntax of Symbulate mirrors the language of probability in that the primary objects in Symbulate are the same as the primary components of a probability model: probability spaces, random variables, events. Once these components are specified, Symbulate allows users to simulate many times from the probability model and summarize the results. This section contains a brief introduction to Symbulate; many more examples can be found throughout the text or in the Symbulate documentation. Remember to first import Symbulate during a Python session using the command from symbulate import * 3.2.1 Simulating outcomes We continue Example 3.1 from Section 3.1 where \\(X\\) is the sum of two rolls of a fair four-sided die, and \\(Y\\) is the larger of the two rolls (or the common value if a tie). The following Symbulate code defines a probability space35 P for simulating the 16 equally likely ordered pairs of rolls via a box model. P = BoxModel([1, 2, 3, 4], size = 2, replace = True) The above code tells Symbulate to draw 2 tickets (size = 2), with replacement36, from a box with tickets labeled 1, 2, 3, and 4 (entered as the Python list [1, 2, 3, 4]). Each simulated outcome consists of an ordered37 pair of rolls. The sim(n) command simulates n realizations of probability space outcomes (or events or random variables). print(P.sim(10)) ## &lt;symbulate.results.Results object at 0x00000000207D6F48&gt; 3.2.2 Simulating random variables A Symbulate RV is specified by the probability space on which it is defined and the mapping function which defines it. Recall that \\(X\\) is the sum of the two dice rolls and \\(Y\\) is the larger (max). X = RV(P, sum) Y = RV(P, max) The above code simply defines the random variables. Since a random variable \\(X\\) is a function, any RV can be called as a function38 to return its value \\(X(\\omega)\\) for a particular outcome \\(\\omega\\) in the probability space. omega = (3, 2) # a pair of rolls print(X(omega), Y(omega)) ## Warning: Calling an RV as a function simply applies the function that defines the RV to the input, regardless of whether that input is a possible outcome in the underlying probability space. ## Warning: Calling an RV as a function simply applies the function that defines the RV to the input, regardless of whether that input is a possible outcome in the underlying probability space. ## 5 3 The following commands simulate 100 values of the random variable Y and store the results as y. For consistency with standard notation, the random variable itself is denoted with an uppercase letter Y, while the realized values of it are denoted with a lowercase letter y. y = Y.sim(100) print(y) ## &lt;symbulate.results.RVResults object at 0x000000001FA99748&gt; Values and their frequencies can be summarized using tabulate. print(y.tabulate()) ## {2: 16, 4: 43, 1: 6, 3: 35} By default, tabulate returns frequencies (counts). Adding the argument normalize = True returns relative frequencies (proportions). print(y.tabulate(normalize = True)) ## {2: 0.16, 4: 0.43, 1: 0.06, 3: 0.35} Methods like sim and tabulate can be chained together in a single line of code. Y.sim(100).tabulate(normalize = True) ## {2: 0.17, 4: 0.44, 1: 0.09, 3: 0.3} Each call to sim reruns the simulation to generate a new set of simulated values. To perform multiple operations on a single set of simulated values, store the simulation results as a variable (like y above). When running Y.sim(100) Symbulate simulates, in the background, outcomes from the probability space P and then computes Y for these outcomes; however, the outcomes themselves are not saved. (We will soon see how to simulate multiple quantities simultaneously.) We can plot the 100 individual simulated values of \\(Y\\) in a rug plot. y.plot(&#39;rug&#39;) plt.show() The rug plot emphasizes that realizations of the random varible \\(Y\\) are numbers along a number line. However, the rug plot does not adequately summarize the relative frequencies. Instead, calling .plot() produces39 an impulse plot which displays the simulated values and their relative frequencies. y.plot() plt.show() 3.2.3 Approximating distributions The true distribution of \\(Y\\) is displayed in Figure XXX. The plot above, based on only 100 simulated values, provides a poor approximation to the distribution of \\(Y\\). We often initially simulate a small number of repetitions to see what the simulation is doing and check that it is working properly. However, in order to accurately approximate probabilities or distribution we simulate a large number of repetitions (usually thousands for our purposes). Now we simulate 10,000 values of the random variable Y and summarize the simulation output to approximate the distribution of \\(Y\\). Since the simulation results below are stored as y, the same set of results is used to produce the table and the plot. Compare the simulation results with Table XXX and Figure XXX. The results of 10000 repetitions provide a much better approximation to the true distribution of \\(Y\\) than the results of just 100 repetitions. y = Y.sim(10000) print(y.tabulate()) ## {4: 4412, 1: 611, 3: 3162, 2: 1815} y.plot() plt.show() ## Traceback (most recent call last): ## File &quot;C:\\Users\\kjross\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_qt5.py&quot;, line 508, in _draw_idle ## self.draw() ## File &quot;C:\\Users\\kjross\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py&quot;, line 388, in draw ## self.figure.draw(self.renderer) ## File &quot;C:\\Users\\kjross\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py&quot;, line 38, in draw_wrapper ## return draw(artist, renderer, *args, **kwargs) ## File &quot;C:\\Users\\kjross\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py&quot;, line 1709, in draw ## renderer, self, artists, self.suppressComposite) ## File &quot;C:\\Users\\kjross\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py&quot;, line 135, in _draw_list_compositing_images ## a.draw(renderer) ## File &quot;C:\\Users\\kjross\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py&quot;, line 38, in draw_wrapper ## return draw(artist, renderer, *args, **kwargs) ## File &quot;C:\\Users\\kjross\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py&quot;, line 2607, in draw ## self._update_title_position(renderer) ## File &quot;C:\\Users\\kjross\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py&quot;, line 2548, in _update_title_position ## ax.xaxis.get_ticks_position() in choices): ## File &quot;C:\\Users\\kjross\\Anaconda3\\lib\\site-packages\\matplotlib\\axis.py&quot;, line 2146, in get_ticks_position ## self._get_ticks_position()] ## File &quot;C:\\Users\\kjross\\Anaconda3\\lib\\site-packages\\matplotlib\\axis.py&quot;, line 1833, in _get_ticks_position ## minor = self.minorTicks[0] ## IndexError: list index out of range Figure 3.3: Simulation-based approximate distribution of \\(Y\\), the larger (or common value if a tie) of two rolls of a fair four-sided die. The following is a summary of a simulation of \\(X\\) values. Compare with XXX x = X.sim(10000) print(x.tabulate()) ## {8: 618, 7: 1200, 4: 1832, 6: 1940, 5: 2446, 3: 1287, 2: 677} x.plot() plt.show() 3.2.4 Simulating events Events can also be defined and simulated. For programming reasons, events are enclosed in parentheses () rather than braces \\(\\{\\}\\). A = (Y &lt; 3) # an event A realization of an event is True if the event occurs for the simulated outcome, or False if not. print(A.sim(10)) ## &lt;symbulate.results.Results object at 0x000000002B49C808&gt; For logical equality use a double equal sign ==. For example, (Y == 3) represents the event \\(\\{Y=3\\}\\). B = (Y == 3) # an event print(B.sim(10000).tabulate()) ## {True: 3237, False: 6763} 3.2.5 Simulating multiple random variables We can simulate \\((X, Y)\\) pairs using40 &amp;. We store the simulation output as xy to emphasize that xy contains pairs of values. xy = (X &amp; Y).sim(100) print(xy) ## &lt;symbulate.results.RVResults object at 0x000000002B4A0AC8&gt; Pairs of values can also be tabulated. print(xy.tabulate()) ## {(3, 2): 15, (6, 4): 15, (4, 3): 10, (5, 4): 9, (7, 4): 16, (8, 4): 6, (4, 2): 7, (2, 1): 5, (5, 3): 16, (6, 3): 1} print(xy.tabulate(normalize = True)) ## {(3, 2): 0.15, (6, 4): 0.15, (4, 3): 0.1, (5, 4): 0.09, (7, 4): 0.16, (8, 4): 0.06, (4, 2): 0.07, (2, 1): 0.05, (5, 3): 0.16, (6, 3): 0.01} Individual pairs can be plotting in a scatter plot, which is a two-dimensional analog of a rug plot. xy.plot() plt.show() The values can be “jittered” slightly, as in Figure ??, so that points do not coincide. xy.plot(jitter = True) plt.show() The two-dimensional analog of an impulse plot is a tile plot. For two discrete variables, the 'tile' plot type produces a tile plot (a.k.a. heat map) where rectangles represent the simulated pairs with their relative frequencies visualized on a color scale. xy.plot(&#39;tile&#39;) plt.show() We can add the impulse plot for each of each \\(X\\) and \\(Y\\) in the margins of the tile plot using the 'marginals' argument. xy.plot([&#39;tile&#39;, &#39;marginals&#39;]) plt.show() 3.2.6 Simulating outcomes and random variables Recall Table 3.1 which displays both the outcomes of the two rolls and the corresponding values of \\(X\\) and \\(Y\\) for 10 repetitions. Calling (X &amp; Y).sim(10) as in the previous section produces results like those in the table, but only the values of (X &amp; Y) are saved and displayed. The outcomes of the rolls are generated in the background but not saved. We can create a RV which returns the outcomes of the probability space41. The default mapping function for RV is the identity function, \\(g(u) = u\\), so simulating values of U=RV(P) below returns the outcomes of the BoxModel P representing the outcome of the two rolls. U = RV(P) U.sim(10) ## &lt;symbulate.results.RVResults object at 0x000000002E664188&gt; Now we can simulate and display the outcomes along with the values of \\(X\\) and \\(Y\\) using &amp;. (U &amp; X &amp; Y).sim(10) ## &lt;symbulate.results.RVResults object at 0x000000002B537C88&gt; Because the probability space P returns pairs of values, U=RV(P) abve defines a random vector. The individual components^[The components can also be accessed using brackets. U1, U2 = RV(P) is shorthand for U = RV(P) U1 = U[0] U2 = U[1] Python uses zero-based indexing, so 0 refers to the first components, 1 to the second, and so on.] of U can be “unpacked” as U1, U2 in the following. Here U1 represents the result of the first roll and U2 the second. U1, U2 = RV(P) (U1 &amp; U2 &amp; X &amp; Y).sim(10) ## &lt;symbulate.results.RVResults object at 0x000000002B57F248&gt; 3.2.7 Simulating equally likely outcomes In the code above we used a box model to specify the probability space correspoding to pairs of rolls of a four-sided die. When tickets are equally likely and sampled with replacement, a Discrete Uniform model can also be used. Think of a DiscreteUniform(a, b) probability space corresponding to a spinner with sectors of equal area labeled with integer values from a to b (inclusive). For example, the spinner in Figure 3.1 corresponds to DiscreteUniform(1, 4). In the following, \\(U\\) represents the result of a single roll of a fair four-sided die. The default mapping function in RV is the identity, so U = RV(P) represents42 \\(U(\\omega) = \\omega\\). P = DiscreteUniform(a = 1, b = 4) U = RV(P) plt.figure() U.sim(10000).plot() plt.show() For two rolls the probability space corresponds to spinning the DiscreteUniform spinner two times, which is coded43 as DiscreteUniform(a = 1, b = 4) ** 2. The first line below has the same effect44 as BoxModel([1, 2, 3, 4], size = 2, replace = True). P = DiscreteUniform(a = 1, b = 4) ** 2 X = RV(P, sum) Y = RV(P, max) plt.figure() (X &amp; Y).sim(10000).plot([&#39;tile&#39;, &#39;marginals&#39;]) plt.show() 3.2.8 Brief summary of Symbulate commands Many scenarios require only a few lines of Symbulate code to set up, run, analyze, and visualize. Table comprises the requisite Symbulate commands for a wide variety of situations. Command Function BoxModel Define a box model ProbabilitySpace Define a custom probability space RV Define random variables, vectors, or processes RandomProcess Define a discrete or continuous time stochastic process apply Apply transformations [] (brackets) Access a component of a random vector, or a random process at a particular time * (and **) Define independent probability spaces or distributions AssumeIndependent Assume random variables or processes are independent | (vertical bar) Condition on events &amp; Join multiple random variables into a random vector sim Simulate outcomes, events, and random variables, vectors, and processes tabulate Tabulate simulated values plot Plot simulated values filter (and relatives) Create subsets of simulated values (filter_eq, filter_lt, etc) count (and relatives) Count simulated values which satisfy some critera (count_eq, count_lt, etc) Statistical summaries mean, median, sd, var, quantile, corr, cov, etc. Common models See Chapters ?? and ?? While no previous experience with Python is required, it is also possible to incorporate Python programming with Symbulate code. In particular, Python functions or loops can be used: to define or transform random variables or stochastic processes, or to investigate the effects of changing parameter values. Also, while many common plots are built in with the Symbulate plot function, the Matplotlib package can be used to create or customize plots. Some of these features will be illustrated in the next section and more examples are found throughout the text. 3.2.9 Exercises Example 3.4 Flip a coin 4 times and let \\(X\\) be the number of H. Write the Symbulate code to define X using a box model with tickets labeled H and T. Simulate a few outcomes and a few values of X. Write the Symbulate code to define X using a box model with tickets labeled 1 and 0 and without counting. Simulate a few outcomes and a few values of X. Write the Symbulate code to conduct a simulation and use the results to approximate \\(\\IP(X = 3)\\). Solution. to Example 3.3. See code below. Note the use of count_eq with the H/T labels and sum with the 1/0 labels. (It is also possible to use count_eq(1) with the 1/0 labels, but the point of indicators is that they turn counting into summing.) P = BoxModel([&#39;H&#39;, &#39;T&#39;], size = 4) P.sim(5) # a few outcomes ## &lt;symbulate.results.Results object at 0x000000002EB49048&gt; X = RV(P, count_eq(&#39;H&#39;)) X.sim(5) # a few values of X ## &lt;symbulate.results.RVResults object at 0x000000002EB492C8&gt; X.sim(10000).count_eq(3) / 10000 ## 0.2443 P = BoxModel([&#39;H&#39;, &#39;T&#39;], size = 4) P.sim(5) # a few outcomes ## &lt;symbulate.results.Results object at 0x000000002EB49508&gt; X = RV(P, count_eq(&#39;H&#39;)) X.sim(5) # a few values of X ## &lt;symbulate.results.RVResults object at 0x000000002E4BB1C8&gt; X.sim(10000).count_eq(3) / 10000 ## 0.2545 Technically, a probability space is a triple \\((\\Omega, \\mathcal{F}, \\IP)\\). We primarily view a Symbulate probability space as a description of the probability model rather than an explicit specification of \\(\\Omega\\). For example, we define a BoxModel instead of creating a set with all possible outcomes. We tend to represent a probability space with P, even though this is a slight abuse of notation.↩︎ The default argument for replace is True, so we could have just written BoxModel([1, 2, 3, 4], size = 2).↩︎ There is an additional argument order_matters which defaults to True, but we could set it to false for unordered pairs.↩︎ The warning you get when you call a RV as a function just means that Symbulate is not going to check for you that the inputs to the function you used to define the RV actually match up with the outcomes of the probability space P.↩︎ For discrete random variables 'impulse' is the default plot type. Like .tabulate(), the .plot() method also has a normalize argument; the default is normalize=True.↩︎ Technically &amp; joins two RVs together to form a random vector. While we often intepret Symbulate RV as random variable, it really functions as random vector.↩︎ You might try (P &amp; X ).sim(10). But P is a probability space object, and X is an RV object, and &amp; can only be used to join like objects together. Much like in probability theory in generality, in Symbulate the probability space plays a background role, and it is usually random variables we are interested in.↩︎ For technical reasons, Symbulate will not plot simulated outcomes from a ProbabilitySpace, only simulated realizations of an RV. Essentially, as mentioned in earlier sections, probability space outcomes can be anything — not necessarily numbers — and so there are too many potential situations and plots for Symbulate to handle with a single plot command. In contrast, simulated realizations of RV are numbers (or vectors of numbers) which facilitates plotting. Plotting simulated outcomes from a probability space P with numerical outcomes can be achieved by first defining X = RV(P) and then simulating and plotting values of X. That is, replace P.sim(1000).plot() with RV(P).sim(1000).plot(). However, this only works if the outcomes of P are numerical.↩︎ For now you can interpretDiscreteUniform(a = 1, b = 4) as a spinner with four quarters labeled 1, 2, 3, 4, and ** 2 as “spin the spinner twice”. In Python, ** represents exponentiation; e.g., 2 ** 5 = 32. So DiscreteUniform(a = 1, b = 4) ** 2 is equivalent to DiscreteUniform(a = 1, b = 4) * DiscreteUniform(a = 1, b = 4). Future sections will reveal why the product * notation is natural for independent spins of spinners.↩︎ BoxModel assumes equally likely tickets by default, but there are options for non-equally likely cases.↩︎ "],
["moe.html", "3.3 Approximating probabilities: Simulation margin of error", " 3.3 Approximating probabilities: Simulation margin of error The probability of an event can be approximated by simulating the random phenomenon a large number of times and computing the relative frequency of the event. However, while after enough repetitions we expect the simulated relative frequency to be close to the true probability, there probably won’t be an exact match. Therefore, in addition to reporting the approximate probability, we should also provide a margin of error which indicates how close we think our simulated relative frequency is to the true probability. Continuing the dice example, suppose we want to estimate \\(\\IP(X=6)\\), the probability that the sum of two rolls of a fair four-sided is six. The true probability is \\(3/16=0.1875\\). We will now carry out an analysis similar to the coin flipping example in Section 1.2.1 to investigate simulation margin of error and how it is influenced by the number of simulated values used to compute the relative frequency. We will perform a “meta-simulation”. The process is as follows Simulate two rolls of a fair four-sided die. Compute the sum (\\(X\\)) and see if it is equal to 6. Repeat step 1 to generate \\(n\\) simulated values of the sum (\\(X\\)). Compute the relative frequency of sixes: count the number of the \\(n\\) simulated values equal to 6 and divide by \\(n\\). Denote this relative frequency \\(\\hat{p}\\). Repeat step 2 a large number of times, recording the relative frequency \\(\\hat{p}\\) for each set of \\(n\\) values. Be sure to distinguish between steps 2 and 3. A simulation will typically involve just steps 1 and 2, resulting in a single relative frequency based on \\(n\\) simulated values. Step 3 is the “meta” step; we see how this relative frequency varies from simulation to simulation to help us in determing an appropriate margin of error. The important quantity in this analysis is \\(n\\), the number of simulated values used to compute relative frequency in a single simulation. We wish to see how \\(n\\) impacts margin of error. The number of simulations in step 3 just needs to be “large” enough to provide a clear picture of how the relative frequency varies from simulation to simulation. The more the relative frequency varies from simulation to simulation, the larger the margin of error needs to be. We can combine steps 1 and 2 of the meta-simulation to put it in the framework of the simulations from earlier in this chapter. Namely, we can code the meta-simulation as a single simulation in which A sample space outcome represents \\(n\\) values of the sum of two fair-four sided dice The main random variable of interest is the proportion of the \\(n\\) values which are equal to 6. Let’s first consider \\(n=100\\). The following Symbulate code defines the probability space corresponding to 100 values of the sum of two-fair four sided dice. Notice the use of apply which functions much in the same way45 as RV. n = 100 P = (DiscreteUniform(1, 4) ** 2).apply(sum) ** n P.sim(5) ## &lt;symbulate.results.Results object at 0x000000002EB49288&gt; In the code above DiscreteUniform(1, 4) ** 2 simulates two rolls of a fair four-sided die .apply(sum) computes the sum of the two rolls ** n repeats the process n times to generate a set of n independent values, each value representing the sum of two rolls of a fair four-sided die P.sim(5) simulates 5 sets, each set consisting of n sums Now we define the random variable which takes as an input a set of \\(n\\) sums and returns the proportion of the \\(n\\) sums which are equal to six. phat = RV(P, count_eq(6)) / n phat.sim(5) ## &lt;symbulate.results.RVResults object at 0x000000002E4BB3C8&gt; In the code above phat is an RV defined on the probability space P. Recall that an outcome of P is a set of n sums (and each sum is the sum of two rolls of a fair four-sided die). The function that defines the RV is count.eq(6), which counts the number of values in the set that are equal to 6. We then46 divide by n, the total number of values in the set, to get the relative frequency. (Remember that a transformation of a random variable is also a random variable.) phat.sim(5) generates 5 simulated values of the relative frequency phat. Each simulated value of phat is the relative frequency of sixes in n sums of two rolls of a fair four-sided die. Now we simulate and summarize a large number of values of phat. We’ll simulate 100 values for illustration. Be sure not to confuse 100 with n. Remmeber, the important quantity is n, the number of simulated values used in computing each relative frequency. phat.sim(100).plot(normalize = False) plt.ylabel(&#39;Number of simulations&#39;); plt.show() We see that the 100 relative frequencies are roughly centered around the true probability 0.1875, but there is variability in the relative frequencies from simulation to simulation. From the range of values, we see that most relative frequencies are within about 0.08 or so from the true probability 0.1875. So 0.08 seems like a reasonable value of the margin of error, but the actual depends on what we mean by “most”. We can get a clearer picture if we run more simulations. Now we repeat the analysis, but with \\(n=10000\\). In this case, each relative frequency is computed based on 10000 independent values, each value representing a sum of two rolls of a fair four-sided die. As before, we simulate 100 relative frequencies. n = 10000 P = (DiscreteUniform(1, 4) ** 2).apply(sum) ** n phat = RV(P, count_eq(6)) / n phat.sim(100).plot(normalize = False) plt.ylabel(&#39;Number of simulations&#39;); plt.show() Again we see that the 100 relative frequencies are roughly centered around the true probability 0.1875, but there is less variability in the relative frequencies from simulation to simulation for \\(n=10000\\) than for \\(n=100\\). From the range of values, we see that most relative frequencies are within about 0.007 of the true probability 0.1875. Thus, it seems reasonable to define 0.007 as the margin of error of a simulation-based approximation of \\(\\IP(X = 6)\\) based on \\(n=10000\\) repetitions. (cap:moe-compare) Comparison of margins of error for 95% confidence for the meta-simulations in Sections 1.2.1 and 3.3. Probability that True value 95% m.o.e. (n = 100) 95% m.o.e. (n = 10000) 95% m.o.e. (n = 1000000) A fair coin flip lands H 0.5000 0.1000 0.0100 1e-03 Two rolls of a fair four-sided die sum to 3 0.1875 0.0781 0.0078 8e-04 That is, the larger the number (\\(n\\)) of values used in the computation of relative frequency, the smaller the margin of error. Depends on true probability. Numerator is max at 0.5, so 1/sqrt(n). True probability is unknown in practice, so we can estimate the margin of error using by plugging in the approximate probability. As in Section 1.2.1 it appears that when we increase \\(n\\) by a factor of 100 (from 100 to 10000) we achieve an extra decimal place in precision. This is indeed the case in general. Remember: in any simulation the resulting probabilities are approximate. The margin of error between an actual probability and a simulated relative frequency is roughly on the order \\(1/\\sqrt{n}\\), where \\(n\\) is the number of simulated values used to calculate the relative frequency More precisely, if \\(\\hat{p}\\) represents the simulated relative frequency, we estimate with 95% confidence47 that the interval with endpoints \\[ \\hat{p}\\pm 2 \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{N}} \\] contains the actual probability. Warning: alternative methods are necessary when the actual probability being estimated is close to 0 or to 1. Finally, keep in mind that any probability is based on a series of assumptions and these assumptions are probably not satisfied exactly by the random phenomenon. For example, the probability that a coin lands on H is probably not 0.5 exactly . But there is no practical difference. For most of the situations we’ll enounter, estimating a probability to within 0.01 of its true value will be sufficient, and so simulations of size 10000 are appropriate. (Of course, there are situations where probabilities need to be estimated much more precisely, e.g., the probability that a bridge will collapse. These situations require more intensive methods.) One difference between RV and apply: apply preserves the type of the input object. That is, if apply is applied to a ProbabilitySpace then the output will be a ProbabilitySpace; if apply is applied to an RV then the output will be an RV. In contrast, RV always creates an RV.↩︎ Unfortunately, for techincal reasons, RV(P, count_eq(6) / n) will not work. It is possible to divide by n within RV if we define a custom function def rel_freq_six(x): return x.count_eq(6) / n and then define RV(P, rel_freq_six).↩︎ We will see the rationale behind this formula later in the class. The factor 2 comes from the fact that for a Normal distribution, about 95% of values are within 2 standard deviations of the mean. Technically, the factor 2 corresponds to 95% confidence only when a single probability is estimated. If multiple probabilities are estimated simultaneously, then alternative methods should be used, e.g., increasing the factor 2 using a Bonferroni correction. For example, a multiple of 5 rather than 2 produces very conservative error bounds.↩︎ "],
["non-equally-likely-outcomes-a-weighted-die.html", "3.4 Non-equally likely outcomes: A weighted die", " 3.4 Non-equally likely outcomes: A weighted die In the next few sections we will investigate some examples that further illustrate properties of random variables and distributions, the simulation process, and Symbulate code. Recall that the (probability) distribution of a random variable specifies the possible values of the RV and a way of determining corresponding probabilities. The distribution of a random variable specifies the long run pattern of variation of values of the random variable over many repetitions of the underlying random phenomenon. The distribution of a random variable (\\(X\\)) can be approximated by simulating an outcome of the underlying random phenomenon (\\(\\omega\\)) observing the value of the random variable for that outcome (\\((X(\\omega)\\)) repeating this process many times then computing relative frequencies involving the simulated values of the RV (\\(x\\)) to approximate probabilities of events involving the random variable (e.g., \\(\\IP(X\\le x)\\)). We will discuss distributions in more detail in Chapter XXX, but the examples in this Chapter provide an introduction to some of the ideas. One key idea is that any distribution can be represented by a spinner. For example, the spinner in Figure 3.1 corresponds to a single roll of a fair four-sided die. But what about a weighted die like the one in Example 2.31? Before considering the weighted die, let’s look at the fair die in Symbulate. Let \\(U\\) be the result of a single roll of a four-sided die. Let \\(\\IP\\) be the probability measure corresponding to a fair die. BoxModel assumes equally likely outcomes by default, so calling BoxModel([1, 2, 3, 4]) assumes a fair die. (The default size value is 1, so BoxModel([1, 2, 3, 4]) corresponds to a single roll of a fair four-sided die.) The random variable \\(U\\) is just the outcome of this roll, identified by the identity function \\(X(\\omega) = \\omega\\). (Recall that a Symbulate RV is always defined in terms of a probability space and a function RV(probspace, function). The default function is the identity: \\(g(\\omega) = \\omega\\).) P = BoxModel([1, 2, 3, 4]) U = RV(P) U.sim(10000).plot() plt.show() The plot displays a simulation-based approximation to the distribution of \\(U\\) according to the probability measure \\(\\IP\\). We see that the four values are equally likely. This distribution can be represented by the spinner in Figure 3.1. Now consider the weighted die in Example 2.31: a single roll results in 1 with probability 1/10, 2 with probability 2/10, 3 with probability 3/10, 4 with probability 4/10. Let \\(\\IQ\\) be the probability measure corresponding to the assumption that the die is weighted as in Example 2.31. We can specify non-equally likely outcomes in BoxModel using the probs option. The probability space Q in the following code corresponds to a single roll of the weighted die. Note that \\(U\\) is still defined via the identity function. Q = BoxModel([1, 2, 3, 4], probs = [0.1, 0.2, 0.3, 0.4]) U = RV(Q) U.sim(10000).plot() plt.show() The plot displays a simulation-based approximation to the distribution of \\(U\\), but now according to the probability measure \\(\\IQ\\). This distribution can be represented by the spinner in Figure 3.4. Figure 3.4: Spinner corresponding to a single roll of the weighted four-sided die in Example 2.31. Note that in the two scenarios, (1) the sample space is the same, \\(\\Omega=\\{1,2,3,4\\}\\), and (2) the random variable is the same function, \\(U(\\omega) = \\omega\\). What changes is the probability measure, from \\(\\IP\\) (fair die) to \\(\\IQ\\) (weighted die). Changing the probability measure changes the distribution of \\(U\\). Another way to model a weighted die is with a box model with 10 tickets — one ticket labeled 1, two tickets labeled 2, three tickets labeled 3, and four tickets labeled 4 — from which a single ticket is drawn. A BoxModel can be specified in this way using the following {label: number of tickets with the label} formulation48. This formulation is especially useful when multiple tickets are drawn from the box without replacement. Q = BoxModel({1: 1, 2: 2, 3: 3, 4: 4}) U = RV(Q) U.sim(10000).plot() plt.show() Some lessons from this example. Changing a probability measure changes distributions of random variables. Distributions can be represented by spinners. Box models can handle situations with non-equally likely outcomes. In Symbulate, BoxModel has options like probs that can be used to specify probabilities of individual outcomes. Braces {} are used here because this defines a Python dictionary. But don’t confuse this code with set notation↩︎ "],
["joint-distributions-rolling-dice-yet-again.html", "3.5 Joint distributions: rolling dice yet again", " 3.5 Joint distributions: rolling dice yet again The example in Section 3.2 involved the sum \\(X\\) and max \\(Y\\) of two rolls of a fair four-sided die. In Example 2.42 we found \\(\\IP(X=4, Y=3)=2/16\\). In a similar way, we can find \\(\\IP(X=x, Y=y)\\) for each possible \\((x, y)\\) pair. These values, displayed in Table 3.2, specify the joint distribution of \\(X\\) and \\(Y\\). Table 3.2: Joint distribution of \\(X\\) and \\(Y\\), the sum and the larger (or common value if a tie) of two rolls of a fair four-sided die. Possible values of \\(X\\) are in the leftmost column; possible values of \\(Y\\) are in the top row. \\(x\\) \\ \\(y\\) | 1 2 3 4 2 | 1/16 0 0 0 3 | 0 2/16 0 0 4 | 0 1/16 2/16 0 5 | 0 0 2/16 2/16 6 | 0 0 1/16 2/16 7 | 0 0 0 2/16 8 | 0 0 0 1/16 Notice that the tile plot suggests a tactile method for simulating \\((X, Y)\\) pairs directly. Namely, pairs generated using the spinner in Figure 3.5 below will follow the same pattern as in the above tile plot. (The spinner in Figure 3.5 represents the joint distribution of \\((X, Y)\\).) Figure 3.5: Spinner which generates \\((X, Y)\\) pairs, where \\(X\\) is the sum and \\(Y\\) is the larger (or common value if a tie) of two rolls of a fair four-sided die. The joint distribution in Table 3.2 corresponds to the spinner in Figure 3.5. Once we have obtained the distribution, we now have two ways to simulate an \\((X, Y)\\) pair with the distribution inTable 3.2 . Simulate two rolls of a fair four sided die. Let \\(X\\) be the sum of the two values and let \\(Y\\) be the larger of the two rolls (or the common value if a tie). Spin the spinner in Figure 3.5 once and record the resulting \\((X, Y)\\) pair. (Recall that this spinner returns a pair of values.) Of course, the second method requires that the distribution of \\((X, Y)\\) is known. But in principle, there are always two ways of simulating a value \\(x\\) of a random variable \\(X\\). (Simulate from the probability space.) Simulate an outcome \\(\\omega\\) from the underlying probability space and set \\(x = X(\\omega)\\). (Simulate from the distribution.) Construct a spinner corresponding to the distribution of \\(X\\) and spin it once to generate \\(x\\). The second method requires that the distribution of \\(X\\) is known. However, as we will see in many examples, it is common to specify the distribution of a random variable directly without defining the underlying probability space. Below is the Symbulate code for the second method, which corresponds to the spinner in Figure 3.5. Note that the probability space outcomes (the tickets in BoxModel) correspond to the possible \\((X, Y)\\) pairs, which are not equally likely (even though the 16 pairs of rolls are). We specify the probability of each outcome by using the probs option. To generate a single \\((X, Y)\\) pair, we spin the spinner once, and we draw one ticket from the box of pairs; this is why size = 1. xy_pairs = [(2, 1), (3, 2), (4, 2), (4, 3), (5, 3), (5, 4), (6, 3), (6, 4), (7, 4), (8, 4)] pxy = [1/16, 2/16, 1/16, 2/16, 2/16, 2/16, 1/16, 2/16, 2/16, 1/16] P = BoxModel(xy_pairs, probs = pxy, size = 1, replace = True) print(P.sim(5)) ## &lt;symbulate.results.Results object at 0x000000002B495708&gt; We now wish to define the random variables \\(X\\) and \\(Y\\). An outcome of P is a pair of values. Recall that a Symbulate RV is always defined in terms of a probability space and a function RV(probspace, function). The default function is the identity: \\(g(\\omega) = \\omega\\). Therefore, RV(P) would just correspond to the pair of values generated by P. The sum \\(X\\) corresponds to the first coordinate in the pair and the max \\(Y\\) corresponds to the second. We can define these random variables in Symbulate by “unpacking” the pair as in the following49 X, Y = RV(P) (X &amp; Y).sim(5) ## &lt;symbulate.results.RVResults object at 0x000000002B4954C8&gt; Then we can simulate many \\((X, Y)\\) pairs and summarize as before. The tile plot depicts the approximate joint distribution on \\((X, Y)\\) pairs. The impulse plots in the “margins” of the plot are the simulated “marginal distributions” of \\(X\\) and \\(Y\\). xy = (X &amp; Y).sim(16000) plt.figure() xy.plot([&#39;tile&#39;, &#39;marginal&#39;]) plt.show() xy.tabulate() ## {(5, 4): 2060, (3, 2): 2055, (6, 4): 1970, (4, 3): 1998, (7, 4): 1883, (4, 2): 998, (8, 4): 944, (5, 3): 2048, (2, 1): 1008, (6, 3): 1036} We can compute \\(\\IP(X=4)\\) from the joint distribution by summing over the possible \\((X, Y)\\) pairs for which \\(X=4\\): \\(\\IP(X=4) = \\IP(X=4, Y=2) + \\IP(X=4, Y=3)=3/16\\). In the context of multiple random variables, a probability involving only one of the random variables is called a marginal probability. The marginal distribution of \\(X\\) is obtained by computing \\(\\IP(X=x)\\) for each possible value of \\(x\\). This is accomplished by summing across the columns in Table 3.2. Similarly, the marginal distribution of \\(Y\\) is obtained by summing across the rows. Think of adding a total column (for \\(X\\)) and a total row (for \\(Y\\)) in the “margins” of the table. For example, the marginal distribution of \\(Y\\) is displayed in the following table; a simulation-based approximation is displayed in Figure 3.3. \\(y\\) | 1 2 3 4 \\(\\IP(Y=y)\\) 1/16 | 3/16 5/16 | 7/16 The marginal distributions of \\(X\\) and \\(Y\\) can be depicted as spinners, as in Figure 3.6. Figure 3.6: Marginal distributions of \\(X\\) (left) and \\(Y\\) (right), the sum and the larger (or common value if a tie) of two rolls of a fair four-sided die. Example 3.5 (Don’t do what Donny Don’t does.) Donny says “Forget the spinner in Figure 3.5. I can simulate an \\((X, Y)\\) pair just by spinning each of the spinners in Figure 3.6 once.” Is Donny correct? If not, can you help him see why not? Solution. to Example 3.5 Donny is not correct. Yes, spinning the \\(X\\) spinner in Figure 3.6 will generate values of \\(X\\) according to the proper marginal distribution, and similarly for \\(Y\\). However, spinning each of the spinners will not produce \\((X, Y)\\) pairs with the correct joint distribution. For example, Donny’s method could produce \\(X=2\\) and \\(Y=4\\), which is not a possible \\((X, Y)\\) pair. Donny’s method treats the values of \\(X\\) and \\(Y\\) as if they were independent; the result of the \\(X\\) spin would not change what could happen with the \\(Y\\) spin (since the spins are physically independent). However, the \\(X\\) and \\(Y\\) values are related. For example, if \\(X=2\\) then \\(Y\\) must be 1; if \\(X=4\\) then \\(Y\\) must be 2 or 3. The joint distribution spinner in Figure 3.5 correctly reflects the relationship between \\(X\\) and \\(Y\\). But in general, you cannot recover the joint distribution from the marginal distributions, which is what Donny is attempting to do. Just because you know the row and column totals doesn’t mean you know all the values of the interior cells in the joint distribution table. Donny’s method corresponds to (1) rolling the die twice and summing to get \\(X\\), (2) rolling the die two more times and finding the larger roll to get \\(Y\\). Essentially, Donny is not using the same probability space for \\(X\\) and \\(Y\\), and therefore events involving both random variables cannot be studied. In Symbulate, Donny’s code — which would produce an error — would look like X = RV(BoxModel([1, 2, 3, 4], size = 2), sum) Y = RV(BoxModel([1, 2, 3, 4], size = 2), max) (X &amp; Y).sim(10000) ### Error: Events must be defined on same probability space. In Donny’s code, his random variables are defined on different probability spaces; one box model is used to generate the rolls for \\(X\\) and a separate box model is used to generate the rolls for \\(Y\\). As we have mentioned a few times, random variables (and events) must all be defined on the same probability space50. Example 3.6 (Don’t do what Donny Don’t does.) Donny says “I see what you mean about needing the spinner in Figure 3.5 to simulate \\((X, Y)\\) pairs. So then forget the spinners in Figure 3.6. If I want to simulate \\(X\\) values, I could just spin the spinner in Figure 3.5 and ignore the \\(Y\\) values.” Is Donny’s method correct? If not, can you help him see why not? Solution. to Example 3.6 Donny is correct! The joint distribution spinner in Figure 3.5 correctly produces \\((X, Y)\\) pairs according to the joint distribution in Table 3.2. Ignoring the \\(Y\\) values is like “summing across the rows” and only worrying about what happens in total for \\(X\\). For example, in the long run, 1/16 of spins will generate (4, 2) and 2/16 of spins will generate (4, 3), so ignoring the \\(y\\) values, 3/16 of spins will return an \\(x\\) value of 4. From the joint distribution you can always find the marginal distributions (by finding row and column totals). (Donny’s method does work, but it does require more work than necessary. If you really only needed to simulate \\(X\\) values, you only need the distribution of \\(X\\) and not the joint distribution of \\(X\\) and \\(Y\\), so you could use the \\(X\\) spinner in Figure 3.6.) Some lessons from this example. There are two ways to simulate a value of a random variable. Simulate an outcome from the underlying probability space and evaluate the random variable for the simulated outcome. Find the distribution of the random variable, and simulate a value from that distribution (e.g., by constructing a spinner). To simulate an \\((X, Y)\\) pair it is, in general51, not sufficient to simulate a value of \\(X\\) from its marginal distribution and a value of \\(Y\\) from its marginal distribution. Instead, a pair \\((X, Y)\\) must be simulated from the joint distribution. Since P returns pairs of outcomes, Z=RV(P) is a random vector. Components of a vector can be indexed with brackets []; e.g., the first component is Z[0] and the second is Z[1]. (Remember: Python uses zero-based indexing.) So the “unpacked” code is an equivalent but simpler version of Z = RV(P); X = Z[0]; Y = Z[1].↩︎ If Donny really wanted to simulate two independent pairs of rolls, one to compute \\(X\\) and one to compute \\(Y\\), he would still need define the random variables on the same probability space, using BoxModel([1, 2, 3, 4], size = 2) ** 2 for which an example outcome would be ((3, 2), (1, 1)). Then he could define X=RV(P)[0].apply(sum) and X=RV(P)[1].apply(max). But it’s hard to justify why Donny would want to do this.↩︎ When \\(X\\) and \\(Y\\) are independent it is sufficient to simulate values of \\(X\\) and \\(Y\\) separately from their respective marginal distributions. We study independence in detail in Section ??.↩︎ "],
["sec-mscoin-sim.html", "3.6 Customizing random variables: Heads following Heads", " 3.6 Customizing random variables: Heads following Heads Recall the coin flipping problem in Section 1.5. Flip a fair coin four times and record the results in order. For the recorded sequence, compute the proportion of the flips which immediately follow a H that result in H. What value do you expect for this proportion? (If there are no flips which immediately follow a H, i.e. the outcome is either TTTT or TTTH, discard the sequence and try again with four more flips.) For example, the sequence HHTT means the the first and second flips are heads and the third and fourth flips are tails. For this sequence there are two flips which immediately followed heads, the second and the third, of which one (the second) was heads. So the proportion in question for this sequence is 1/2. We saw in Example 2.26 that the quantity of interest, the proportion Proportion of H following H, is a random variable. We define the random variables \\(Z\\), the number of flips immediately following H. \\(Y\\), the number of flips immediately following H that result in H. \\(X=Y/Z\\), the proportion of flips immediately following H that result in H. Table 2.4 displays the 16 possible outcomes in the sample space along with the value of \\(X, Y, Z\\) for each outcome. Note that \\(X\\) takes values in \\(\\{0, 1/2, 2/3, 1\\}\\). Now let’s assume the 16 outcomes are equally likely. This corresponds to assuming (1) the coin is fair (that is, any flip is equally likely to land on H or T), and (2) the result of one flip has no bearing on the others (that is, the flips are independent). One technicality is that \\(Y\\) and \\(X\\) are not defined for the outcomes TTTH and TTTT and we assume that these outcomes are discarded. One way to model this scenario is with a probability measure \\(\\IP\\) that assigns probability 0 to the event \\(\\{TTTH, TTTT\\}\\) and probability 1/14 to each of the remaining outcomes. Using Table 2.4 we can summarize the behavior of \\(X\\) according to the probability measure \\(\\IP\\). Namely, we compute \\(\\IP(X=x)\\) for each possible value of \\(x\\). These values, reported in 3.3, describe the distribution of the random variable \\(X\\), which is depicted in the spinner in Figure Table 3.3: Distribution of \\(X\\), the proportion of flips immediately following H that result in H, for four flips of a fair coin. \\(x\\) | \\(\\IP(X=x)\\) | (Corresponding outcomes) | 0 | 6/14 | \\(\\{HTHT, HTTH, HTTT, THTT, THTH, TTHT\\}\\) | 1/2 | 4/14 | \\(\\{HHTH, HTHH, HHTT, THHT\\}\\) | 2/3 | 1/14 | \\(\\{HHHT\\}\\) | 1 | 3/14 | \\(\\{HHHH, THHH, TTHH\\}\\) | Figure 3.7: Spinner corresponding to the distribution of the proportion of flips immediately following H that result in H, for four flips of a fair coin. We now use Symbulate to conduct a simulation. We first define the probability space of 16 equally likely outcomes, but when we run the simulation we’ll discard TTTH and TTTT, keeping only those repetitions which result in one of the other 14 outcomes. We define the probability space of 16 equally likely outcomes via a box model: P = BoxModel([0, 1], size = 4). When dealing with sequences of binary outcomes it is useful to define the outcome of interest as 1 and the other outcome as 0. In coin flips, we can define H as 1 and T as 0. For example, HHTT would be (1,1,0,0). With this formulation we can count the number of heads in a sequence by summing the 0/1 values in the sequence. If we sum the elements in the outcome sequence, we add 1 every time we see a H and 0 every time we see a T, resulting in the total number of H. For example (1, 1, 0, 0) leads to 1+1+0+0=2 H. We will define the random variables \\(X, Y, Z\\) in Symbulate. Remember that a random variable is a function defined on the probability space. In Section ??, simple built-in functions like sum and max were used to define RVs. For example, the random variable which counts the total number of H in the sequence of flips (using the 0/1 formulation) would be RV(P, sum). However, it is also possible to program custom functions to use in defining Symbulate random variables, e.g., X=RV(P, custom_function). You just need to make sure that the custom function takes as an input an object corresponding to the output of the probability space P. The custom function count_flips_following_H, defined using Python code below, takes as an input a sequence of coin flips and returns the number of flips in the sequence which immediately followed H; this will be used to define \\(Z\\). Similarly, the custom function count_H_following_H counts the number of flips immediately following H that result in H; this will be used to define \\(Y\\). For now, you don’t need to worry too much about the Python code. Just know that the functions do what they’re supposed to do. (And note that with the 0/1 formulation, we are counting H using sum.) def count_flips_following_H(omega): return sum(omega[0:(len(omega) - 1)]) def count_H_following_H(omega): return sum(a * b for a, b in zip(omega[1:len(omega)], omega[0:len(omega) - 1])) # An example outcome outcome = (1, 1, 0, 0) print(count_flips_following_H(outcome), count_H_following_H(outcome)) ## 2 1 Now we have everything we need to set up the probability space and random variables in Symbulate. Remember that transformations of random variables defined on the sample probability space are random variables. The same is true in Symbulate. Once we have defined Symbulate RVs Z and Y, we can define X = Y / Z, which will also be a Symbulate RV. P = BoxModel([1, 0], size = 4) Z = RV(P, count_flips_following_H) Y = RV(P, count_H_following_H) X = Y / Z # An example outcome outcome = (1, 1, 0, 0) print(Z(outcome), Y(outcome), X(outcome)) ## Warning: Calling an RV as a function simply applies the function that defines the RV to the input, regardless of whether that input is a possible outcome in the underlying probability space. ## Warning: Calling an RV as a function simply applies the function that defines the RV to the input, regardless of whether that input is a possible outcome in the underlying probability space. ## Warning: Calling an RV as a function simply applies the function that defines the RV to the input, regardless of whether that input is a possible outcome in the underlying probability space. ## 2 1 0.5 Now we run the simulation. Recall that the probability space corresponds to the 16 equally likely outcomes, but we want to discard TTTH and TTTT, the outcomes for which \\(Z=0\\). We do this by conditioning on the event \\(\\{Z&gt;0\\}\\) (coded in Symbulate as (Z&gt;0)). We will cover conditioning in much more detail starting in Chapter ??. For now, just read the code (X | (Z &gt; 0) ) as “keep values of X only for simulated repetitions for which \\(Z&gt;0\\) (and discard the rest)”. In the presence of conditioning, sim doesn’t count the values it discards, so the simulation below will continue to run until 14000 repetitions that satisfy (Z&gt;0) are obtained. x = (X | (Z &gt; 0) ).sim(14000) plt.figure() x.plot() plt.show() x.tabulate() ## {0.5: 3952, 0.0: 5977, 1.0: 3027, 0.6666666666666666: 1044} We see that the results of the simulation are consistent with the theoretical values in Table 3.3. That is, the simulated (long run) relative frequencies are close to the theoretical probabilities. As discussed in Section 1.5, one quantity of interest is the long run average of \\(X\\), which we can approximate by computing the mean (average) of the 14000 simulated values. print(x.mean()) ## 0.4070714285714286 We see the average of simulated values of \\(X\\) is close to 0.4. That is, 0.4 (roughly) is the average value of the proportion of H following H that we would expect to see in the long run over many sets of four fair coin flips. This is decidely less than 1/2; we think most people would find this surprising. The distribution of \\(X\\) is not centered at 0; it is more likely for \\(X\\) to be 0 than to be either 2/3 or 1. This imbalance pulls the long run average down below 0.5. We will return to this idea later. Some lessons from this example. The proportion of flips that immediately follow H that result in H is a random variable, and not a single number. This random variable has a distribution that is not centered at 1/2; the proportion of interest is more likely to be below 1/2 than above 1/2. A random variable is a function defined on a problem space. In Symbulate, custom functions can be used to define RVs. Both mathematically and in Symbulate, transformations of random variables defined on the same probability space are random variables. When dealing with sequences of binary outcomes it is useful to define the outcome of interest as 1 and the other outcome as 0. With this formulation, counting the 1s is equivalent to summing. We saw a brief introduction to how conditioning on event, with the vertical bar |, can be used to keep only those simulated repetitions that satisfy some criteria. "],
["changing-parameters-matching-problem.html", "3.7 Changing parameters: Matching problem", " 3.7 Changing parameters: Matching problem "],
["sec-linear-rescaling.html", "3.8 Outcomes on a continuous scale: Meeting times", " 3.8 Outcomes on a continuous scale: Meeting times Uniform distributions are the continuous analog of equally likely outcomes. The standard uniform distribution is the Uniform(0, 1) distribution corresponding to the spinner in Figure 2.2 which returns values between52 0 and 1. Recall that the values in the picture are rounded to two decimal places, but the spinner represents an idealized model where the spinner is infinitely precise so that any real number between 0 and 1 is a possible value. We assume that the (infinitely fine) needle is “equally likely” to land on any value between 0 and 1. The following Symbulate code defines a probability space representing the Uniform(0, 1) model, and a random variable equal to the result of a single spin: \\(U(\\omega)=\\omega\\). Recall that the default function used to define a Symbulate RV is the identity. The plot displays 100 simulated values. Note that the values seem to be “evenly spread” between 0 and 1. P = Uniform(0, 1) U = RV(P) plt.figure() U.sim(100).plot(&#39;rug&#39;) plt.show() The usual plot, and the Symbulate default, for summarizing values on a continuous scale is a histogram. A histogram groups the observed values into “bins” and plots relative frequencies for each bin53. Typically, in a histogram areas of bars represent relative frequencies; in which case the axis which represents the length of the bars is called “density”. It is recommended that the bins all have the same width so that area and length of the bars are equivalent, with the only difference being the scale on the axis (that is, with equal bin widths, density is a linear rescaling of height and bars with the same height represent the same area/relative frequency.) plt.figure() U.sim(10000).plot() plt.show() The standard uniform distribution, Uniform(0, 1), is a distribution on the interval \\([0, 1]\\). The uniform distribution on the interval \\([a, b]\\), for \\(a&lt;b\\), is called the Uniform(\\(a\\), \\(b\\)) distribution. Uniform distributions on other intervals can be obtained from the Uniform(0, 1) distribution via a linear rescaling. A linear rescaling is a transformation of the form \\(g(u) = a +bu\\). For example, converting temperature from Celsius to Fahrenheit using \\(g(u) = 32 + 1.8u\\) is a linear rescaling. A linear rescaling “preserves relative interval length” in the following sense. If interval A and interval B have the same length in the original measurement units, then the rescaled intervals A and B will have the same length in the rescaled units. For example, [0, 10] and [10, 20] Celsius, both length 10 degrees Celsius, correspond to [32, 50] and [50, 68] Fahrenheit, both length 18 degrees Fahrenheit. If the ratio of the lengths of interval A and B is \\(r\\) in the original measurement units, then the ratio of the lengths in the rescaled units is also \\(r\\). For example, [10, 30] is twice as long as [0, 10] in Celsius; for the corresponding Fahrenheit intervals, [50, 86] is twice as long as [32, 50]. Suppose \\(U\\) has a Uniform(0, 1) distribution. Then for any \\(a&lt;b\\), the linear rescaling \\(X = a + (b-a)U\\) has a Uniform(\\(a\\), \\(b\\)) distribution. (This rescaling maps 0 to \\(a\\) and 1 to \\(b\\), which corresponds to a line with y-intercept \\(a\\) and slope \\((b-a)/(1-0)\\).) For example, suppose that SAT Math scores have a uniform distribution on the interval \\([200, 800]\\). (This is certainly NOT true, and we will consider a more realistic distribution in Section ??.) If \\(X\\) denotes Math score, then we can simulate values of \\(X\\) by spinning the Uniform(0, 1) spinner to obtain \\(U\\) and set \\(X = 200 + 600 U\\). P = Uniform(0, 1) U = RV(P) X = 200 + 600 * U plt.figure() X.sim(100).plot(&#39;rug&#39;) plt.show() plt.figure() x= X.sim(10000) x.plot() plt.show() print(x.count_lt(300) / 10000, x.count_lt(400) / 10000, x.count_lt(500) / 10000) ## 0.1664 0.3287 0.4922 The plots show that the values are roughly uniformly distributed between 200 and 800: about 17% of values are between 200 and 300, about 17% between 300 and 400, about 17% between 400 and 500. Recall from Section 2.4.4 that for a continuous uniform distribution, probability is a ratio of lengths. Each of these intervals is length 100, and the total length of the interval of possible values is 600, so the theoretical probability for each interval is \\(100/600\\approx 0.167\\). Note that the shape of the histogram for the SAT scores is similar to that of the Uniform(0, 1) values. the only difference is the labeling on the horizontal axis. Because a linear rescaling preserves relative interval length, it will not change the shape of the histogram. That is, a linear rescaling does not change the shape of the distribution, only the range of possible values. For example, on the original [0, 1] scale, the intervals (0.1, 0.2) and (0.5, 0.6) both are of length 0.1 and so they each have probability 0.1/1. On the [200, 800] scale, these intervals correspond, respectively, to (260, 320) and (500, 560), each an interval of length 60 with probability \\(60/600=0.1\\). Roughly, all the values in the (0.1, 0.2) bin in the original scale map to the (260, 320) bin in the new scale, similarly for (0.5, 0.6) to (500, 560). Therefore, the shape of the histogram is preserved. Example 3.7 Let \\(\\IP\\) be the probabilty space corresponding to the Uniform(0, 1) spinner and let \\(U\\) represent the result of a single spin. Define \\(V=1-U\\). Does \\(V\\) result from a linear rescaling of \\(U\\)? What are the possible values of \\(V\\)? Is \\(V\\) the same random variable as \\(U\\)? Find \\(\\IP(U \\le 0.1)\\) and \\(\\IP(V \\le 0.1)\\). Sketch a plot of what the histogram of many simulated values of \\(V\\) would look like. Does \\(V\\) have the same distribution as \\(U\\)? Solution. to Example 3.7 Yes, \\(V\\) result from the linear rescaling \\(u\\mapsto 1-u\\) (intercept of 1 and slope of \\(-1\\).) \\(V\\) takes values in the interval [0,1]. (Basically, this transformation just changes the direction of the spinner from clockwise to counterclockwise. The axis on the usual spinner has values \\(u\\) increasing clockwise from 0 to 1. Applying the transformation \\(1-u\\), the values would decrease clockwise from 1 to 0.) No. \\(V\\) and \\(U\\) are different random variables. If the spin lands on \\(\\omega=0.1\\), then \\(U(\\omega)=0.1\\) but \\(V(\\omega)=0.9\\). \\(V\\) and \\(U\\) return different values for the same outcome; they are measuring different things. \\(\\IP(U \\le 0.1) = 0.1\\) and \\(\\IP(V \\le 0.1)=\\IP(1-U \\le 0.1) = \\IP(U\\ge 0.9) = 0.1\\). Note, however, that these are different events: \\(\\{U \\le 0.1\\}=\\{0 \\le \\omega \\le 0.1\\}\\) while \\(\\{V \\le 0.1\\}=\\{0.9 \\le \\omega \\le 1\\}\\). But each is an interval of length 0.1 so they have the same probability according to the uniform probability measure. Since \\(V\\) is a linear rescaling of \\(U\\), the shape of the histogram of simulated values of \\(V\\) should be the same as that for \\(U\\). Also, the possible values of \\(V\\) are the same as those for \\(U\\). So the histograms should look identical (aside from natural simulation variability). Yes, \\(V\\) has the same distribution as \\(U\\). While for any single outcome (spin), the values of \\(V\\) and \\(U\\) will be different, over many repetitions (spins) the pattern of variation of the \\(V\\) values, as depicted in a histogram, will be identical to that of \\(U\\). P = Uniform(0, 1) U = RV(P) V = 1 - U plt.figure() V.sim(10000).plot() plt.show() Some lessons from this example. A histogram can be used to summarize the distribution of a random variable that takes values on a continuous scale. When plotting values on a continuous scale in a histogram, relative frequencies are represented by areas. A linear rescaling of a random variable does not change the basic shape of its distribution, just the range of possible values. Do NOT confuse a random variable with its distribution. The RV is the numerical quantity being measured The distribution is the long run pattern of variation of many observed values of the RV Two random variables can have the same (long run) distribution, even if the values of the two random variables are never equal on any particular repetition (outcome). Why is the interval \\([0, 1]\\) the standard instead of some other range of values? Because probabilities take values in \\([0, 1]\\). We will see why this is useful in more detail later, but for a preview see ??.↩︎ Symbulate chooses the number of bins automatically, but you can set the number of bins using the bins option, e.g., .plot(bins=100)↩︎ "],
["appendix-distributions.html", "A Summary of common distributions", " A Summary of common distributions Figure A.1: A Uniform(0, 1) distribution spinner. The values in the picture are rounded to two decimal places, but in the idealized model the spinner is infitely precise so that any real number between 0 and 1 is a possible value. Figure A.2: An Exponential(1) distribution spinner. The values in the picture are rounded to two decimal places, but in the idealized model the spinner is infitely precise so that any real number between 0 and \\(\\infty\\) is a possible value. The spinner is duplicated on the right; the highlighted sectors illustrate the non-linearity of axis values and how this corresponds to the cdf \\(F_X(x)=1-e^{-x}, x&gt;0\\). "],
["appendix-plots.html", "B Visualizing and Summarizing Data", " B Visualizing and Summarizing Data We will generally be concerned with summarizing output from simulations of thousands of values, so we do not cover considerations for small data sets. "],
["a-few-common-plots-for-numerical-data.html", "B.1 A few common plots for numerical data", " B.1 A few common plots for numerical data B.1.1 Rug plot A rug plot can be used to plot individual values along a number line. If the same numerical value occurs multiple times, B.1.2 Impulse plot A rug plot typically does not give an adequate summary of the values and their frequencies. An impulse plot (a.k.a. “spike plot”) is a plot of observed values with bars whose heights indicate respective relative frequencies. Adding jitter when comparing impulse plots Impulse plots are most useful when there are a small number of distinct observed values. When there are many distinct observed values, displaying bars for each distinct value can become unwieldy. (Discrete example of when histogram is needed, e.g. Binomial(1000, 0.5)) B.1.3 Histograms It it typically more useful to group “close” values together before plotting. A histogram groups the observed values into “bins” and plots relative frequencies for each bin. Discrete histogram Typically, in a histogram areas of bars represent relative frequencies; in which case the axis which represents the length of the bars is called density. It is recommended that the bins all have the same width so that area and length of the bars are equivalent, with the only difference being the scale on the axis (that is, with equal bin widths, density is a linear rescaling of height and bars with the same height represent the same area/relative frequency.) B.1.4 Density plots B.1.5 Scatterplots Adding jitter B.1.6 Tile plots B.1.7 Two-dimensional histograms B.1.8 Two-dimensional density plots B.1.9 Mosaic plots B.1.10 Violin plots B.1.11 Plotting more than two variables Spaghetti? plot Using color, facets B.1.12 Time plots "],
["descriptive-statistics.html", "B.2 Descriptive statistics", " B.2 Descriptive statistics B.2.1 Frequency and relative frequency B.2.2 Percentiles Ignore vagaries of even/odd Five number summary B.2.3 Mean B.2.4 Variance and standard deviation B.2.5 Covariance and correlation B.2.6 Regression? "],
["transforming-values.html", "B.3 Transforming values", " B.3 Transforming values Effect of nonlinear transformation on histograms Effect of nonlinear transformations on mean, median/percentiles "],
["appendix-math.html", "C Mathematical Preliminaries", " C Mathematical Preliminaries link to videos and sites "],
["sets.html", "C.1 Sets", " C.1 Sets set builder notation DeMorgan’s laws Cartesian product Sets of sets "],
["functions.html", "C.2 Functions", " C.2 Functions function as input output, list "],
["references.html", "References", " References Gilovich, Thomas D., Robert P. Vallone, and Amos Tversky. 1985. “The Hot Hand in Basketball: On the Misperception of Random Sequences.” Cognitive Psychology 17 (3): 295–314. https://doi.org/https://doi.org/10.1016/0010-0285(85)90010-6. Miller, Joshua B., and Adam Sanjurjo. 2018a. “Surprised by the Hot Hand Fallacy? A Truth in the Law of Small Numbers.” Econometrica 86 (6): 2019–47. https://doi.org/10.3982/ECTA14943. ———. 2018b. “A Cold Shower for the Hot Hand Fallacy: Robust Evidence That Belief in the Hot Hand Is Justified.” OSF Preprints. https://doi.org/10.31219/osf.io/pj79r. ———. 2018c. “Is It a Fallacy to Believe in the Hot Hand in the Nba Three-Point Contest?” OSF Preprints. https://doi.org/10.31219/osf.io/dmksp. Ross, Kevin, and Dennis L. Sun. 2019. “Symbulate: Simulation in the Language of Probability.” Journal of Statistics Education 27 (1): 12–28. https://doi.org/10.1080/10691898.2019.1600387. Xie, Yihui. 2015. Dynamic Documents with R and Knitr. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. http://yihui.name/knitr/. ———. 2020. Bookdown: Authoring Books and Technical Documents with R Markdown. https://github.com/rstudio/bookdown. "]
]
